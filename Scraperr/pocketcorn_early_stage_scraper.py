#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PocketCornæ—©æœŸé¡¹ç›®å‘ç°å™¨ - ä¸“é—¨å¯»æ‰¾MRR 5ä¸‡ä»¥ä¸‹çš„åäººAIåˆ›ä¸šå…¬å¸
åŸºäºçœŸå®Scraperrå¹³å°çš„å®šåˆ¶åŒ–æŠ•èµ„åˆ†æå·¥å…·
"""

import asyncio
import aiohttp
import json
import time
from urllib.parse import quote
from datetime import datetime
import sqlite3

class EarlyStagePocketCornScraper:
    """æ—©æœŸåäººAIé¡¹ç›®ä¸“ç”¨çˆ¬è™«"""
    
    def __init__(self):
        self.session = None
        self.results = []
        
        # è°ƒæ•´ä¸ºæ—©æœŸé¡¹ç›®ç”»åƒ - MRR 5ä¸‡ä»¥ä¸‹ï¼Œå°å›¢é˜Ÿ
        self.search_patterns = {
            'early_stage_signals': [
                "å¤©ä½¿è½® åäººAIåˆ›ä¸š",
                "Pre-Aè½® AIåˆåˆ›å…¬å¸", 
                "ç§å­è½® æœºå™¨å­¦ä¹ ",
                "å°å›¢é˜Ÿ AIäº§å“",
                "Bç«¯SaaS æœˆæ”¶å…¥ 3ä¸‡",
                "AIå·¥å…· æ—©æœŸç”¨æˆ·",
                "åäººåˆ›å§‹äºº AIåˆåˆ›",
                "ç®—æ³•å·¥ç¨‹å¸ˆ åˆ›ä¸š",
                "AIåº”ç”¨ MVP",
                "æœºå™¨å­¦ä¹  åŸå‹"
            ],
            'mrr_indicators': [
                "æœˆæ”¶å…¥ 2ä¸‡-5ä¸‡",
                "MRR 30000-50000", 
                "ä»˜è´¹ç”¨æˆ· 100-500",
                "Bç«¯å®¢æˆ· 10-50å®¶",
                "SaaSè®¢é˜… æœˆè´¹",
                "ä¼ä¸šæœåŠ¡ å°å®¢æˆ·",
                "APIè°ƒç”¨ ä»˜è´¹",
                "è½¯ä»¶æˆæƒ æœˆè®¢é˜…"
            ],
            'team_signals': [
                "å›¢é˜Ÿ 3-8äºº",
                "åˆ›å§‹å›¢é˜Ÿ æŠ€æœ¯èƒŒæ™¯",
                "CTO åäºº",
                "ç®—æ³•è´Ÿè´£äºº",
                "AIå›¢é˜Ÿ æ¸…ååŒ—å¤§",
                "æµ·å½’åˆ›ä¸š AI",
                "å‰å¤§å‚ AIå·¥ç¨‹å¸ˆ",
                "åšå£«åˆ›ä¸š æœºå™¨å­¦ä¹ "
            ]
        }
        
        # ä¸“æ³¨å¯»æ‰¾è¿™ç±»æ—©æœŸé¡¹ç›®
        self.target_characteristics = {
            'revenue_range': 'æœˆæ”¶å…¥2-5ä¸‡äººæ°‘å¸',
            'team_size': '3-8äººå°å›¢é˜Ÿ',
            'funding_stage': 'å¤©ä½¿è½®/Pre-Aè½®',
            'business_model': 'Bç«¯SaaS/AIå·¥å…·',
            'founder_background': 'åäººæŠ€æœ¯åˆ›å§‹äºº',
            'product_stage': 'MVP/æ—©æœŸäº§å“'
        }
        
    async def start_session(self):
        """å¯åŠ¨HTTPä¼šè¯"""
        connector = aiohttp.TCPConnector(ssl=False)
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=aiohttp.ClientTimeout(total=15),
            headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
        )
        
    async def search_early_stage_companies(self):
        """æœç´¢æ—©æœŸé˜¶æ®µçš„åäººAIå…¬å¸"""
        print("ğŸš€ PocketCornæ—©æœŸé¡¹ç›®å‘ç°å™¨å¯åŠ¨ä¸­...")
        print("ğŸ¯ ç›®æ ‡ç”»åƒ: MRR 5ä¸‡ä»¥ä¸‹çš„åäººAIåˆ›ä¸šå…¬å¸")
        print("="*70)
        
        await self.start_session()
        
        try:
            # æœç´¢æ—©æœŸé¡¹ç›®ä¿¡å·
            for category, patterns in self.search_patterns.items():
                print(f"\\nğŸ” æœç´¢ç±»åˆ«: {category}")
                for pattern in patterns:
                    await self.scrape_search_results(pattern, category)
                    await asyncio.sleep(2)  # é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                    
        finally:
            await self.session.close()
            
        await self.analyze_early_stage_opportunities()
        
    async def scrape_search_results(self, search_term, category):
        """æŠ“å–æœç´¢ç»“æœ"""
        try:
            # ä½¿ç”¨å¤šä¸ªæœç´¢å¼•æ“
            search_engines = [
                f"https://cn.bing.com/search?q={quote(search_term)}",
                f"https://www.so.com/s?q={quote(search_term)}",  # 360æœç´¢
                f"https://www.sogou.com/web?query={quote(search_term)}"  # æœç‹—
            ]
            
            for search_url in search_engines[:1]:  # å…ˆæµ‹è¯•ä¸€ä¸ªæœç´¢å¼•æ“
                print(f"  ğŸ“Š æœç´¢: {search_term}")
                result = await self.scrape_url(search_url, search_term, category)
                if result:
                    self.results.append(result)
                    
        except Exception as e:
            print(f"  âŒ æœç´¢å¤±è´¥: {search_term} - {str(e)}")
            
    async def scrape_url(self, url, search_term, category):
        """æŠ“å–å•ä¸ªURL"""
        try:
            async with self.session.get(url) as response:
                if response.status == 200:
                    content = await response.text()
                    
                    # åˆ†æå†…å®¹å¯»æ‰¾æ—©æœŸé¡¹ç›®ä¿¡å·
                    signals = self.extract_early_stage_signals(content, search_term)
                    
                    return {
                        'search_term': search_term,
                        'category': category,
                        'url': url,
                        'status': 'success',
                        'signals_found': signals,
                        'content_sample': content[:1000] if content else '',
                        'timestamp': datetime.now().isoformat()
                    }
                else:
                    return {
                        'search_term': search_term,
                        'category': category,
                        'url': url,
                        'status': 'error',
                        'error': f'HTTP {response.status}',
                        'timestamp': datetime.now().isoformat()
                    }
        except Exception as e:
            return {
                'search_term': search_term,
                'category': category,
                'url': url,
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            
    def extract_early_stage_signals(self, content, search_term):
        """ä»å†…å®¹ä¸­æå–æ—©æœŸé¡¹ç›®ä¿¡å·"""
        signals = []
        
        # å…³é”®è¯åŒ¹é…
        early_stage_keywords = [
            'å¤©ä½¿è½®', 'ç§å­è½®', 'Pre-A', 'åˆåˆ›', 'åˆ›ä¸šå›¢é˜Ÿ',
            'æœˆæ”¶å…¥', 'MRR', 'ä»˜è´¹ç”¨æˆ·', 'SaaS', 'Bç«¯',
            'å°å›¢é˜Ÿ', 'åäººåˆ›å§‹äºº', 'CTO', 'ç®—æ³•å·¥ç¨‹å¸ˆ',
            'MVP', 'äº§å“åŸå‹', 'betaæµ‹è¯•', 'æ—©æœŸç”¨æˆ·'
        ]
        
        for keyword in early_stage_keywords:
            if keyword in content:
                signals.append({
                    'type': 'keyword_match',
                    'keyword': keyword,
                    'relevance': 'high' if keyword in search_term else 'medium'
                })
                
        return signals
        
    async def analyze_early_stage_opportunities(self):
        """åˆ†ææ—©æœŸæŠ•èµ„æœºä¼š"""
        print("\\n" + "="*70)
        print("ğŸ“Š PocketCornæ—©æœŸé¡¹ç›®åˆ†æç»“æœ")
        print("="*70)
        
        # ç»Ÿè®¡åˆ†æ
        total_searches = len(self.results)
        successful_searches = len([r for r in self.results if r['status'] == 'success'])
        
        print(f"\\nğŸ“ˆ æœç´¢ç»Ÿè®¡:")
        print(f"  â€¢ æœç´¢æŸ¥è¯¢æ•°: {total_searches}")
        print(f"  â€¢ æˆåŠŸæŸ¥è¯¢æ•°: {successful_searches}")
        print(f"  â€¢ æˆåŠŸç‡: {(successful_searches/total_searches*100) if total_searches > 0 else 0:.1f}%")
        
        # ä¿¡å·åˆ†æ
        all_signals = []
        for result in self.results:
            if result['status'] == 'success' and result.get('signals_found'):
                all_signals.extend(result['signals_found'])
                
        print(f"\\nğŸ¯ å‘ç°çš„æ—©æœŸé¡¹ç›®ä¿¡å·:")
        signal_counts = {}
        for signal in all_signals:
            keyword = signal['keyword']
            signal_counts[keyword] = signal_counts.get(keyword, 0) + 1
            
        for keyword, count in sorted(signal_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  â€¢ {keyword}: {count} æ¬¡æåŠ")
            
        # ä¿å­˜ç»“æœ
        report_file = f"pocketcorn_early_stage_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'target_profile': self.target_characteristics,
                'search_summary': {
                    'total_searches': total_searches,
                    'successful_searches': successful_searches,
                    'signals_found': len(all_signals)
                },
                'signal_analysis': signal_counts,
                'detailed_results': self.results
            }, f, ensure_ascii=False, indent=2)
            
        print(f"\\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æŠ•èµ„å»ºè®®
        print(f"\\nğŸ¯ PocketCornæ—©æœŸæŠ•èµ„å»ºè®®:")
        print(f"  â€¢ ç›®æ ‡ç”»åƒ: {self.target_characteristics['revenue_range']}")
        print(f"  â€¢ å›¢é˜Ÿè§„æ¨¡: {self.target_characteristics['team_size']}")
        print(f"  â€¢ èèµ„é˜¶æ®µ: {self.target_characteristics['funding_stage']}")
        print(f"  â€¢ å•†ä¸šæ¨¡å¼: {self.target_characteristics['business_model']}")
        
        return report_file

async def main():
    """ä¸»å‡½æ•° - é©±åŠ¨Scraperrå¯»æ‰¾æ—©æœŸé¡¹ç›®"""
    print("ğŸš€ å¯åŠ¨PocketCornæ—©æœŸé¡¹ç›®å‘ç°å™¨")
    print("ğŸ¯ åŸºäºScraperrå¹³å°çš„ä¸“ä¸šæŠ•èµ„åˆ†æå·¥å…·")
    
    scraper = EarlyStagePocketCornScraper()
    await scraper.search_early_stage_companies()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\\n\\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†æ—©æœŸé¡¹ç›®å‘ç°")
    except Exception as e:
        print(f"\\n\\nâŒ å‘ç°å™¨æ‰§è¡Œé”™è¯¯: {e}")