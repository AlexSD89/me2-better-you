# Hook å’Œè‡ªåŠ¨åŒ–æ¡†æ¶å®Œæ•´æŒ‡å— / Hook and Automation Framework Complete Guide

## ç³»ç»Ÿæ¦‚è¿° / System Overview

Hook å’Œè‡ªåŠ¨åŒ–æ¡†æ¶æ˜¯ Claude Code ç”Ÿæ€ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ï¼Œæä¾›äº‹ä»¶é©±åŠ¨çš„è‡ªåŠ¨åŒ–èƒ½åŠ›å’Œæ™ºèƒ½å·¥ä½œæµç¨‹ç¼–æ’ã€‚æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº† Hook ç³»ç»Ÿçš„æ¶æ„ã€é…ç½®ã€ä½¿ç”¨æ–¹æ³•å’Œæœ€ä½³å®è·µã€‚

The Hook and automation framework is a core component of the Claude Code ecosystem, providing event-driven automation capabilities and intelligent workflow orchestration. This guide provides detailed information about Hook system architecture, configuration, usage methods, and best practices.

## æ ¸å¿ƒæ¶æ„ / Core Architecture

### 1. Hook äº‹ä»¶ç³»ç»Ÿ / Hook Event System

```mermaid
graph TD
    A[ç”¨æˆ·æ“ä½œ / User Action] --> B[äº‹ä»¶è§¦å‘ / Event Trigger]
    B --> C[Hook æ£€æµ‹ / Hook Detection]
    C --> D[è„šæœ¬æ‰§è¡Œ / Script Execution]
    D --> E[ç»“æœå¤„ç† / Result Processing]
    E --> F[åé¦ˆè¾“å‡º / Feedback Output]
    
    G[ç³»ç»Ÿäº‹ä»¶ / System Events] --> B
    H[å·¥å…·è°ƒç”¨ / Tool Calls] --> B
    I[çŠ¶æ€å˜æ›´ / State Changes] --> B
```

### 2. Hook ç±»å‹åˆ†ç±» / Hook Type Classification

```json
{
  "hook_types": {
    "user_interaction": {
      "user-prompt-submit-hook": "ç”¨æˆ·æäº¤æç¤ºæ—¶è§¦å‘",
      "user-input-complete-hook": "ç”¨æˆ·è¾“å…¥å®Œæˆæ—¶è§¦å‘",
      "session-start-hook": "ä¼šè¯å¼€å§‹æ—¶è§¦å‘",
      "session-end-hook": "ä¼šè¯ç»“æŸæ—¶è§¦å‘"
    },
    "tool_operations": {
      "tool-call-hook": "å·¥å…·è°ƒç”¨æ—¶è§¦å‘",
      "edit-complete-hook": "ç¼–è¾‘å®Œæˆæ—¶è§¦å‘", 
      "file-create-hook": "æ–‡ä»¶åˆ›å»ºæ—¶è§¦å‘",
      "file-delete-hook": "æ–‡ä»¶åˆ é™¤æ—¶è§¦å‘"
    },
    "project_management": {
      "project-start-hook": "é¡¹ç›®å¼€å§‹æ—¶è§¦å‘",
      "task-completion-hook": "ä»»åŠ¡å®Œæˆæ—¶è§¦å‘",
      "build-success-hook": "æ„å»ºæˆåŠŸæ—¶è§¦å‘",
      "test-pass-hook": "æµ‹è¯•é€šè¿‡æ—¶è§¦å‘"
    },
    "quality_assurance": {
      "code-review-hook": "ä»£ç å®¡æŸ¥æ—¶è§¦å‘",
      "lint-check-hook": "ä»£ç æ£€æŸ¥æ—¶è§¦å‘",
      "security-scan-hook": "å®‰å…¨æ‰«ææ—¶è§¦å‘",
      "performance-check-hook": "æ€§èƒ½æ£€æŸ¥æ—¶è§¦å‘"
    }
  }
}
```

## Hook é…ç½®ç®¡ç† / Hook Configuration Management

### 1. å…¨å±€é…ç½® / Global Configuration

#### Claude Code è®¾ç½® / Claude Code Settings
```json
{
  "hooks": {
    "enabled": true,
    "timeout": 30000,
    "retries": 3,
    "logLevel": "info",
    "parallelExecution": true,
    "maxConcurrentHooks": 5,
    "defaultShell": "/bin/bash",
    "environmentVariables": {
      "CLAUDE_HOOK_ENV": "production",
      "PROJECT_ROOT": "${workspaceFolder}",
      "HOOK_LOG_PATH": "/tmp/claude-hooks.log"
    }
  }
}
```

#### Ruler ç»Ÿä¸€é…ç½® / Ruler Unified Configuration
```toml
# .ruler/hooks.toml
[hooks.global]
enabled = true
timeout = 30000
log_level = "info"

[hooks.sound_system]
enabled = true
project_completion_sound = true
error_notification_sound = true

[hooks.quality_assurance]
auto_lint = true
auto_test = true
auto_review = true

[hooks.project_management]
task_tracking = true
progress_notification = true
completion_celebration = true
```

### 2. é¡¹ç›®çº§é…ç½® / Project-Level Configuration

#### .claude/hooks.json é…ç½® / .claude/hooks.json Configuration
```json
{
  "project": "LaunchX-æ™ºé“¾å¹³å°",
  "hooks": {
    "user-prompt-submit-hook": {
      "enabled": true,
      "script": "./hooks/prompt-submit.sh",
      "timeout": 10000,
      "runInBackground": false
    },
    "edit-complete-hook": {
      "enabled": true,
      "script": "./hooks/edit-complete.sh",
      "timeout": 15000,
      "runInBackground": true,
      "conditions": {
        "fileTypes": [".js", ".ts", ".jsx", ".tsx", ".py", ".md"],
        "minChanges": 5
      }
    },
    "task-completion-hook": {
      "enabled": true,
      "script": "./hooks/task-completion.sh",
      "timeout": 5000,
      "conditions": {
        "taskTypes": ["coding", "review", "documentation"],
        "minDuration": 30000
      }
    }
  }
}
```

## å®ç”¨ Hook è„šæœ¬é›†åˆ / Practical Hook Script Collection

### 1. ç”¨æˆ·äº¤äº’ Hook / User Interaction Hooks

#### æç¤ºæäº¤å¤„ç† / Prompt Submit Handler
```bash
#!/bin/bash
# hooks/prompt-submit.sh - ç”¨æˆ·æç¤ºæäº¤å¤„ç†

set -euo pipefail

HOOK_NAME="user-prompt-submit"
TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S")
PROMPT_TEXT="$1"
SESSION_ID="$2"

# è®°å½•æç¤ºå†å² / Log prompt history
echo "[$TIMESTAMP] Session: $SESSION_ID - Prompt: $PROMPT_TEXT" >> .claude/prompt-history.log

# åˆ†ææç¤ºå¤æ‚åº¦ / Analyze prompt complexity
WORD_COUNT=$(echo "$PROMPT_TEXT" | wc -w)
if [ "$WORD_COUNT" -gt 100 ]; then
    echo "ğŸ“Š å¤æ‚æç¤ºæ£€æµ‹ - å­—æ•°: $WORD_COUNT" >&2
    # å¯åŠ¨é•¿ä»»åŠ¡ç›‘æ§ / Start long task monitoring
    touch .claude/long-task-active
fi

# æ£€æŸ¥é¡¹ç›®ä¸Šä¸‹æ–‡ / Check project context
if [[ "$PROMPT_TEXT" =~ "æ™ºé“¾|zhilink|LaunchX" ]]; then
    echo "ğŸ”— LaunchX æ™ºé“¾é¡¹ç›®ä¸Šä¸‹æ–‡æ¿€æ´»" >&2
    export PROJECT_CONTEXT="zhilink"
fi

# æ™ºèƒ½å·¥ä½œæ¨¡å¼æ£€æµ‹ / Smart work mode detection
CURRENT_HOUR=$(date +%H)
if [ "$CURRENT_HOUR" -ge 22 ] || [ "$CURRENT_HOUR" -le 6 ]; then
    echo "ğŸŒ™ å¤œé—´æ¨¡å¼æ¿€æ´» - å¯ç”¨é™éŸ³é€šçŸ¥" >&2
    export SOUND_MODE="silent"
else
    export SOUND_MODE="normal"
fi

echo "âœ… æç¤ºå¤„ç†å®Œæˆ - æ¨¡å¼: $SOUND_MODE, ä¸Šä¸‹æ–‡: ${PROJECT_CONTEXT:-general}"
```

### 2. ç¼–è¾‘å®Œæˆ Hook / Edit Complete Hooks

#### æ™ºèƒ½ç¼–è¾‘åˆ†æ / Intelligent Edit Analysis
```bash
#!/bin/bash
# hooks/edit-complete.sh - ç¼–è¾‘å®Œæˆæ™ºèƒ½åˆ†æ

set -euo pipefail

FILE_PATH="$1"
EDIT_TYPE="$2"  # create, update, delete
CHANGES_COUNT="$3"

# é¡¹ç›®å£°éŸ³ç³»ç»Ÿé›†æˆ / Project sound system integration
SOUND_ENGINE="./å¼€å‘è§„èŒƒå·¥å…·/sound-system/sound_engine.py"
if [ -f "$SOUND_ENGINE" ]; then
    python3 "$SOUND_ENGINE" --event "edit_complete" \
        --file "$FILE_PATH" \
        --changes "$CHANGES_COUNT" \
        --type "$EDIT_TYPE"
fi

# æ™ºèƒ½ä»£ç è´¨é‡æ£€æŸ¥ / Intelligent code quality check
case "${FILE_PATH##*.}" in
    js|ts|jsx|tsx)
        if command -v eslint >/dev/null 2>&1; then
            echo "ğŸ” è¿è¡Œ ESLint æ£€æŸ¥..." >&2
            eslint "$FILE_PATH" --fix-dry-run --format compact
        fi
        ;;
    py)
        if command -v ruff >/dev/null 2>&1; then
            echo "ğŸ” è¿è¡Œ Ruff æ£€æŸ¥..." >&2
            ruff check "$FILE_PATH"
        fi
        ;;
    md)
        if command -v markdownlint >/dev/null 2>&1; then
            echo "ğŸ” è¿è¡Œ Markdown æ£€æŸ¥..." >&2
            markdownlint "$FILE_PATH"
        fi
        ;;
esac

# è‡ªåŠ¨æµ‹è¯•è§¦å‘ / Automatic test triggering
if [[ "$FILE_PATH" =~ \.(js|ts|py)$ ]] && [ "$CHANGES_COUNT" -gt 10 ]; then
    echo "ğŸ§ª å˜æ›´è¾ƒå¤§ï¼Œå»ºè®®è¿è¡Œæµ‹è¯•" >&2
    if [ -f "package.json" ] && jq -e '.scripts.test' package.json >/dev/null; then
        echo "ğŸ’¡ å¯è¿è¡Œ: npm test" >&2
    elif [ -f "pytest.ini" ] || [ -f "pyproject.toml" ]; then
        echo "ğŸ’¡ å¯è¿è¡Œ: pytest" >&2
    fi
fi

# æ–‡æ¡£åŒæ­¥æ£€æŸ¥ / Documentation sync check
if [[ "$FILE_PATH" =~ src/ ]] && [ "$EDIT_TYPE" = "create" ]; then
    echo "ğŸ“š æ–°æ–‡ä»¶åˆ›å»ºï¼Œæ£€æŸ¥æ–‡æ¡£åŒæ­¥..." >&2
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–° README æˆ–æ–‡æ¡£
    if [ ! -f "docs/$(basename "$FILE_PATH" .${FILE_PATH##*.}).md" ]; then
        echo "ğŸ’¡ å»ºè®®åˆ›å»ºå¯¹åº”æ–‡æ¡£: docs/$(basename "$FILE_PATH" .${FILE_PATH##*.}).md" >&2
    fi
fi

echo "âœ… ç¼–è¾‘åˆ†æå®Œæˆ - æ–‡ä»¶: $FILE_PATH, å˜æ›´: $CHANGES_COUNT"
```

### 3. ä»»åŠ¡å®Œæˆ Hook / Task Completion Hooks

#### é¡¹ç›®å®Œæˆåº†ç¥ç³»ç»Ÿ / Project Completion Celebration System
```bash
#!/bin/bash
# hooks/task-completion.sh - ä»»åŠ¡å®Œæˆåº†ç¥å’Œåˆ†æ

set -euo pipefail

TASK_TYPE="$1"
DURATION="$2"
COMPLEXITY="$3"

# åŠ è½½å£°éŸ³ç³»ç»Ÿ / Load sound system
SOUND_ENGINE="./å¼€å‘è§„èŒƒå·¥å…·/sound-system/sound_engine.py"
SCENARIO_MANAGER="./å¼€å‘è§„èŒƒå·¥å…·/sound-system/scenarios.py"

# ä»»åŠ¡å®Œæˆå£°éŸ³åé¦ˆ / Task completion sound feedback
if [ -f "$SOUND_ENGINE" ]; then
    python3 "$SOUND_ENGINE" --event "task_completion" \
        --task-type "$TASK_TYPE" \
        --duration "$DURATION" \
        --complexity "$COMPLEXITY"
fi

# ä»»åŠ¡ç»Ÿè®¡æ›´æ–° / Task statistics update
STATS_FILE=".claude/task-stats.json"
if [ ! -f "$STATS_FILE" ]; then
    echo '{"tasks_completed": 0, "total_time": 0, "by_type": {}}' > "$STATS_FILE"
fi

# æ›´æ–°ç»Ÿè®¡æ•°æ® / Update statistics
python3 -c "
import json
import sys

stats_file = '$STATS_FILE'
task_type = '$TASK_TYPE'
duration = int('$DURATION')

with open(stats_file, 'r') as f:
    stats = json.load(f)

stats['tasks_completed'] += 1
stats['total_time'] += duration

if task_type not in stats['by_type']:
    stats['by_type'][task_type] = {'count': 0, 'time': 0}

stats['by_type'][task_type]['count'] += 1
stats['by_type'][task_type]['time'] += duration

with open(stats_file, 'w') as f:
    json.dump(stats, f, indent=2)

print(f'ğŸ“Š ä»»åŠ¡ç»Ÿè®¡æ›´æ–°: {stats[\"tasks_completed\"]} ä¸ªä»»åŠ¡å®Œæˆ')
"

# æ™ºèƒ½ä¼‘æ¯å»ºè®® / Intelligent break suggestions
TOTAL_TIME=$(jq -r '.total_time' "$STATS_FILE")
RECENT_TASKS=$(jq -r '.tasks_completed' "$STATS_FILE")

if [ "$TOTAL_TIME" -gt 7200000 ]; then  # 2å°æ—¶
    echo "â° è¿ç»­å·¥ä½œè¶…è¿‡2å°æ—¶ï¼Œå»ºè®®ä¼‘æ¯ä¸€ä¸‹ï¼" >&2
elif [ "$RECENT_TASKS" -gt 10 ]; then
    echo "ğŸ¯ å®Œæˆä»»åŠ¡è¾ƒå¤šï¼ŒçŠ¶æ€å¾ˆå¥½ï¼å»ºè®®é€‚å½“ä¼‘æ¯ä¿æŒæ•ˆç‡ã€‚" >&2
fi

# é¡¹ç›®è¿›åº¦æ£€æŸ¥ / Project progress check
if [[ "$TASK_TYPE" =~ "coding|implementation" ]]; then
    echo "ğŸ’» ä»£ç ä»»åŠ¡å®Œæˆï¼Œå»ºè®®è¿è¡Œæµ‹è¯•ç¡®ä¿è´¨é‡" >&2
elif [[ "$TASK_TYPE" =~ "review|refactor" ]]; then
    echo "ğŸ” å®¡æŸ¥/é‡æ„å®Œæˆï¼Œä»£ç è´¨é‡å¾—åˆ°æå‡" >&2
elif [[ "$TASK_TYPE" =~ "documentation" ]]; then
    echo "ğŸ“ æ–‡æ¡£ä»»åŠ¡å®Œæˆï¼Œé¡¹ç›®å¯ç»´æŠ¤æ€§å¢å¼º" >&2
fi

echo "ğŸ‰ ä»»åŠ¡å®Œæˆ! ç±»å‹: $TASK_TYPE, è€—æ—¶: ${DURATION}ms"
```

## é«˜çº§è‡ªåŠ¨åŒ–æ¨¡å¼ / Advanced Automation Patterns

### 1. å·¥ä½œæµç¨‹ç¼–æ’ / Workflow Orchestration

#### å¤šé˜¶æ®µä»»åŠ¡è‡ªåŠ¨åŒ– / Multi-stage Task Automation
```bash
#!/bin/bash
# hooks/workflow-orchestrator.sh - å·¥ä½œæµç¨‹ç¼–æ’å™¨

set -euo pipefail

WORKFLOW_TYPE="$1"
PROJECT_CONTEXT="$2"

case "$WORKFLOW_TYPE" in
    "feature-development")
        echo "ğŸš€ å¯åŠ¨åŠŸèƒ½å¼€å‘å·¥ä½œæµ..." >&2
        # 1. ä»£ç åˆ†æé˜¶æ®µ
        ./hooks/analyze-codebase.sh "$PROJECT_CONTEXT"
        # 2. è®¾è®¡ç¡®è®¤é˜¶æ®µ  
        ./hooks/design-review.sh "$PROJECT_CONTEXT"
        # 3. å®ç°é˜¶æ®µ
        ./hooks/implementation-tracking.sh "$PROJECT_CONTEXT"
        # 4. æµ‹è¯•é˜¶æ®µ
        ./hooks/testing-automation.sh "$PROJECT_CONTEXT"
        # 5. æ–‡æ¡£æ›´æ–°é˜¶æ®µ
        ./hooks/documentation-sync.sh "$PROJECT_CONTEXT"
        ;;
    "bug-fix")
        echo "ğŸ› å¯åŠ¨é—®é¢˜ä¿®å¤å·¥ä½œæµ..." >&2
        # 1. é—®é¢˜å®šä½
        ./hooks/bug-analysis.sh "$PROJECT_CONTEXT"
        # 2. å½±å“è¯„ä¼°
        ./hooks/impact-assessment.sh "$PROJECT_CONTEXT"
        # 3. ä¿®å¤å®ç°
        ./hooks/fix-implementation.sh "$PROJECT_CONTEXT"
        # 4. å›å½’æµ‹è¯•
        ./hooks/regression-testing.sh "$PROJECT_CONTEXT"
        ;;
    "refactoring")
        echo "ğŸ”§ å¯åŠ¨é‡æ„å·¥ä½œæµ..." >&2
        # 1. ä»£ç è´¨é‡åˆ†æ
        ./hooks/quality-analysis.sh "$PROJECT_CONTEXT"
        # 2. é‡æ„è®¡åˆ’
        ./hooks/refactoring-plan.sh "$PROJECT_CONTEXT"
        # 3. æ¸è¿›å¼é‡æ„
        ./hooks/incremental-refactor.sh "$PROJECT_CONTEXT"
        # 4. è´¨é‡éªŒè¯
        ./hooks/quality-verification.sh "$PROJECT_CONTEXT"
        ;;
esac

echo "âœ… å·¥ä½œæµç¨‹ $WORKFLOW_TYPE ç¼–æ’å®Œæˆ"
```

### 2. æ™ºèƒ½è´¨é‡ç›‘æ§ / Intelligent Quality Monitoring

#### å®æ—¶ä»£ç è´¨é‡ç›‘æ§ / Real-time Code Quality Monitoring
```python
#!/usr/bin/env python3
# hooks/quality-monitor.py - å®æ—¶ä»£ç è´¨é‡ç›‘æ§

import json
import subprocess
import sys
from pathlib import Path
from datetime import datetime
import logging

class QualityMonitor:
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.metrics_file = self.project_root / '.claude' / 'quality-metrics.json'
        self.setup_logging()
    
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('.claude/quality-monitor.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def check_code_quality(self, file_path):
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶çš„ä»£ç è´¨é‡"""
        file_path = Path(file_path)
        results = {
            'file': str(file_path),
            'timestamp': datetime.now().isoformat(),
            'metrics': {}
        }
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©æ£€æŸ¥å·¥å…·
        if file_path.suffix in ['.js', '.ts', '.jsx', '.tsx']:
            results['metrics'].update(self._check_javascript(file_path))
        elif file_path.suffix == '.py':
            results['metrics'].update(self._check_python(file_path))
        elif file_path.suffix == '.md':
            results['metrics'].update(self._check_markdown(file_path))
        
        # æ›´æ–°é¡¹ç›®è´¨é‡æŒ‡æ ‡
        self._update_project_metrics(results)
        return results
    
    def _check_javascript(self, file_path):
        """æ£€æŸ¥ JavaScript/TypeScript æ–‡ä»¶"""
        metrics = {}
        
        # ESLint æ£€æŸ¥
        try:
            result = subprocess.run(
                ['eslint', str(file_path), '--format', 'json'],
                capture_output=True, text=True, timeout=30
            )
            if result.stdout:
                eslint_data = json.loads(result.stdout)
                if eslint_data and len(eslint_data) > 0:
                    file_data = eslint_data[0]
                    metrics['eslint'] = {
                        'error_count': file_data.get('errorCount', 0),
                        'warning_count': file_data.get('warningCount', 0),
                        'fixable_error_count': file_data.get('fixableErrorCount', 0),
                        'fixable_warning_count': file_data.get('fixableWarningCount', 0)
                    }
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, json.JSONDecodeError):
            self.logger.warning(f"ESLint æ£€æŸ¥å¤±è´¥: {file_path}")
        
        # TypeScript ç±»å‹æ£€æŸ¥
        if file_path.suffix in ['.ts', '.tsx']:
            try:
                result = subprocess.run(
                    ['tsc', '--noEmit', '--skipLibCheck', str(file_path)],
                    capture_output=True, text=True, timeout=30
                )
                metrics['typescript'] = {
                    'type_errors': len([line for line in result.stderr.split('\n') if 'error TS' in line])
                }
            except (subprocess.TimeoutExpired, subprocess.CalledProcessError):
                self.logger.warning(f"TypeScript æ£€æŸ¥å¤±è´¥: {file_path}")
        
        return metrics
    
    def _check_python(self, file_path):
        """æ£€æŸ¥ Python æ–‡ä»¶"""
        metrics = {}
        
        # Ruff æ£€æŸ¥
        try:
            result = subprocess.run(
                ['ruff', 'check', str(file_path), '--format', 'json'],
                capture_output=True, text=True, timeout=30
            )
            if result.stdout:
                ruff_data = json.loads(result.stdout)
                metrics['ruff'] = {
                    'violations': len(ruff_data),
                    'fixable': len([v for v in ruff_data if v.get('fix')])
                }
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, json.JSONDecodeError):
            self.logger.warning(f"Ruff æ£€æŸ¥å¤±è´¥: {file_path}")
        
        # mypy ç±»å‹æ£€æŸ¥
        try:
            result = subprocess.run(
                ['mypy', str(file_path), '--json-report', '/dev/stdout'],
                capture_output=True, text=True, timeout=30
            )
            if result.stdout:
                mypy_data = json.loads(result.stdout)
                metrics['mypy'] = {
                    'type_errors': len(mypy_data.get('reports', {}).get('summary', {}).get('errors', []))
                }
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, json.JSONDecodeError):
            self.logger.warning(f"mypy æ£€æŸ¥å¤±è´¥: {file_path}")
        
        return metrics
    
    def _check_markdown(self, file_path):
        """æ£€æŸ¥ Markdown æ–‡ä»¶"""
        metrics = {}
        
        try:
            result = subprocess.run(
                ['markdownlint', str(file_path), '--json'],
                capture_output=True, text=True, timeout=30
            )
            if result.stdout:
                md_data = json.loads(result.stdout)
                metrics['markdownlint'] = {
                    'issues': len(md_data.get(str(file_path), []))
                }
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, json.JSONDecodeError):
            self.logger.warning(f"Markdownlint æ£€æŸ¥å¤±è´¥: {file_path}")
        
        return metrics
    
    def _update_project_metrics(self, file_results):
        """æ›´æ–°é¡¹ç›®æ•´ä½“è´¨é‡æŒ‡æ ‡"""
        if not self.metrics_file.parent.exists():
            self.metrics_file.parent.mkdir(parents=True)
        
        # åŠ è½½ç°æœ‰æŒ‡æ ‡
        if self.metrics_file.exists():
            with open(self.metrics_file, 'r') as f:
                project_metrics = json.load(f)
        else:
            project_metrics = {
                'files': {},
                'summary': {
                    'total_files': 0,
                    'last_updated': None,
                    'quality_trend': []
                }
            }
        
        # æ›´æ–°æ–‡ä»¶æŒ‡æ ‡
        project_metrics['files'][file_results['file']] = file_results
        project_metrics['summary']['total_files'] = len(project_metrics['files'])
        project_metrics['summary']['last_updated'] = datetime.now().isoformat()
        
        # è®¡ç®—è´¨é‡è¶‹åŠ¿
        self._calculate_quality_trend(project_metrics)
        
        # ä¿å­˜æ›´æ–°åçš„æŒ‡æ ‡
        with open(self.metrics_file, 'w') as f:
            json.dump(project_metrics, f, indent=2)
        
        self.logger.info(f"é¡¹ç›®è´¨é‡æŒ‡æ ‡å·²æ›´æ–°: {file_results['file']}")
    
    def _calculate_quality_trend(self, project_metrics):
        """è®¡ç®—è´¨é‡è¶‹åŠ¿"""
        total_errors = 0
        total_warnings = 0
        
        for file_data in project_metrics['files'].values():
            metrics = file_data.get('metrics', {})
            for tool_metrics in metrics.values():
                if isinstance(tool_metrics, dict):
                    total_errors += tool_metrics.get('error_count', 0) + tool_metrics.get('type_errors', 0)
                    total_warnings += tool_metrics.get('warning_count', 0) + tool_metrics.get('violations', 0)
        
        quality_score = max(0, 100 - (total_errors * 10 + total_warnings * 2))
        
        # è®°å½•è´¨é‡è¶‹åŠ¿
        trend_entry = {
            'timestamp': datetime.now().isoformat(),
            'quality_score': quality_score,
            'total_errors': total_errors,
            'total_warnings': total_warnings
        }
        
        project_metrics['summary']['quality_trend'].append(trend_entry)
        
        # ä¿æŒæœ€è¿‘30ä¸ªæ•°æ®ç‚¹
        if len(project_metrics['summary']['quality_trend']) > 30:
            project_metrics['summary']['quality_trend'] = project_metrics['summary']['quality_trend'][-30:]

if __name__ == '__main__':
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 quality-monitor.py <file_path>")
        sys.exit(1)
    
    file_path = sys.argv[1]
    monitor = QualityMonitor('.')
    results = monitor.check_code_quality(file_path)
    
    print(f"âœ… è´¨é‡æ£€æŸ¥å®Œæˆ: {file_path}")
    if results['metrics']:
        print(f"ğŸ“Š å‘ç°æŒ‡æ ‡: {json.dumps(results['metrics'], indent=2)}")
```

### 3. æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ– / Performance Monitoring and Optimization

#### Hook æ€§èƒ½åˆ†æå™¨ / Hook Performance Analyzer
```bash
#!/bin/bash
# hooks/performance-analyzer.sh - Hook æ€§èƒ½åˆ†æå™¨

set -euo pipefail

HOOK_NAME="$1"
START_TIME="$2"
END_TIME="$3"

DURATION=$((END_TIME - START_TIME))
PERF_LOG=".claude/hook-performance.log"

# è®°å½•æ€§èƒ½æ•°æ® / Record performance data
echo "$(date -Iseconds) | $HOOK_NAME | ${DURATION}ms" >> "$PERF_LOG"

# æ€§èƒ½é˜ˆå€¼æ£€æŸ¥ / Performance threshold check
SLOW_THRESHOLD=5000  # 5ç§’
VERY_SLOW_THRESHOLD=15000  # 15ç§’

if [ "$DURATION" -gt "$VERY_SLOW_THRESHOLD" ]; then
    echo "ğŸŒ è­¦å‘Š: Hook '$HOOK_NAME' æ‰§è¡Œæ—¶é—´è¿‡é•¿ (${DURATION}ms)" >&2
    echo "ğŸ’¡ å»ºè®®ä¼˜åŒ–æˆ–è®¾ç½®ä¸ºåå°æ‰§è¡Œ" >&2
elif [ "$DURATION" -gt "$SLOW_THRESHOLD" ]; then
    echo "â° æ³¨æ„: Hook '$HOOK_NAME' æ‰§è¡Œè¾ƒæ…¢ (${DURATION}ms)" >&2
fi

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š / Generate performance report
if [ "$((RANDOM % 10))" -eq 0 ]; then  # 10% æ¦‚ç‡ç”ŸæˆæŠ¥å‘Š
    python3 -c "
import re
from collections import defaultdict, Counter
from datetime import datetime, timedelta

perf_data = defaultdict(list)
with open('$PERF_LOG', 'r') as f:
    for line in f:
        if '|' in line:
            parts = line.strip().split(' | ')
            if len(parts) == 3:
                timestamp, hook_name, duration = parts
                duration_ms = int(duration.replace('ms', ''))
                perf_data[hook_name].append(duration_ms)

print('ğŸ“Š Hook æ€§èƒ½åˆ†ææŠ¥å‘Š:')
for hook_name, durations in perf_data.items():
    if durations:
        avg_duration = sum(durations) / len(durations)
        max_duration = max(durations)
        min_duration = min(durations)
        print(f'  {hook_name}:')
        print(f'    å¹³å‡è€—æ—¶: {avg_duration:.1f}ms')
        print(f'    æœ€å¤§è€—æ—¶: {max_duration}ms')
        print(f'    æœ€å°è€—æ—¶: {min_duration}ms')
        print(f'    æ‰§è¡Œæ¬¡æ•°: {len(durations)}')
        print()
"
fi

echo "âš¡ Hook æ€§èƒ½åˆ†æå®Œæˆ: $HOOK_NAME (${DURATION}ms)"
```

## å¹³å°ç‰¹å®šé›†æˆ / Platform-Specific Integration

### 1. LaunchX æ™ºé“¾å¹³å°é›†æˆ / LaunchX Zhilink Platform Integration

#### æ™ºé“¾é¡¹ç›® Hook é…ç½® / Zhilink Project Hook Configuration
```json
{
  "zhilink_hooks": {
    "development": {
      "frontend-change-hook": {
        "script": "./hooks/zhilink/frontend-change.sh",
        "triggers": ["src/app/**/*.tsx", "src/components/**/*.tsx"],
        "actions": [
          "TypeScript ç±»å‹æ£€æŸ¥",
          "React ç»„ä»¶éªŒè¯",
          "Tailwind CSS æ£€æŸ¥",
          "è‡ªåŠ¨åŒ–æµ‹è¯•è§¦å‘"
        ]
      },
      "backend-change-hook": {
        "script": "./hooks/zhilink/backend-change.sh", 
        "triggers": ["src/services/**/*.ts", "src/database/**/*.ts"],
        "actions": [
          "API ç±»å‹æ£€æŸ¥",
          "æ•°æ®åº“æ¨¡å‹éªŒè¯",
          "å•å…ƒæµ‹è¯•è¿è¡Œ",
          "é›†æˆæµ‹è¯•è§¦å‘"
        ]
      },
      "chat-system-hook": {
        "script": "./hooks/zhilink/chat-system.sh",
        "triggers": ["src/app/chat/**/*.tsx", "src/services/chat/**/*.ts"],
        "actions": [
          "èŠå¤©åŠŸèƒ½æµ‹è¯•",
          "å®æ—¶é€šä¿¡éªŒè¯",
          "æ€§èƒ½åŸºå‡†æµ‹è¯•"
        ]
      }
    }
  }
}
```

#### æ™ºé“¾å‰ç«¯å˜æ›´ Hook / Zhilink Frontend Change Hook
```bash
#!/bin/bash
# hooks/zhilink/frontend-change.sh - æ™ºé“¾å‰ç«¯å˜æ›´å¤„ç†

set -euo pipefail

CHANGED_FILE="$1"
CHANGE_TYPE="$2"

echo "ğŸ”— LaunchX æ™ºé“¾å‰ç«¯å˜æ›´æ£€æµ‹: $CHANGED_FILE" >&2

# Next.js é¡¹ç›®æ£€æŸ¥ / Next.js project check
if [[ "$CHANGED_FILE" =~ src/app/ ]]; then
    echo "ğŸ“± App Router æ–‡ä»¶å˜æ›´ï¼Œæ£€æŸ¥è·¯ç”±ç»“æ„..." >&2
    
    # æ£€æŸ¥é¡µé¢ç»„ä»¶è§„èŒƒ / Check page component standards
    if [[ "$CHANGED_FILE" =~ page\.tsx$ ]]; then
        echo "ğŸ“„ é¡µé¢ç»„ä»¶å˜æ›´ï¼ŒéªŒè¯å¯¼å‡ºè§„èŒƒ..." >&2
        # æ£€æŸ¥æ˜¯å¦æœ‰é»˜è®¤å¯¼å‡º
        if ! grep -q "export default" "$CHANGED_FILE"; then
            echo "âš ï¸  è­¦å‘Š: é¡µé¢ç»„ä»¶ç¼ºå°‘é»˜è®¤å¯¼å‡º" >&2
        fi
    fi
    
    # æ£€æŸ¥å¸ƒå±€ç»„ä»¶ / Check layout components
    if [[ "$CHANGED_FILE" =~ layout\.tsx$ ]]; then
        echo "ğŸ—ï¸  å¸ƒå±€ç»„ä»¶å˜æ›´ï¼Œæ£€æŸ¥children prop..." >&2
        if ! grep -q "children.*React\.ReactNode" "$CHANGED_FILE"; then
            echo "ğŸ’¡ å»ºè®®: ç¡®ä¿å¸ƒå±€ç»„ä»¶åŒ…å«children propç±»å‹å®šä¹‰" >&2
        fi
    fi
fi

# React ç»„ä»¶è´¨é‡æ£€æŸ¥ / React component quality check
if [[ "$CHANGED_FILE" =~ \.tsx$ ]]; then
    echo "âš›ï¸  React ç»„ä»¶æ£€æŸ¥..." >&2
    
    # æ£€æŸ¥ Hooks ä½¿ç”¨è§„èŒƒ / Check Hooks usage standards
    if grep -q "useState\|useEffect\|useCallback\|useMemo" "$CHANGED_FILE"; then
        echo "ğŸª æ£€æµ‹åˆ° Hooks ä½¿ç”¨ï¼ŒéªŒè¯ä¾èµ–æ•°ç»„..." >&2
    fi
    
    # æ£€æŸ¥ TypeScript ç±»å‹å®šä¹‰ / Check TypeScript type definitions
    if ! grep -q "interface\|type\|:" "$CHANGED_FILE"; then
        echo "ğŸ’¡ å»ºè®®: æ·»åŠ  TypeScript ç±»å‹å®šä¹‰æé«˜ä»£ç è´¨é‡" >&2
    fi
    
    # Tailwind CSS ç±»åæ£€æŸ¥ / Tailwind CSS class check
    if grep -q "className=" "$CHANGED_FILE"; then
        echo "ğŸ¨ æ£€æµ‹åˆ° Tailwind CSS ä½¿ç”¨" >&2
        # å¯ä»¥æ·»åŠ  Tailwind ç±»åéªŒè¯é€»è¾‘
    fi
fi

# è‡ªåŠ¨åŒ–æµ‹è¯•å»ºè®® / Automated testing suggestions
if [[ "$CHANGE_TYPE" = "create" ]]; then
    COMPONENT_NAME=$(basename "$CHANGED_FILE" .tsx)
    TEST_FILE="src/__tests__/${COMPONENT_NAME}.test.tsx"
    
    if [ ! -f "$TEST_FILE" ]; then
        echo "ğŸ§ª å»ºè®®åˆ›å»ºæµ‹è¯•æ–‡ä»¶: $TEST_FILE" >&2
    fi
fi

# å£°éŸ³åé¦ˆ / Sound feedback
if [ -f "./å¼€å‘è§„èŒƒå·¥å…·/sound-system/sound_engine.py" ]; then
    python3 "./å¼€å‘è§„èŒƒå·¥å…·/sound-system/sound_engine.py" \
        --event "zhilink_frontend_change" \
        --file "$CHANGED_FILE" \
        --type "$CHANGE_TYPE"
fi

echo "âœ… æ™ºé“¾å‰ç«¯å˜æ›´å¤„ç†å®Œæˆ"
```

### 2. å¤šé¡¹ç›®æ”¯æŒ / Multi-Project Support

#### é¡¹ç›®ä¸Šä¸‹æ–‡æ£€æµ‹ / Project Context Detection
```bash
#!/bin/bash
# hooks/project-context-detector.sh - é¡¹ç›®ä¸Šä¸‹æ–‡æ£€æµ‹å™¨

set -euo pipefail

detect_project_context() {
    local current_dir="$PWD"
    
    # LaunchX æ™ºé“¾é¡¹ç›®æ£€æµ‹ / LaunchX Zhilink project detection
    if [[ "$current_dir" =~ zhilink ]] || [ -f "æ™ºé“¾ç³»ç»ŸéªŒæ”¶æŠ¥å‘Š.md" ]; then
        echo "zhilink"
        return 0
    fi
    
    # PocketCorn é¡¹ç›®æ£€æµ‹ / PocketCorn project detection  
    if [[ "$current_dir" =~ pocketcorn ]] || [ -f "pocketcorn.config.js" ]; then
        echo "pocketcorn"
        return 0
    fi
    
    # Trading Agents é¡¹ç›®æ£€æµ‹ / Trading Agents project detection
    if [[ "$current_dir" =~ trading ]] || [ -f "trading-config.json" ]; then
        echo "trading"
        return 0
    fi
    
    # çŸ¥è¯†ç®¡ç†é¡¹ç›®æ£€æµ‹ / Knowledge management project detection
    if [ -d ".obsidian" ] || [[ "$current_dir" =~ obsidian ]]; then
        echo "knowledge"
        return 0
    fi
    
    # é€šç”¨é¡¹ç›® / Generic project
    echo "general"
}

PROJECT_CONTEXT=$(detect_project_context)
echo "ğŸ¯ é¡¹ç›®ä¸Šä¸‹æ–‡: $PROJECT_CONTEXT" >&2

# è®¾ç½®é¡¹ç›®ç‰¹å®šçš„ç¯å¢ƒå˜é‡ / Set project-specific environment variables
case "$PROJECT_CONTEXT" in
    "zhilink")
        export PROJECT_TYPE="web-platform"
        export TECH_STACK="nextjs,typescript,tailwind,mongodb"
        export SOUND_THEME="professional"
        ;;
    "pocketcorn")
        export PROJECT_TYPE="data-analysis"
        export TECH_STACK="python,jupyter,pandas,plotly"
        export SOUND_THEME="analytical"
        ;;
    "trading")
        export PROJECT_TYPE="financial-system"
        export TECH_STACK="python,fastapi,asyncio,websockets"
        export SOUND_THEME="trading"
        ;;
    "knowledge")
        export PROJECT_TYPE="knowledge-management"
        export TECH_STACK="markdown,obsidian,javascript"
        export SOUND_THEME="academic"
        ;;
    *)
        export PROJECT_TYPE="general"
        export TECH_STACK="unknown"
        export SOUND_THEME="default"
        ;;
esac

echo "PROJECT_CONTEXT=$PROJECT_CONTEXT"
echo "PROJECT_TYPE=$PROJECT_TYPE"
echo "TECH_STACK=$TECH_STACK"
echo "SOUND_THEME=$SOUND_THEME"
```

## ç›‘æ§å’Œè°ƒè¯• / Monitoring and Debugging

### 1. Hook æ—¥å¿—ç³»ç»Ÿ / Hook Logging System

#### ç»“æ„åŒ–æ—¥å¿—è®°å½• / Structured Logging
```python
#!/usr/bin/env python3
# hooks/logger.py - Hook ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ

import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

class HookLogger:
    def __init__(self, log_dir: str = '.claude/logs'):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—æ ¼å¼ / Set up log format
        self.setup_loggers()
    
    def setup_loggers(self):
        """è®¾ç½®ä¸åŒçº§åˆ«çš„æ—¥å¿—è®°å½•å™¨"""
        # ä¸»æ—¥å¿—è®°å½•å™¨ / Main logger
        self.main_logger = logging.getLogger('hook_main')
        self.main_logger.setLevel(logging.INFO)
        
        # æ€§èƒ½æ—¥å¿—è®°å½•å™¨ / Performance logger
        self.perf_logger = logging.getLogger('hook_performance')
        self.perf_logger.setLevel(logging.INFO)
        
        # é”™è¯¯æ—¥å¿—è®°å½•å™¨ / Error logger
        self.error_logger = logging.getLogger('hook_errors')
        self.error_logger.setLevel(logging.ERROR)
        
        # é…ç½®æ–‡ä»¶å¤„ç†å™¨ / Configure file handlers
        main_handler = logging.FileHandler(self.log_dir / 'hooks.log')
        perf_handler = logging.FileHandler(self.log_dir / 'performance.log')
        error_handler = logging.FileHandler(self.log_dir / 'errors.log')
        
        # JSON æ ¼å¼åŒ–å™¨ / JSON formatter
        formatter = logging.Formatter('%(message)s')
        
        for handler in [main_handler, perf_handler, error_handler]:
            handler.setFormatter(formatter)
        
        self.main_logger.addHandler(main_handler)
        self.perf_logger.addHandler(perf_handler)
        self.error_logger.addHandler(error_handler)
    
    def log_hook_execution(self, hook_name: str, event_data: Dict[str, Any], 
                          execution_time: Optional[float] = None, 
                          status: str = 'success', error: Optional[str] = None):
        """è®°å½• Hook æ‰§è¡Œä¿¡æ¯"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'hook_name': hook_name,
            'status': status,
            'event_data': event_data,
            'execution_time_ms': execution_time,
            'error': error
        }
        
        # ä¸»æ—¥å¿—è®°å½• / Main log record
        self.main_logger.info(json.dumps(log_entry))
        
        # æ€§èƒ½æ—¥å¿—è®°å½• / Performance log record
        if execution_time is not None:
            perf_entry = {
                'timestamp': datetime.now().isoformat(),
                'hook_name': hook_name,
                'execution_time_ms': execution_time,
                'performance_category': self._categorize_performance(execution_time)
            }
            self.perf_logger.info(json.dumps(perf_entry))
        
        # é”™è¯¯æ—¥å¿—è®°å½• / Error log record
        if error:
            error_entry = {
                'timestamp': datetime.now().isoformat(),
                'hook_name': hook_name,
                'error': error,
                'event_data': event_data
            }
            self.error_logger.error(json.dumps(error_entry))
    
    def _categorize_performance(self, execution_time: float) -> str:
        """æ€§èƒ½åˆ†ç±»"""
        if execution_time < 100:
            return 'fast'
        elif execution_time < 1000:
            return 'normal'
        elif execution_time < 5000:
            return 'slow'
        else:
            return 'very_slow'
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½å’Œä½¿ç”¨æŠ¥å‘Š"""
        report = {
            'generated_at': datetime.now().isoformat(),
            'hook_statistics': self._analyze_hook_usage(),
            'performance_statistics': self._analyze_performance(),
            'error_statistics': self._analyze_errors()
        }
        
        # ä¿å­˜æŠ¥å‘Š / Save report
        report_file = self.log_dir / f'report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        return report
    
    def _analyze_hook_usage(self) -> Dict[str, Any]:
        """åˆ†æ Hook ä½¿ç”¨æƒ…å†µ"""
        hook_counts = {}
        success_counts = {}
        
        try:
            with open(self.log_dir / 'hooks.log', 'r') as f:
                for line in f:
                    try:
                        entry = json.loads(line.strip())
                        hook_name = entry.get('hook_name', 'unknown')
                        status = entry.get('status', 'unknown')
                        
                        hook_counts[hook_name] = hook_counts.get(hook_name, 0) + 1
                        if status == 'success':
                            success_counts[hook_name] = success_counts.get(hook_name, 0) + 1
                    except json.JSONDecodeError:
                        continue
        except FileNotFoundError:
            pass
        
        return {
            'total_executions': sum(hook_counts.values()),
            'hook_counts': hook_counts,
            'success_rates': {
                hook: (success_counts.get(hook, 0) / count * 100)
                for hook, count in hook_counts.items()
            }
        }
    
    def _analyze_performance(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½ç»Ÿè®¡"""
        performance_data = {}
        
        try:
            with open(self.log_dir / 'performance.log', 'r') as f:
                for line in f:
                    try:
                        entry = json.loads(line.strip())
                        hook_name = entry.get('hook_name', 'unknown')
                        exec_time = entry.get('execution_time_ms', 0)
                        
                        if hook_name not in performance_data:
                            performance_data[hook_name] = []
                        performance_data[hook_name].append(exec_time)
                    except json.JSONDecodeError:
                        continue
        except FileNotFoundError:
            pass
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡ / Calculate statistics
        statistics = {}
        for hook_name, times in performance_data.items():
            if times:
                statistics[hook_name] = {
                    'avg_time': sum(times) / len(times),
                    'min_time': min(times),
                    'max_time': max(times),
                    'total_executions': len(times)
                }
        
        return statistics
    
    def _analyze_errors(self) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯ç»Ÿè®¡"""
        error_counts = {}
        
        try:
            with open(self.log_dir / 'errors.log', 'r') as f:
                for line in f:
                    try:
                        entry = json.loads(line.strip())
                        hook_name = entry.get('hook_name', 'unknown')
                        error_counts[hook_name] = error_counts.get(hook_name, 0) + 1
                    except json.JSONDecodeError:
                        continue
        except FileNotFoundError:
            pass
        
        return {
            'total_errors': sum(error_counts.values()),
            'error_counts': error_counts
        }

# å‘½ä»¤è¡Œæ¥å£ / Command line interface
if __name__ == '__main__':
    logger = HookLogger()
    
    if len(sys.argv) > 1 and sys.argv[1] == 'report':
        report = logger.generate_report()
        print(json.dumps(report, indent=2))
    else:
        # ç¤ºä¾‹æ—¥å¿—è®°å½• / Example logging
        logger.log_hook_execution(
            hook_name='example-hook',
            event_data={'file': 'test.py', 'action': 'edit'},
            execution_time=150.5,
            status='success'
        )
        print("âœ… æ—¥å¿—è®°å½•å®Œæˆ")
```

### 2. Hook æ€§èƒ½ä¼˜åŒ– / Hook Performance Optimization

#### æ‰¹é‡å¤„ç†ä¼˜åŒ– / Batch Processing Optimization
```bash
#!/bin/bash
# hooks/batch-processor.sh - Hook æ‰¹é‡å¤„ç†ä¼˜åŒ–å™¨

set -euo pipefail

BATCH_FILE="/tmp/claude-hook-batch.txt"
BATCH_TIMEOUT=5  # 5ç§’æ‰¹é‡è¶…æ—¶
MAX_BATCH_SIZE=10

# åˆå§‹åŒ–æ‰¹é‡æ–‡ä»¶ / Initialize batch file
if [ ! -f "$BATCH_FILE" ]; then
    touch "$BATCH_FILE"
fi

# æ·»åŠ ä»»åŠ¡åˆ°æ‰¹é‡é˜Ÿåˆ— / Add task to batch queue
add_to_batch() {
    local hook_name="$1"
    local event_data="$2"
    
    echo "$(date +%s)|$hook_name|$event_data" >> "$BATCH_FILE"
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹é‡é˜ˆå€¼ / Check if batch threshold reached
    local batch_size=$(wc -l < "$BATCH_FILE")
    if [ "$batch_size" -ge "$MAX_BATCH_SIZE" ]; then
        process_batch
    fi
}

# å¤„ç†æ‰¹é‡ä»»åŠ¡ / Process batch tasks
process_batch() {
    if [ ! -s "$BATCH_FILE" ]; then
        return 0
    fi
    
    echo "ğŸ”„ å¤„ç†æ‰¹é‡ Hook ä»»åŠ¡..." >&2
    
    local temp_file="/tmp/claude-hook-batch-processing.txt"
    mv "$BATCH_FILE" "$temp_file"
    touch "$BATCH_FILE"
    
    # å¹¶è¡Œå¤„ç†æ‰¹é‡ä»»åŠ¡ / Process batch tasks in parallel
    while IFS='|' read -r timestamp hook_name event_data; do
        (
            echo "æ‰§è¡Œ Hook: $hook_name" >&2
            # è¿™é‡Œæ‰§è¡Œå®é™…çš„ Hook é€»è¾‘
            # Execute actual Hook logic here
        ) &
    done < "$temp_file"
    
    # ç­‰å¾…æ‰€æœ‰åå°ä»»åŠ¡å®Œæˆ / Wait for all background tasks
    wait
    
    rm -f "$temp_file"
    echo "âœ… æ‰¹é‡å¤„ç†å®Œæˆ" >&2
}

# å®šæ—¶æ‰¹é‡å¤„ç† / Timed batch processing
start_batch_timer() {
    (
        while true; do
            sleep "$BATCH_TIMEOUT"
            if [ -s "$BATCH_FILE" ]; then
                process_batch
            fi
        done
    ) &
    
    echo $! > "/tmp/claude-hook-batch-timer.pid"
}

# åœæ­¢æ‰¹é‡è®¡æ—¶å™¨ / Stop batch timer
stop_batch_timer() {
    if [ -f "/tmp/claude-hook-batch-timer.pid" ]; then
        local timer_pid=$(cat "/tmp/claude-hook-batch-timer.pid")
        if kill -0 "$timer_pid" 2>/dev/null; then
            kill "$timer_pid"
        fi
        rm -f "/tmp/claude-hook-batch-timer.pid"
    fi
}

# å‘½ä»¤è¡Œæ¥å£ / Command line interface
case "${1:-}" in
    "add")
        add_to_batch "$2" "$3"
        ;;
    "process")
        process_batch
        ;;
    "start-timer")
        start_batch_timer
        echo "â±ï¸  æ‰¹é‡è®¡æ—¶å™¨å·²å¯åŠ¨"
        ;;
    "stop-timer")
        stop_batch_timer
        echo "â¹ï¸  æ‰¹é‡è®¡æ—¶å™¨å·²åœæ­¢"
        ;;
    *)
        echo "ä½¿ç”¨æ–¹æ³•: $0 {add|process|start-timer|stop-timer} [å‚æ•°...]"
        exit 1
        ;;
esac
```

## æœ€ä½³å®è·µæ€»ç»“ / Best Practices Summary

### 1. Hook è®¾è®¡åŸåˆ™ / Hook Design Principles
- **è½»é‡åŒ–**: Hook åº”ä¿æŒè½»é‡ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹
- **å¹‚ç­‰æ€§**: å¤šæ¬¡æ‰§è¡ŒåŒä¸€ Hook åº”äº§ç”Ÿç›¸åŒç»“æœ
- **é”™è¯¯å¤„ç†**: ä¼˜é›…å¤„ç†é”™è¯¯ï¼Œä¸å½±å“ä¸»è¦åŠŸèƒ½
- **æ—¥å¿—è®°å½•**: è¯¦ç»†è®°å½•æ‰§è¡Œè¿‡ç¨‹ä¾¿äºè°ƒè¯•

### 2. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ / Performance Optimization Strategies
- **å¼‚æ­¥æ‰§è¡Œ**: éå…³é”® Hook ä½¿ç”¨åå°æ‰§è¡Œ
- **æ‰¹é‡å¤„ç†**: åˆå¹¶ç›¸ä¼¼æ“ä½œå‡å°‘å¼€é”€
- **æ™ºèƒ½ç¼“å­˜**: ç¼“å­˜é‡å¤è®¡ç®—ç»“æœ
- **èµ„æºç®¡ç†**: åˆç†ç®¡ç†ç³»ç»Ÿèµ„æºä½¿ç”¨

### 3. å®‰å…¨è€ƒè™‘ / Security Considerations
- **æƒé™æ§åˆ¶**: é™åˆ¶ Hook çš„æ–‡ä»¶ç³»ç»Ÿè®¿é—®æƒé™
- **è¾“å…¥éªŒè¯**: éªŒè¯æ‰€æœ‰å¤–éƒ¨è¾“å…¥å‚æ•°
- **å®‰å…¨å®¡è®¡**: å®šæœŸå®¡è®¡ Hook è„šæœ¬å®‰å…¨æ€§
- **æ•æ„Ÿä¿¡æ¯**: é¿å…åœ¨æ—¥å¿—ä¸­è®°å½•æ•æ„Ÿä¿¡æ¯

---

## ç›¸å…³èµ„æº / Related Resources
- [Claude Code Hooks å®˜æ–¹æ–‡æ¡£](https://docs.anthropic.com/en/docs/claude-code/hooks)
- [Hook è„šæœ¬ç¤ºä¾‹é›†åˆ](https://github.com/hesreallyhim/awesome-claude-code/tree/main/hooks)
- [è‡ªåŠ¨åŒ–æœ€ä½³å®è·µ](https://github.com/community/automation-best-practices)