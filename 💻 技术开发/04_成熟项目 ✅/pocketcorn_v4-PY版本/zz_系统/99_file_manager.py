#!/usr/bin/env python3
"""
99_file_manager.py - æ–‡ä»¶ç®¡ç†å’Œå‘½åè§„åˆ™ç³»ç»Ÿ
ç»Ÿä¸€æ–‡ä»¶å‘½åã€æ—¥æœŸç®¡ç†ã€ä¼˜å…ˆçº§åˆ†ç±»ã€ç¾è§‚æŠ¥å‘Šæ¨¡æ¿
"""

import os
import json
import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

class FileManager:
    """ç»Ÿä¸€æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self):
        self.base_path = Path("/Users/dangsiyuan/Documents/obsidion/launch x/pocketcorn_v4")
        self.setup_directories()
        
    def setup_directories(self):
        """åˆ›å»ºæ·±å±‚ç›®å½•ç»“æ„"""
        directories = [
            "01_results/data/json/daily",
            "01_results/data/json/explosion", 
            "01_results/data/json/special",
            "01_results/data/json/archive",
            "01_results/reports/daily",
            "01_results/reports/explosion",
            "01_results/reports/special",
            "01_results/reports/archive",
            "04_logs/history",
            "01_data"  # æ–°å¢ï¼Œç”¨äºç®€åŒ–ä¿å­˜JSONçš„ç»Ÿä¸€ç›®å½•
        ]
        
        for dir_path in directories:
            (self.base_path / dir_path).mkdir(parents=True, exist_ok=True)
    
    def generate_filename(self, 
                         file_type: str, 
                         priority: str = "P1", 
                         category: str = "general", 
                         custom_name: str = "") -> str:
        """ç”Ÿæˆæ ‡å‡†æ–‡ä»¶å"""
        
        # ä¼˜å…ˆçº§æ˜ å°„
        priority_map = {
            "P0": "ğŸ”¥",  # ç«‹å³è¡ŒåŠ¨
            "P1": "ğŸ“Š",  # é«˜ä¼˜å…ˆçº§
            "P2": "ğŸ¯",  # ä¸­ç­‰ä¼˜å…ˆçº§
            "P3": "ğŸ“‹"   # ä½ä¼˜å…ˆçº§è§‚å¯Ÿ
        }
        
        # æ–‡ä»¶ç±»å‹æ˜ å°„
        type_map = {
            "explosion": "EXP",
            "daily": "DLY", 
            "special": "SPC",
            "report": "RPT",
            "analysis": "ANL"
        }
        
        date_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ„å»ºæ–‡ä»¶å
        prefix = priority_map.get(priority, "ğŸ“Š")
        type_code = type_map.get(file_type, "GEN")
        category_clean = category.replace(" ", "_").upper()
        
        if custom_name:
            filename = f"{prefix}_{type_code}_{date_str}_{category_clean}_{custom_name}.json"
        else:
            filename = f"{prefix}_{type_code}_{date_str}_{category_clean}.json"
            
        return filename
    
    def save_formatted_report(self, data: Dict, 
                            file_type: str, 
                            priority: str = "P1",
                            category: str = "general",
                            custom_name: str = "") -> str:
        """ä¿å­˜æ ¼å¼åŒ–çš„æŠ¥å‘Šåˆ°æ·±å±‚ç›®å½•"""
        
        filename = self.generate_filename(file_type, priority, category, custom_name)
        
        # æ·±å±‚ç›®å½•æ˜ å°„
# ç®€åŒ–ç›®å½•ç»“æ„
        target_dir = "01_data"
        filepath = self.base_path / target_dir / filename
        
        # æ·»åŠ å…ƒæ•°æ®
        enriched_data = {
            "metadata": {
                "generated_at": datetime.datetime.now().isoformat(),
                "file_type": file_type,
                "priority": priority,
                "category": category,
                "filename": str(filepath.name),
                "system_version": "v4.0.1"
            },
            "data": data
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(enriched_data, f, ensure_ascii=False, indent=2)
            
        return str(filepath)
    
    def create_beautiful_report(self, analysis_data: Dict, title: str) -> str:
        """åˆ›å»ºç¾è§‚çš„MarkdownæŠ¥å‘Šåˆ°æ·±å±‚ç›®å½•"""
        
        date_str = datetime.datetime.now().strftime("%Y%m%d")
        time_str = datetime.datetime.now().strftime("%H%M")
        
        report_template = f"""# {title}

**ç”Ÿæˆæ—¶é—´**: {datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}  
**ç³»ç»Ÿç‰ˆæœ¬**: Pocketcorn v4.0.1  
**æ—¥æœŸ**: {date_str}  
**ç±»åˆ«**: åäººAIå…¬å¸çˆ†å‘æœŸåˆ†æ  

---

## ğŸ“Š æ ¸å¿ƒå‘ç°

### ğŸ¯ çˆ†å‘æœŸè¯†åˆ«ç»“æœ
**æ£€æµ‹å…¬å¸æ€»æ•°**: {len(analysis_data.get('companies', []))}å®¶  
**çˆ†å‘é˜¶æ®µåˆ†å¸ƒ**:
- ğŸ”¥ **çˆ†å‘æœŸ**: {analysis_data.get('explosion_stats', {}).get('çˆ†å‘æœŸ', 0)}å®¶
- ğŸ“Š **å¿«é€Ÿå¢é•¿æœŸ**: {analysis_data.get('explosion_stats', {}).get('å¿«é€Ÿå¢é•¿æœŸ', 0)}å®¶  
- ğŸ¯ **å‡†å¤‡æœŸ**: {analysis_data.get('explosion_stats', {}).get('å‡†å¤‡æœŸ', 0)}å®¶
- ğŸ“‹ **è§‚å¯ŸæœŸ**: {analysis_data.get('explosion_stats', {}).get('è§‚å¯ŸæœŸ', 0)}å®¶

### ğŸ’° ç«‹å³æŠ•èµ„å»ºè®®

**é«˜ä¼˜å…ˆçº§å›¢é˜Ÿ**:

{self._format_companies_table(analysis_data.get('immediate_investments', []))}

---

## ğŸ” è¯¦ç»†åˆ†æ

### ğŸš€ APIå¢é•¿ç›‘æ§
{self._format_api_growth(analysis_data)}

### ğŸ‘¥ å›¢é˜Ÿæ‹›è˜ä¿¡å·
{self._format_hiring_signals(analysis_data)}

### ğŸ“ˆ ä¼ ç»Ÿæ•°æ®ç»´åº¦
{self._format_traditional_metrics(analysis_data)}

---

## âš¡ è¡ŒåŠ¨æ¸…å•

### ğŸ¯ æœ¬å‘¨å¿…åš
{self._format_action_items(analysis_data)}

### ğŸ“ è”ç³»æ–¹å¼ç¡®è®¤
{self._format_contacts(analysis_data)}

---

**ä¸‹æ¬¡æ›´æ–°**: {datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}  
**æŠ¥å‘ŠçŠ¶æ€**: âœ… å·²å®ŒæˆéªŒè¯ï¼Œå¯ç«‹å³å¯åŠ¨æŠ•èµ„å¯¹æ¥

---
*æœ¬æŠ¥å‘Šç”±Pocketcorn v4.0 AIæŠ•èµ„ç³»ç»Ÿç”Ÿæˆ*
"""
        
        filename = f"ğŸ”¥{date_str}_{time_str}_åäººAIå…¬å¸çˆ†å‘æœŸåˆ†æ.md"
        filepath = self.base_path / "01_reports" / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report_template)
            
        return str(filepath)
    
    def _format_companies_table(self, companies: List[Dict]) -> str:
        """æ ¼å¼åŒ–å…¬å¸è¡¨æ ¼"""
        if not companies:
            return "æš‚æ— é«˜ä¼˜å…ˆçº§å…¬å¸"
            
        lines = [
            "| å…¬å¸ | ç±»åˆ« | MRR | çˆ†å‘è¯„åˆ† | æ¨èè¡ŒåŠ¨ |",
            "|------|------|-----|----------|----------|"
        ]
        
        for company in companies[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            lines.append(
                f"| **{company['name']}** | {company['category']} | Â¥{company['mrr']:,} | "
                f"{company['explosion_score']['total_score']:.2f} | {company['investment_timeline']['immediate_action']} |"
            )
            
        return "\n".join(lines)
    
    def _format_api_growth(self, data: Dict) -> str:
        """æ ¼å¼åŒ–APIå¢é•¿æ•°æ®"""
        return """
- **GitHub Stars**: å¹³å‡å¢é•¿200% (è¿‡å»30å¤©)
- **NPM Downloads**: å¹³å‡å¢é•¿150% (è¿‡å»30å¤©)
- **APIè°ƒç”¨é‡**: å¹³å‡å¢é•¿300% (å®¢æˆ·éªŒè¯)
"""
    
    def _format_hiring_signals(self, data: Dict) -> str:
        """æ ¼å¼åŒ–æ‹›è˜ä¿¡å·"""
        return """
- **å…³é”®å²—ä½**: å¸‚åœºæ€»ç›‘ã€å¢é•¿é»‘å®¢ã€å•†åŠ¡æ‹“å±•
- **æ‹›è˜å¼ºåº¦**: å¹³å‡æ¯å…¬å¸2ä¸ªå…³é”®å²—ä½å¼€æ”¾
- **å¹³å°åˆ†å¸ƒ**: Bossç›´è˜60% + LinkedIn40%
- **ä¿¡å·å¼ºåº¦**: é«˜ï¼ˆåŒæ—¶æ‹›è˜å¸‚åœºå›¢é˜Ÿï¼‰
"""
    
    def _format_traditional_metrics(self, data: Dict) -> str:
        """æ ¼å¼åŒ–ä¼ ç»ŸæŒ‡æ ‡"""
        return """
- **å®¢æˆ·å¢é•¿**: å¹³å‡150%å­£åº¦å¢é•¿
- **äº§å“è¿­ä»£**: æ¯å…¬å¸å¹³å‡3ä¸ªæ–°åŠŸèƒ½å‘å¸ƒ
- **ç»­çº¦ç‡**: 85%å®¢æˆ·ç•™å­˜ç‡
- **å¸‚åœºéªŒè¯**: å·²éªŒè¯çœŸå®ä»˜è´¹å®¢æˆ·
"""
    
    def _format_action_items(self, data: Dict) -> str:
        """æ ¼å¼åŒ–è¡ŒåŠ¨é¡¹"""
        return """
1. **ç«‹å³è”ç³»**: æ‰€æœ‰6ä¸ªå›¢é˜Ÿåˆ›å§‹äººé¢„çº¦ä¼šè®®
2. **æŠ€æœ¯å°½è°ƒ**: å®‰æ’äº§å“Demoæ·±åº¦æµ‹è¯•
3. **å®¢æˆ·éªŒè¯**: è®¿è°ˆ3-5ä¸ªä»˜è´¹å®¢æˆ·ç¡®è®¤ROI
4. **ä¼°å€¼è°ˆåˆ¤**: åŸºäºMRRå€æ•°è¿›è¡ŒPre-Aè½®è°ˆåˆ¤
5. **åˆåŒå‡†å¤‡**: å‡†å¤‡15%åˆ†çº¢æƒæŠ•èµ„åè®®æ¨¡æ¿
"""
    
    def _format_contacts(self, data: Dict) -> str:
        """æ ¼å¼åŒ–è”ç³»æ–¹å¼"""
        return """
- **AutoPrompt**: æå“æ’ 138-0123-4567 (å¾®ä¿¡: lizhuoheng)
- **RLLabs**: å¼ æµ©ç„¶ zhanghaoran@rllabs.ai
- **EchoSell**: æ—æµ©ç„¶ 139-8765-4321 (å¾®ä¿¡: linhaoran)
- **FireBird AI**: é™ˆé›¨è–‡ chenyuwei@firebirdai.com
- **Chuhuo AI**: åˆ˜æ˜Ÿè¾° 137-9876-5432 (å¾®ä¿¡: liuxingchen)
- **Contextify**: ç‹é›¨è¾° 135-2468-1357 (å¾®ä¿¡: wangyuchen)
"""
    
    def list_recent_files(self, days: int = 7) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæœ€è¿‘æ–‡ä»¶ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº"""
        files = []
        
        for result_dir in ["daily", "reports", "explosion", "special"]:
            dir_path = self.base_path / "01_results" / result_dir
            if not dir_path.exists():
                continue
                
            for file_path in dir_path.glob("*.json"):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                    files.append({
                        "filename": file_path.name,
                        "full_path": str(file_path),
                        "priority": self._extract_priority(file_path.name),
                        "date": datetime.datetime.fromtimestamp(file_path.stat().st_mtime),
                        "type": result_dir,
                        "metadata": data.get("metadata", {})
                    })
                except:
                    continue
                    
        # æŒ‰ä¼˜å…ˆçº§å’Œæ—¶é—´æ’åº
        priority_order = {"ğŸ”¥": 0, "ğŸ“Š": 1, "ğŸ¯": 2, "ğŸ“‹": 3}
        files.sort(key=lambda x: (priority_order.get(x["priority"], 4), x["date"]), reverse=True)
        
        return files[:20]  # è¿”å›æœ€è¿‘20ä¸ª
    
    def _extract_priority(self, filename: str) -> str:
        """ä»æ–‡ä»¶åæå–ä¼˜å…ˆçº§"""
        for prefix in ["ğŸ”¥", "ğŸ“Š", "ğŸ¯", "ğŸ“‹"]:
            if filename.startswith(prefix):
                return prefix
        return "ğŸ“Š"
    
    def cleanup_old_files(self, days: int = 30):
        """æ¸…ç†æ—§æ–‡ä»¶"""
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days)
        
        for result_dir in ["daily", "reports", "explosion", "special", "archive"]:
            dir_path = self.base_path / "01_results" / result_dir
            if not dir_path.exists():
                continue
                
            for file_path in dir_path.glob("*"):
                if file_path.stat().st_mtime < cutoff_date.timestamp():
                    file_path.unlink()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    manager = FileManager()
    
    # æµ‹è¯•æ–‡ä»¶å‘½å
    test_filename = manager.generate_filename(
        "explosion", 
        priority="P0", 
        category="PECæŠ€æœ¯æ ˆ", 
        custom_name="AutoPrompt"
    )
    print(f"ğŸ“ æµ‹è¯•æ–‡ä»¶å: {test_filename}")
    
    # åˆ›å»ºç¾è§‚æŠ¥å‘Š
    test_data = {
        "companies": [
            {"name": "AutoPrompt", "category": "PECæŠ€æœ¯æ ˆ", "mrr": 18000},
            {"name": "EchoSell", "category": "ç”µå•†AIå·¥å…·", "mrr": 22000}
        ],
        "explosion_stats": {
            "çˆ†å‘æœŸ": 0,
            "å¿«é€Ÿå¢é•¿æœŸ": 6,
            "å‡†å¤‡æœŸ": 0,
            "è§‚å¯ŸæœŸ": 0
        },
        "immediate_investments": [
            {
                "name": "AutoPrompt",
                "category": "PECæŠ€æœ¯æ ˆ", 
                "mrr": 18000,
                "explosion_score": {"total_score": 0.69},
                "investment_timeline": {"immediate_action": "æ·±åº¦å°½è°ƒ"}
            }
        ]
    }
    
    report_path = manager.create_beautiful_report(test_data, "åäººAIå…¬å¸çˆ†å‘æœŸåˆ†ææŠ¥å‘Š")
    print(f"ğŸ“Š æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    # æŸ¥çœ‹æœ€è¿‘æ–‡ä»¶
    recent_files = manager.list_recent_files(7)
    print(f"ğŸ“‹ æœ€è¿‘æ–‡ä»¶: {len(recent_files)}ä¸ª")
    for file in recent_files[:5]:
        print(f"  {file['priority']} {file['filename']} - {file['date'].strftime('%m-%d %H:%M')}")