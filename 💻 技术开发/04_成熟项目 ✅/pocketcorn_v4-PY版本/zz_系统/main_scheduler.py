#!/usr/bin/env python3
"""
main_scheduler.py - ä¸»ç¨‹åºè°ƒåº¦åˆ†é…ç³»ç»Ÿ
ç»Ÿä¸€è°ƒåº¦æ‰€æœ‰æ¨¡å—ï¼Œç®¡ç†æ–‡ä»¶å‘½åï¼Œç”Ÿæˆç¾è§‚æŠ¥å‘Š
"""

import os
import sys
import json
import datetime
import subprocess
from pathlib import Path
from typing import Dict, List, Any

import importlib.util

# åŠ¨æ€å¯¼å…¥æ¨¡å—
fm_spec = importlib.util.spec_from_file_location("file_manager", os.path.join(os.path.dirname(__file__), "99_file_manager.py"))
rt_spec = importlib.util.spec_from_file_location("report_templates", os.path.join(os.path.dirname(__file__), "report_templates.py"))
tr_spec = importlib.util.spec_from_file_location("tool_registry", os.path.join(os.path.dirname(__file__), "tool_registry.py"))

fm_module = importlib.util.module_from_spec(fm_spec)
rt_module = importlib.util.module_from_spec(rt_spec)
tr_module = importlib.util.module_from_spec(tr_spec)

fm_spec.loader.exec_module(fm_module)
rt_spec.loader.exec_module(rt_module)
tr_spec.loader.exec_module(tr_module)

FileManager = fm_module.FileManager
ReportTemplates = rt_module.ReportTemplates
get_tool_registry = tr_module.get_tool_registry

class MainScheduler:
    """ä¸»ç¨‹åºè°ƒåº¦å™¨"""
    
    def __init__(self):
        self.base_path = Path("/Users/dangsiyuan/Documents/obsidion/launch x/pocketcorn_v4")
        self.file_manager = FileManager()
        self.templates = ReportTemplates()
        self.setup_logging()
        self.registry = get_tool_registry(self.base_path)
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = self.base_path / "04_logs"
        log_dir.mkdir(exist_ok=True)
        
    def run_daily_analysis(self):
        """è¿è¡Œæ¯æ—¥åˆ†æ"""
        print("ğŸš€ å¯åŠ¨æ¯æ—¥AIé¡¹ç›®å‘ç°ç³»ç»Ÿ...")
        
        # 1. è¿è¡Œçˆ†ç‚¸æœŸæ£€æµ‹ï¼ˆä¿æŒç°æœ‰æ¨¡æ‹Ÿé€»è¾‘ï¼‰
        explosion_results = self.run_explosion_detection()
        
        # 2. ç”Ÿæˆä¸“ä¸šæŠ¥å‘Š
        report_path = self.generate_daily_report(explosion_results)
        
        # 3. æ›´æ–°å†å²è®°å½•
        self.update_history_log(explosion_results)
        
        # 3.1 è¿­ä»£ä¼˜åŒ–æŠ¥å‘Šï¼ˆæ–°æ¥å…¥ï¼‰
        try:
            io_spec = importlib.util.spec_from_file_location(
                "iteration_optimizer", os.path.join(os.path.dirname(__file__), "09_iteration_optimizer.py")
            )
            io_module = importlib.util.module_from_spec(io_spec)
            io_spec.loader.exec_module(io_module)
            IterationOptimizer = io_module.IterationOptimizer
            optimizer = IterationOptimizer()
            iteration_report = optimizer.generate_iteration_report()
            self.file_manager.save_formatted_report(
                {"iteration_report": iteration_report},
                file_type="analysis",
                priority="P1",
                category="æ–¹æ³•è®ºè¿­ä»£",
                custom_name="iteration_optimizer"
            )
        except Exception as e:
            print(f"âš ï¸ è¿­ä»£ä¼˜åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        
        # 3.2 ä¸ç¡®å®šæ€§éªŒè¯ï¼ˆæ–°æ¥å…¥ï¼‰
        try:
            uv_spec = importlib.util.spec_from_file_location(
                "uncertainty_validator", os.path.join(os.path.dirname(__file__), "11_uncertainty_validator.py")
            )
            uv_module = importlib.util.module_from_spec(uv_spec)
            uv_spec.loader.exec_module(uv_module)
            UncertaintyValidatorV4 = uv_module.UncertaintyValidatorV4
            validator = UncertaintyValidatorV4()
            companies = explosion_results.get("immediate_investments", [])
            validations = []
            for c in companies[:5]:
                project = {
                    "name": c.get("name"),
                    "mrr": c.get("mrr", 0),
                    "growth_rate": 0.25,
                    "team_quality": 0.75,
                    "data_sources": []
                }
                validations.append(validator.validate_project(project))
            self.file_manager.save_formatted_report(
                {"validations": validations},
                file_type="analysis",
                priority="P1",
                category="ä¸ç¡®å®šæ€§éªŒè¯",
                custom_name="uncertainty_validation"
            )
        except Exception as e:
            print(f"âš ï¸ ä¸ç¡®å®šæ€§éªŒè¯å¤±è´¥: {e}")
        
        # 4. è¾“å‡ºæ€»ç»“
        self.print_summary(explosion_results, report_path)
        
    def run_explosion_detection(self) -> Dict[str, Any]:
        """è¿è¡Œçˆ†å‘æœŸæ£€æµ‹"""
        print("ğŸ” å¼€å§‹çˆ†å‘æœŸæ£€æµ‹...")
        try:
            companies = [
                {'name': 'AutoPrompt', 'category': 'PECæŠ€æœ¯æ ˆ', 'mrr': 18000},
                {'name': 'RLLabs', 'category': 'PECæŠ€æœ¯æ ˆ', 'mrr': 25000},
                {'name': 'Contextify', 'category': 'PECæŠ€æœ¯æ ˆ', 'mrr': 12000},
                {'name': 'EchoSell', 'category': 'ç”µå•†AIå·¥å…·', 'mrr': 22000},
                {'name': 'FireBird AI', 'category': 'ç”µå•†AIå·¥å…·', 'mrr': 16000},
                {'name': 'Chuhuo AI', 'category': 'ç”µå•†AIå·¥å…·', 'mrr': 15000}
            ]
            explosion_stats = {"çˆ†å‘æœŸ": 0, "å¿«é€Ÿå¢é•¿æœŸ": 6, "å‡†å¤‡æœŸ": 0, "è§‚å¯ŸæœŸ": 0}
            immediate_investments = [
                {
                    "name": company['name'],
                    "category": company['category'],
                    "mrr": company['mrr'],
                    "explosion_score": {"total_score": 0.69},
                    "investment_timeline": {"immediate_action": "æ·±åº¦å°½è°ƒ", "due_diligence": "2-3å‘¨", "term_sheet": "3-4å‘¨", "closing": "6-8å‘¨"}
                }
                for company in companies
            ]
            return {
                "companies": companies,
                "explosion_stats": explosion_stats,
                "immediate_investments": immediate_investments,
                "generated_at": datetime.datetime.now().isoformat()
            }
        except Exception as e:
            print(f"âŒ çˆ†å‘æœŸæ£€æµ‹å¤±è´¥: {e}")
            return {}
    
    def generate_daily_report(self, analysis_data: Dict[str, Any]) -> str:
        return self.file_manager.create_beautiful_report(analysis_data, title="åäººAIå…¬å¸çˆ†å‘æœŸåˆ†æ")

    def update_history_log(self, analysis_data: Dict[str, Any]):
        log_file = self.base_path / "04_logs" / "history.jsonl"
        with open(log_file, 'a', encoding='utf-8') as f:
            record = {"ts": datetime.datetime.now().isoformat(), "type": "daily", "data": analysis_data}
            f.write(json.dumps(record, ensure_ascii=False) + "\n")

    def print_summary(self, analysis_data: Dict[str, Any], report_path: str):
        print("\nâœ… ä»Šæ—¥åˆ†æå®Œæˆï¼")
        print(f"æŠ¥å‘Šè·¯å¾„: {report_path}")
        if analysis_data:
            print(f"ç«‹å³æŠ•èµ„å»ºè®®: {len(analysis_data.get('immediate_investments', []))} å®¶")

    def run_weekly_review(self):
        print("ğŸ“… å¯åŠ¨å‘¨åº¦å›é¡¾...")
        # ä¿æŒç°æœ‰ weekly ä¸­çš„å†å²å¯ŒåŒ–ä¸æƒé‡å†™å›é€»è¾‘ï¼ˆåœ¨ learn å‘½ä»¤ä¸­å·²æœ‰ï¼‰
        print("ï¼ˆå‘¨åº¦å›é¡¾å ä½ï¼Œå·²ç”± learn å‘½ä»¤æ‰¿è½½æ ¸å¿ƒåŠŸèƒ½ï¼‰")

    def cleanup_old_files(self, days: int = 30):
        print("ğŸ§¹ æ¸…ç†æ—§æ–‡ä»¶...")
        cutoff = datetime.datetime.now() - datetime.timedelta(days=days)
        data_dir = self.base_path / "01_results" / "data" / "json"
        if data_dir.exists():
            for sub in data_dir.rglob("*.json"):
                try:
                    ts = datetime.datetime.fromtimestamp(sub.stat().st_mtime)
                    if ts < cutoff:
                        sub.unlink()
                except Exception:
                    pass

    def list_recent_files(self) -> Dict[str, List[Dict[str, Any]]]:
        categories = {
            "daily_data": self.base_path / "01_results" / "data" / "json" / "daily",
            "explosion_data": self.base_path / "01_results" / "data" / "json" / "explosion",
            "special_data": self.base_path / "01_results" / "data" / "json" / "special",
            "reports_daily": self.base_path / "01_results" / "reports" / "daily",
            "reports_special": self.base_path / "01_results" / "reports" / "special",
        }
        result: Dict[str, List[Dict[str, Any]]] = {}
        for name, path in categories.items():
            files = []
            if path.exists():
                for fp in sorted(path.glob("*.json"), key=lambda p: p.stat().st_mtime, reverse=True)[:20]:
                    files.append({"filename": fp.name, "date": datetime.datetime.fromtimestamp(fp.stat().st_mtime)})
            result[name] = files
        return result

    def run_system_check(self):
        print("ğŸ”§ è¿è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")
        checks = {
            "æ–‡ä»¶ç³»ç»Ÿ": (self.base_path / "01_results").exists(),
            "é…ç½®æ–‡ä»¶": (self.base_path / "zz_é…ç½®").exists(),
            "æ—¥å¿—ç³»ç»Ÿ": (self.base_path / "04_logs").exists(),
            "æ ¸å¿ƒæ¨¡å—": (self.base_path / "zz_ç³»ç»Ÿ").exists(),
            "ä¸“é¡¹è¿½è¸ª": (self.base_path / "01_results" / "reports").exists()
        }
        print("\nğŸ“Š ç³»ç»Ÿå¥åº·çŠ¶æ€:")
        for check, status in checks.items():
            print(f"  âœ… {check}: {'æ­£å¸¸' if status else 'éœ€è¦ä¿®å¤'}")
        return all(checks.values())

# ä¸»ç¨‹åºå…¥å£

def main():
    scheduler = MainScheduler()
    if len(sys.argv) > 1:
        command = sys.argv[1]
        if command == "daily":
            scheduler.run_daily_analysis()
        elif command == "weekly":
            scheduler.run_weekly_review()
        elif command == "cleanup":
            scheduler.cleanup_old_files()
        elif command == "check":
            scheduler.run_system_check()
        elif command == "list":
            categorized = scheduler.list_recent_files()
            for category, files in categorized.items():
                print(f"\n{category}: {len(files)}ä¸ªæ–‡ä»¶")
        elif command == "special":
            print("ğŸ” å¯åŠ¨ä¸“é¡¹æœç´¢(PEC)...")
            registry = scheduler.registry
            result = registry.run_tool("special_search_pec", params={})
            if result.success:
                data = result.data
                print("JSON:", data.get("json_path"))
                print("MARKDOWN:", data.get("md_path"))
            else:
                print("âŒ ä¸“é¡¹æœç´¢å¤±è´¥:", result.error)
        elif command == "learn":
            print("ğŸ“š å¯åŠ¨å†å²å¯ŒåŒ–ä¸æƒé‡æ ¡å‡†...")
            try:
                he_spec = importlib.util.spec_from_file_location(
                    "history_enricher", os.path.join(os.path.dirname(__file__), "14_history_enricher.py")
                )
                he_module = importlib.util.module_from_spec(he_spec)
                he_spec.loader.exec_module(he_module)
                HistoryEnricher = he_module.HistoryEnricher
                enricher = HistoryEnricher()
                stats = enricher.scan_and_ingest()
                print(f"ğŸ—‚ï¸ å†å²å¯ŒåŒ–å®Œæˆ: æ‰«æ{stats['files_scanned']} | å†™å…¥{stats['files_ingested']}")

                we_spec = importlib.util.spec_from_file_location(
                    "weights", os.path.join(os.path.dirname(__file__), "03_enhanced_weights.py")
                )
                we_module = importlib.util.module_from_spec(we_spec)
                we_spec.loader.exec_module(we_module)
                DynamicWeightEngine = we_module.DynamicWeightEngine
                dwe = DynamicWeightEngine()
                new_weights = dwe.learn_from_history("../zz_æ•°æ®/history.db")
                cfg_path = scheduler.base_path / "zz_é…ç½®" / "02_weights_config.json"
                try:
                    with open(cfg_path, 'w', encoding='utf-8') as f:
                        json.dump(new_weights, f, ensure_ascii=False, indent=2)
                    print("âš–ï¸ åŠ¨æ€æƒé‡å·²åŸºäºå†å²æ•°æ®å†æ ¡å‡†")
                except Exception as e:
                    print(f"âš ï¸ å†™å…¥æƒé‡å¤±è´¥: {e}")
            except Exception as e:
                print(f"âš ï¸ å†å²å¯ŒåŒ–ä¸æƒé‡æ ¡å‡†å¤±è´¥: {e}")
        else:
            print(
                """
ğŸ“‹ Pocketcorn v4.0 ä¸»ç¨‹åºè°ƒåº¦ç³»ç»Ÿ

ä½¿ç”¨æ–¹æ³•:
  python main_scheduler.py daily     - è¿è¡Œæ¯æ—¥åˆ†æ
  python main_scheduler.py weekly    - è¿è¡Œå‘¨åº¦å›é¡¾
  python main_scheduler.py cleanup   - æ¸…ç†æ—§æ–‡ä»¶
  python main_scheduler.py check     - ç³»ç»Ÿå¥åº·æ£€æŸ¥
  python main_scheduler.py list      - åˆ—å‡ºæœ€è¿‘æ–‡ä»¶
  python main_scheduler.py special   - å¯åŠ¨ä¸“é¡¹æœç´¢
  python main_scheduler.py learn     - å¯åŠ¨å†å²å¯ŒåŒ–ä¸æƒé‡æ ¡å‡†
                """
            )
    else:
        scheduler.run_daily_analysis()

if __name__ == "__main__":
    main()