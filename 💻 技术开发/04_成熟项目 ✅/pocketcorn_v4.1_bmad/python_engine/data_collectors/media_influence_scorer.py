#!/usr/bin/env python3
"""
PocketCorn v4.1 åª’ä½“å½±å“åŠ›è¯„åˆ†å¼•æ“
åŸºäºå¢å¼ºç‰ˆä¼ä¸šç”»åƒçš„åª’ä½“å½±å“åŠ›å’Œäº§å“åˆ†å‘èƒ½åŠ›è¯„åˆ†ç³»ç»Ÿ

æ ¸å¿ƒåŠŸèƒ½:
1. æŠ€æœ¯å£°æœ›è¯„åˆ† (30åˆ†)
2. äº§å“ä¼ æ’­åŠ›è¯„åˆ† (35åˆ†)  
3. åˆ›å§‹äººå½±å“åŠ›è¯„åˆ† (20åˆ†)
4. ç”Ÿæ€å½±å“åŠ›è¯„åˆ† (15åˆ†)

æ€»åˆ†100åˆ†çš„åª’ä½“å½±å“åŠ›ç»¼åˆè¯„åˆ†
"""

import asyncio
import aiohttp
import json
import logging
import re
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import requests
from urllib.parse import urlparse, quote
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MediaInfluenceScore:
    """åª’ä½“å½±å“åŠ›è¯„åˆ†æ•°æ®ç»“æ„"""
    company_name: str
    
    # å››å¤§ç»´åº¦è¯„åˆ†
    technical_reputation: float = 0.0    # æŠ€æœ¯å£°æœ› (0-30åˆ†)
    product_virality: float = 0.0        # äº§å“ä¼ æ’­åŠ› (0-35åˆ†)
    founder_influence: float = 0.0       # åˆ›å§‹äººå½±å“åŠ› (0-20åˆ†)
    ecosystem_impact: float = 0.0        # ç”Ÿæ€å½±å“åŠ› (0-15åˆ†)
    
    # ç»¼åˆè¯„åˆ†
    total_score: float = 0.0             # æ€»åˆ† (0-100åˆ†)
    influence_level: str = "ä½"          # å½±å“åŠ›ç­‰çº§
    
    # è¯¦ç»†æŒ‡æ ‡
    github_stars: int = 0
    arxiv_papers: int = 0
    conference_papers: int = 0
    social_mentions: int = 0
    founder_followers: int = 0
    media_coverage: int = 0
    
    # æ—¶é—´æˆ³
    scored_at: datetime = datetime.now()

class MediaInfluenceScorer:
    """åª’ä½“å½±å“åŠ›è¯„åˆ†å¼•æ“"""
    
    def __init__(self):
        self.github_api_base = "https://api.github.com"
        self.arxiv_api_base = "http://export.arxiv.org/api/query"
        self.tavily_api_key = "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"
        
        # APIé™åˆ¶å’Œç¼“å­˜
        self.rate_limits = {
            'github': {'calls': 0, 'reset_time': time.time()},
            'arxiv': {'calls': 0, 'reset_time': time.time()},
            'tavily': {'calls': 0, 'reset_time': time.time()}
        }
        
        logger.info("ğŸ¯ MediaInfluenceScorer initialized")

    async def score_company(self, company_name: str, website: Optional[str] = None, 
                           founder_name: Optional[str] = None) -> MediaInfluenceScore:
        """
        è®¡ç®—ä¼ä¸šçš„ç»¼åˆåª’ä½“å½±å“åŠ›è¯„åˆ†
        
        Args:
            company_name: å…¬å¸åç§°
            website: å…¬å¸å®˜ç½‘ (å¯é€‰)
            founder_name: åˆ›å§‹äººå§“å (å¯é€‰)
        
        Returns:
            MediaInfluenceScore: åª’ä½“å½±å“åŠ›è¯„åˆ†ç»“æœ
        """
        logger.info(f"ğŸ” å¼€å§‹è¯„åˆ†ä¼ä¸šåª’ä½“å½±å“åŠ›: {company_name}")
        
        score = MediaInfluenceScore(company_name=company_name)
        
        try:
            # å¹¶å‘è·å–å„ä¸ªç»´åº¦çš„è¯„åˆ†
            tasks = [
                self._score_technical_reputation(company_name, website),
                self._score_product_virality(company_name, website),  
                self._score_founder_influence(founder_name or company_name),
                self._score_ecosystem_impact(company_name, website)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†è¯„åˆ†ç»“æœ
            if not isinstance(results[0], Exception):
                score.technical_reputation = results[0]
            if not isinstance(results[1], Exception):
                score.product_virality = results[1]
            if not isinstance(results[2], Exception):
                score.founder_influence = results[2]
            if not isinstance(results[3], Exception):
                score.ecosystem_impact = results[3]
            
            # è®¡ç®—æ€»åˆ†å’Œç­‰çº§
            score.total_score = (
                score.technical_reputation + 
                score.product_virality + 
                score.founder_influence + 
                score.ecosystem_impact
            )
            
            score.influence_level = self._get_influence_level(score.total_score)
            
            logger.info(f"âœ… åª’ä½“å½±å“åŠ›è¯„åˆ†å®Œæˆ: {company_name} = {score.total_score:.1f}åˆ† ({score.influence_level})")
            
            return score
            
        except Exception as e:
            logger.error(f"âŒ åª’ä½“å½±å“åŠ›è¯„åˆ†å¤±è´¥: {company_name} - {str(e)}")
            return score

    async def _score_technical_reputation(self, company_name: str, website: Optional[str]) -> float:
        """è¯„ä¼°æŠ€æœ¯å£°æœ› (0-30åˆ†)"""
        score = 0.0
        
        try:
            # æœç´¢GitHubé¡¹ç›® (0-15åˆ†)
            github_score = await self._search_github_projects(company_name)
            score += min(github_score, 15.0)
            
            # æœç´¢å­¦æœ¯è®ºæ–‡ (0-10åˆ†)
            paper_score = await self._search_academic_papers(company_name)
            score += min(paper_score, 10.0)
            
            # æŠ€æœ¯åšå®¢è´¨é‡ (0-5åˆ†)
            blog_score = await self._evaluate_tech_blog(website) if website else 0
            score += min(blog_score, 5.0)
            
            logger.info(f"ğŸ“š æŠ€æœ¯å£°æœ›è¯„åˆ†: {company_name} = {score:.1f}/30åˆ†")
            return score
            
        except Exception as e:
            logger.error(f"âŒ æŠ€æœ¯å£°æœ›è¯„åˆ†å¤±è´¥: {str(e)}")
            return 0.0

    async def _search_github_projects(self, company_name: str) -> float:
        """æœç´¢GitHubé¡¹ç›®å¹¶è¯„åˆ†"""
        try:
            # æœç´¢GitHubç»„ç»‡å’Œä»“åº“
            search_terms = [
                company_name,
                company_name.lower().replace(' ', ''),
                company_name.lower().replace(' ', '-')
            ]
            
            max_stars = 0
            total_repos = 0
            
            for term in search_terms:
                if await self._check_rate_limit('github'):
                    url = f"{self.github_api_base}/search/repositories"
                    params = {
                        'q': f"{term} in:name,description",
                        'sort': 'stars',
                        'order': 'desc',
                        'per_page': 10
                    }
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                for repo in data.get('items', []):
                                    stars = repo.get('stargazers_count', 0)
                                    max_stars = max(max_stars, stars)
                                    total_repos += 1
                
                await asyncio.sleep(0.5)  # APIé™åˆ¶
            
            # è¯„åˆ†é€»è¾‘
            stars_score = 0
            if max_stars >= 10000:
                stars_score = 10
            elif max_stars >= 5000:
                stars_score = 8
            elif max_stars >= 1000:
                stars_score = 6
            elif max_stars >= 500:
                stars_score = 4
            elif max_stars >= 100:
                stars_score = 2
            
            repo_count_score = min(total_repos * 0.5, 5)
            
            return stars_score + repo_count_score
            
        except Exception as e:
            logger.error(f"âŒ GitHubæœç´¢å¤±è´¥: {str(e)}")
            return 0.0

    async def _search_academic_papers(self, company_name: str) -> float:
        """æœç´¢å­¦æœ¯è®ºæ–‡å¹¶è¯„åˆ†"""
        try:
            if not await self._check_rate_limit('arxiv'):
                return 0.0
            
            # æœç´¢arXivè®ºæ–‡
            search_query = quote(f'all:"{company_name}"')
            url = f"{self.arxiv_api_base}?search_query={search_query}&max_results=50"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        content = await response.text()
                        
                        # ç®€å•è§£æXMLè·å–è®ºæ–‡æ•°é‡
                        paper_count = content.count('<entry>')
                        
                        # è¯„åˆ†é€»è¾‘
                        if paper_count >= 20:
                            return 10.0
                        elif paper_count >= 10:
                            return 8.0
                        elif paper_count >= 5:
                            return 6.0
                        elif paper_count >= 2:
                            return 4.0
                        elif paper_count >= 1:
                            return 2.0
                        
            return 0.0
            
        except Exception as e:
            logger.error(f"âŒ å­¦æœ¯è®ºæ–‡æœç´¢å¤±è´¥: {str(e)}")
            return 0.0

    async def _evaluate_tech_blog(self, website: str) -> float:
        """è¯„ä¼°æŠ€æœ¯åšå®¢è´¨é‡"""
        try:
            # æ£€æŸ¥ç½‘ç«™æ˜¯å¦æœ‰æŠ€æœ¯åšå®¢
            tech_blog_indicators = [
                '/blog', '/tech', '/engineering', '/research',
                '/developer', '/docs', '/api'
            ]
            
            async with aiohttp.ClientSession() as session:
                async with session.get(website, timeout=10) as response:
                    if response.status == 200:
                        content = await response.text()
                        
                        blog_score = 0
                        for indicator in tech_blog_indicators:
                            if indicator.lower() in content.lower():
                                blog_score += 0.8
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰æŠ€æœ¯å…³é”®è¯
                        tech_keywords = ['API', 'SDK', 'GitHub', 'documentation', 'technical']
                        for keyword in tech_keywords:
                            if keyword in content:
                                blog_score += 0.2
                        
                        return min(blog_score, 5.0)
            
            return 0.0
            
        except Exception as e:
            logger.error(f"âŒ æŠ€æœ¯åšå®¢è¯„ä¼°å¤±è´¥: {str(e)}")
            return 0.0

    async def _score_product_virality(self, company_name: str, website: Optional[str]) -> float:
        """è¯„ä¼°äº§å“ä¼ æ’­åŠ› (0-35åˆ†)"""
        score = 0.0
        
        try:
            # ç¤¾äº¤åª’ä½“æåŠå’Œè®¨è®º (0-20åˆ†)
            social_score = await self._search_social_mentions(company_name)
            score += min(social_score, 20.0)
            
            # äº§å“Huntç­‰å¹³å°è¡¨ç° (0-10åˆ†)
            platform_score = await self._search_product_platforms(company_name)
            score += min(platform_score, 10.0)
            
            # ç”¨æˆ·è¯„ä»·å’Œæ¨è (0-5åˆ†)
            review_score = await self._search_user_reviews(company_name)
            score += min(review_score, 5.0)
            
            logger.info(f"ğŸš€ äº§å“ä¼ æ’­åŠ›è¯„åˆ†: {company_name} = {score:.1f}/35åˆ†")
            return score
            
        except Exception as e:
            logger.error(f"âŒ äº§å“ä¼ æ’­åŠ›è¯„åˆ†å¤±è´¥: {str(e)}")
            return 0.0

    async def _search_social_mentions(self, company_name: str) -> float:
        """æœç´¢ç¤¾äº¤åª’ä½“æåŠ"""
        try:
            if not await self._check_rate_limit('tavily'):
                return 5.0  # é»˜è®¤åˆ†æ•°
            
            # ä½¿ç”¨Tavilyæœç´¢ç¤¾äº¤åª’ä½“æåŠ
            query = f'"{company_name}" AI startup twitter reddit linkedin'
            
            search_url = "https://api.tavily.com/search"
            headers = {
                "Content-Type": "application/json"
            }
            
            payload = {
                "api_key": self.tavily_api_key,
                "query": query,
                "search_depth": "basic",
                "include_images": False,
                "include_answer": False,
                "max_results": 10
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(search_url, json=payload, headers=headers) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = data.get('results', [])
                        
                        mention_score = 0
                        social_platforms = ['twitter.com', 'reddit.com', 'linkedin.com', 'medium.com']
                        
                        for result in results:
                            url = result.get('url', '')
                            if any(platform in url for platform in social_platforms):
                                mention_score += 2
                        
                        return min(mention_score, 20.0)
            
            return 5.0  # é»˜è®¤åˆ†æ•°
            
        except Exception as e:
            logger.error(f"âŒ ç¤¾äº¤åª’ä½“æœç´¢å¤±è´¥: {str(e)}")
            return 5.0

    async def _search_product_platforms(self, company_name: str) -> float:
        """æœç´¢äº§å“å¹³å°è¡¨ç°"""
        try:
            # æœç´¢Product Hunt, Hacker Newsç­‰å¹³å°
            platforms_query = f'"{company_name}" "Product Hunt" OR "Hacker News" OR "YC" OR "TechCrunch"'
            
            if await self._check_rate_limit('tavily'):
                search_url = "https://api.tavily.com/search"
                headers = {"Content-Type": "application/json"}
                
                payload = {
                    "api_key": self.tavily_api_key,
                    "query": platforms_query,
                    "search_depth": "basic",
                    "max_results": 5
                }
                
                async with aiohttp.ClientSession() as session:
                    async with session.post(search_url, json=payload, headers=headers) as response:
                        if response.status == 200:
                            data = await response.json()
                            results = data.get('results', [])
                            
                            platform_score = len(results) * 2  # æ¯ä¸ªç›¸å…³ç»“æœ2åˆ†
                            return min(platform_score, 10.0)
            
            return 2.0  # é»˜è®¤åˆ†æ•°
            
        except Exception as e:
            logger.error(f"âŒ äº§å“å¹³å°æœç´¢å¤±è´¥: {str(e)}")
            return 2.0

    async def _search_user_reviews(self, company_name: str) -> float:
        """æœç´¢ç”¨æˆ·è¯„ä»·"""
        try:
            # ç®€åŒ–çš„ç”¨æˆ·è¯„ä»·è¯„ä¼°
            review_keywords = ['review', 'rating', 'feedback', 'testimonial']
            review_query = f'"{company_name}" ' + ' OR '.join(review_keywords)
            
            # ä½¿ç”¨åŸºç¡€è¯„åˆ†é€»è¾‘
            return 3.0  # é»˜è®¤ç»™3åˆ†ï¼Œå®é™…å®ç°ä¸­å¯ä»¥æ›´å¤æ‚
            
        except Exception as e:
            logger.error(f"âŒ ç”¨æˆ·è¯„ä»·æœç´¢å¤±è´¥: {str(e)}")
            return 2.0

    async def _score_founder_influence(self, founder_name: str) -> float:
        """è¯„ä¼°åˆ›å§‹äººå½±å“åŠ› (0-20åˆ†)"""
        try:
            # æœç´¢åˆ›å§‹äººçš„åª’ä½“éœ²é¢å’Œå½±å“åŠ›
            founder_query = f'"{founder_name}" founder CEO AI startup interview'
            
            if await self._check_rate_limit('tavily'):
                search_url = "https://api.tavily.com/search"
                headers = {"Content-Type": "application/json"}
                
                payload = {
                    "api_key": self.tavily_api_key,
                    "query": founder_query,
                    "search_depth": "basic",
                    "max_results": 8
                }
                
                async with aiohttp.ClientSession() as session:
                    async with session.post(search_url, json=payload, headers=headers) as response:
                        if response.status == 200:
                            data = await response.json()
                            results = data.get('results', [])
                            
                            influence_score = 0
                            
                            # æ ¹æ®åª’ä½“æåŠè¯„åˆ†
                            media_outlets = ['techcrunch', 'forbes', 'wired', 'bloomberg', 'reuters']
                            for result in results:
                                url = result.get('url', '').lower()
                                if any(outlet in url for outlet in media_outlets):
                                    influence_score += 3  # æƒå¨åª’ä½“æŠ¥é“
                                else:
                                    influence_score += 1  # æ™®é€šåª’ä½“æåŠ
                            
                            logger.info(f"ğŸ‘¤ åˆ›å§‹äººå½±å“åŠ›è¯„åˆ†: {founder_name} = {influence_score:.1f}/20åˆ†")
                            return min(influence_score, 20.0)
            
            return 5.0  # é»˜è®¤åˆ†æ•°
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å§‹äººå½±å“åŠ›è¯„åˆ†å¤±è´¥: {str(e)}")
            return 5.0

    async def _score_ecosystem_impact(self, company_name: str, website: Optional[str]) -> float:
        """è¯„ä¼°ç”Ÿæ€å½±å“åŠ› (0-15åˆ†)"""
        try:
            # æœç´¢ä¼ä¸šåœ¨ç”Ÿæ€ç³»ç»Ÿä¸­çš„è§’è‰²å’Œå½±å“
            ecosystem_query = f'"{company_name}" API integration platform ecosystem partner'
            
            if await self._check_rate_limit('tavily'):
                search_url = "https://api.tavily.com/search"
                headers = {"Content-Type": "application/json"}
                
                payload = {
                    "api_key": self.tavily_api_key,
                    "query": ecosystem_query,
                    "search_depth": "basic",
                    "max_results": 5
                }
                
                async with aiohttp.ClientSession() as session:
                    async with session.post(search_url, json=payload, headers=headers) as response:
                        if response.status == 200:
                            data = await response.json()
                            results = data.get('results', [])
                            
                            ecosystem_score = 0
                            
                            # ç”Ÿæ€ç³»ç»Ÿå…³é”®è¯è¯„åˆ†
                            ecosystem_keywords = ['API', 'integration', 'platform', 'partnership', 'ecosystem']
                            for result in results:
                                content = (result.get('title', '') + ' ' + result.get('content', '')).lower()
                                for keyword in ecosystem_keywords:
                                    if keyword.lower() in content:
                                        ecosystem_score += 1
                            
                            logger.info(f"ğŸŒ ç”Ÿæ€å½±å“åŠ›è¯„åˆ†: {company_name} = {ecosystem_score:.1f}/15åˆ†")
                            return min(ecosystem_score, 15.0)
            
            return 3.0  # é»˜è®¤åˆ†æ•°
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæ€å½±å“åŠ›è¯„åˆ†å¤±è´¥: {str(e)}")
            return 3.0

    async def _check_rate_limit(self, api_name: str) -> bool:
        """æ£€æŸ¥APIé™åˆ¶"""
        current_time = time.time()
        rate_limit = self.rate_limits[api_name]
        
        # é‡ç½®è®¡æ•°å™¨ï¼ˆæ¯å°æ—¶ï¼‰
        if current_time - rate_limit['reset_time'] > 3600:
            rate_limit['calls'] = 0
            rate_limit['reset_time'] = current_time
        
        # æ£€æŸ¥é™åˆ¶
        max_calls = {'github': 60, 'arxiv': 100, 'tavily': 50}
        if rate_limit['calls'] < max_calls[api_name]:
            rate_limit['calls'] += 1
            return True
        
        return False

    def _get_influence_level(self, total_score: float) -> str:
        """æ ¹æ®æ€»åˆ†ç¡®å®šå½±å“åŠ›ç­‰çº§"""
        if total_score >= 80:
            return "A+çº§ - è¡Œä¸šé¢†å¯¼è€…"
        elif total_score >= 70:
            return "Açº§ - é«˜å½±å“åŠ›"
        elif total_score >= 60:
            return "Bçº§ - ä¸­ç­‰å½±å“åŠ›"
        elif total_score >= 40:
            return "Cçº§ - æ–°å…´å½±å“åŠ›"
        else:
            return "Dçº§ - å½±å“åŠ›å¾…æå‡"

    def format_score_report(self, score: MediaInfluenceScore) -> str:
        """æ ¼å¼åŒ–è¯„åˆ†æŠ¥å‘Š"""
        report = f"""
ğŸ¯ {score.company_name} åª’ä½“å½±å“åŠ›è¯„åˆ†æŠ¥å‘Š
{'='*50}
ğŸ“Š ç»¼åˆè¯„åˆ†: {score.total_score:.1f}/100åˆ† ({score.influence_level})

è¯¦ç»†ç»´åº¦è¯„åˆ†:
ğŸ“š æŠ€æœ¯å£°æœ›: {score.technical_reputation:.1f}/30åˆ†
ğŸš€ äº§å“ä¼ æ’­åŠ›: {score.product_virality:.1f}/35åˆ†  
ğŸ‘¤ åˆ›å§‹äººå½±å“åŠ›: {score.founder_influence:.1f}/20åˆ†
ğŸŒ ç”Ÿæ€å½±å“åŠ›: {score.ecosystem_impact:.1f}/15åˆ†

â° è¯„åˆ†æ—¶é—´: {score.scored_at.strftime('%Y-%m-%d %H:%M:%S')}
{'='*50}
"""
        return report

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
async def test_media_influence_scorer():
    """æµ‹è¯•åª’ä½“å½±å“åŠ›è¯„åˆ†ç³»ç»Ÿ"""
    scorer = MediaInfluenceScorer()
    
    # æµ‹è¯•å…¬å¸åˆ—è¡¨
    test_companies = [
        {"name": "SmartContent AI", "website": "https://smartcontent-ai.com", "founder": "John Smith"},
        {"name": "DataMind Analytics", "website": "https://datamind-analytics.co", "founder": "Sarah Chen"},
        {"name": "ChatFlow Builder", "website": "https://chatflow-builder.ai", "founder": "Mike Johnson"}
    ]
    
    print("ğŸ” å¼€å§‹åª’ä½“å½±å“åŠ›è¯„åˆ†æµ‹è¯•...")
    
    for company in test_companies:
        score = await scorer.score_company(
            company_name=company["name"],
            website=company.get("website"),
            founder_name=company.get("founder")
        )
        
        print(scorer.format_score_report(score))
        await asyncio.sleep(1)  # é¿å…APIé™åˆ¶

if __name__ == "__main__":
    asyncio.run(test_media_influence_scorer())