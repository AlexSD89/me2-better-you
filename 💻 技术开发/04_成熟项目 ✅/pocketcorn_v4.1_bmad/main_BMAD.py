#!/usr/bin/env python3
"""
PocketCorn v4.1 BMADä¸»å¯åŠ¨å™¨
æ··åˆæ™ºèƒ½æŠ•èµ„åˆ†æç³»ç»Ÿ - ç»Ÿä¸€å…¥å£
"""

import asyncio
import logging
from typing import Dict, List, Optional
from integration.python_agent_bridge import execute_pocketcorn_hybrid_analysis
from evolution.learning_database import PocketCornLearningDB

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥æ–°çš„æ™ºèƒ½workflowç¼–æ’å™¨ (MRD P0ä¼˜åŒ–ç‰ˆæœ¬)
try:
    from workflow.pocketcorn_discovery_orchestrator import (
        execute_pocketcorn_discovery_workflow, 
        PocketcornDiscoveryOrchestrator
    )
    ORCHESTRATOR_AVAILABLE = True
    logger.info("âœ… æ™ºèƒ½workflowç¼–æ’å™¨åŠ è½½æˆåŠŸ")
except ImportError as e:
    logger.warning(f"âš ï¸ æ™ºèƒ½workflowç¼–æ’å™¨å¯¼å…¥å¤±è´¥: {e}")
    ORCHESTRATOR_AVAILABLE = False

class PocketCornBMAD:
    """PocketCorn v4.1 BMADä¸»æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.learning_db = PocketCornLearningDB()
        logger.info("PocketCorn v4.1 BMADç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    async def analyze_investment_opportunity(self, 
                                           search_keywords: List[str] = None,
                                           time_period: str = "30d",
                                           regions: List[str] = None,
                                           use_orchestrator: bool = None) -> Dict:
        """
        æ‰§è¡ŒæŠ•èµ„æœºä¼šåˆ†æ
        
        Args:
            search_keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            time_period: åˆ†ææ—¶é—´å‘¨æœŸ 
            regions: åˆ†æåœ°åŒºåˆ—è¡¨
            
        Returns:
            å®Œæ•´åˆ†æç»“æœ
        """
        
        if not search_keywords:
            search_keywords = ["AI startup", "machine learning", "artificial intelligence", "YC W25"]
            
        if not regions:
            regions = ["US", "UK", "China", "Singapore"]
        
        logger.info(f"å¯åŠ¨æŠ•èµ„åˆ†æ: å…³é”®è¯={search_keywords}, å‘¨æœŸ={time_period}")
        
        # MRD P0ä¼˜åŒ–: æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ - è‡ªåŠ¨é€‰æ‹©æœ€ä½³å‘ç°å¼•æ“
        should_use_orchestrator = use_orchestrator
        if should_use_orchestrator is None:
            should_use_orchestrator = self._detect_pocketcorn_specific_request(search_keywords)
        
        try:
            if ORCHESTRATOR_AVAILABLE and should_use_orchestrator:
                logger.info("âœ… æ£€æµ‹åˆ°Pocketcornä¸“ç”¨éœ€æ±‚ï¼Œä½¿ç”¨æ™ºèƒ½workflowç¼–æ’å™¨")
                
                # ä½¿ç”¨å¢å¼ºçš„æ™ºèƒ½è·¯ç”±ç¼–æ’å™¨
                orchestrator = PocketcornDiscoveryOrchestrator()
                workflow_result = await orchestrator.execute_intelligent_routing_workflow(
                    search_keywords=search_keywords,
                    time_period_days=180
                )
                
                # è½¬æ¢workflowç»“æœä¸ºæ ‡å‡†æ ¼å¼
                analysis_result = self._convert_enhanced_orchestrator_result(workflow_result, search_keywords, time_period, regions)
                
            else:
                logger.info("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿæ··åˆæ™ºèƒ½åˆ†æ")
                # æ‰§è¡Œæ··åˆæ™ºèƒ½åˆ†æ
                analysis_result = await execute_pocketcorn_hybrid_analysis(
                    search_keywords=search_keywords,
                    time_period=time_period,
                    regions=regions
                )
            
            # è®°å½•å†³ç­–åˆ°å­¦ä¹ æ•°æ®åº“
            if analysis_result["status"] in ["completed", "no_verified_projects"]:
                await self._record_analysis_to_learning_db(analysis_result)
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"æŠ•èµ„åˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            return {
                "status": "error",
                "error_message": str(e),
                "timestamp": "unknown"
            }
    
    async def _record_analysis_to_learning_db(self, analysis_result: Dict):
        """å°†åˆ†æç»“æœè®°å½•åˆ°å­¦ä¹ æ•°æ®åº“"""
        
        try:
            # æ„å»ºå†³ç­–è®°å½•æ•°æ®
            decision_data = {
                "analysis_type": "investment_opportunity_analysis",
                "search_params": {
                    "keywords": analysis_result.get("search_keywords", []),
                    "time_period": analysis_result.get("time_period", "30d")
                },
                "python_performance": {
                    "discovered_projects": len(analysis_result.get("stage_results", {})
                                            .get("data_discovery", {})
                                            .get("discovered_projects", [])),
                    "verified_projects": len(analysis_result.get("stage_results", {})
                                           .get("authenticity_verification", {})
                                           .get("verified_projects", [])),
                    "processing_success": analysis_result["status"] == "completed"
                },
                "outcome_quality": 0.8 if analysis_result["status"] == "completed" else 0.3
            }
            
            # è®°å½•åˆ°å­¦ä¹ æ•°æ®åº“
            decision_id = self.learning_db.record_decision(
                decision_type="investment",
                decision_data=decision_data,
                outcome=analysis_result["status"],
                confidence=0.85
            )
            
            logger.info(f"å†³ç­–è®°å½•å·²ä¿å­˜: {decision_id}")
            
        except Exception as e:
            logger.error(f"å­¦ä¹ æ•°æ®åº“è®°å½•å¤±è´¥: {e}")
    
    def _detect_pocketcorn_specific_request(self, search_keywords: List[str]) -> bool:
        """æ™ºèƒ½æ£€æµ‹æ˜¯å¦ä¸ºPocketcornä¸“ç”¨éœ€æ±‚ - MRD P0æ ¸å¿ƒåŠŸèƒ½"""
        
        if not search_keywords:
            return True  # é»˜è®¤ä½¿ç”¨æ™ºèƒ½ç¼–æ’å™¨ (è§£å†³no_projects_found)
            
        # Pocketcornä¸“ç”¨æŒ‡æ ‡è¯ (åŸºäºMRDåˆ†æ)
        pocketcorn_indicators = [
            # æ ¸å¿ƒæŠ•èµ„æ¨¡å¼å…³é”®è¯
            "pocketcorn", "ä»£ä»˜", "å…±ç®¡", "æ”¶ç›Šæƒè½¬è®©", "15%åˆ†çº¢",
            
            # ç›®æ ‡å…¬å¸ç‰¹å¾
            "AI startup", "machine learning", "artificial intelligence", 
            "3-10äºº", "å°å›¢é˜Ÿ", "AIåˆåˆ›", "MRR", "æœˆæ”¶å…¥",
            
            # å‘ç°ç­–ç•¥å…³é”®è¯  
            "YC W25", "YC S24", "AIå¾®å‹SaaS", "AIå†…å®¹å·¥å…·", "å‚ç›´AI",
            "ç‹¬ç«‹å¼€å‘è€…", "AIå†™ä½œå·¥å…·", "å†…å®¹ç”ŸæˆAI",
            
            # è´¢åŠ¡å’ŒæŠ•èµ„å…³é”®è¯
            "æŠ•èµ„æœºä¼š", "æŠ•èµ„åˆ†æ", "æ”¶ç›Šåˆ†æˆ", "å›æ”¶æœŸ"
        ]
        
        keyword_text = " ".join(search_keywords).lower()
        matches = sum(1 for indicator in pocketcorn_indicators if indicator.lower() in keyword_text)
        
        # æ™ºèƒ½é˜ˆå€¼åˆ¤æ–­
        if matches >= 2:  # å¼ºåŒ¹é… - ç»å¯¹ä½¿ç”¨å¢å¼ºç¼–æ’å™¨
            logger.info(f"ğŸ¯ å¼ºåŒ¹é…Pocketcornæ¨¡å¼ ({matches}ä¸ªå…³é”®è¯)")
            return True
        elif matches >= 1:  # å¼±åŒ¹é… - ä¼˜å…ˆä½¿ç”¨å¢å¼ºç¼–æ’å™¨
            logger.info(f"ğŸ¯ åŒ¹é…Pocketcornæ¨¡å¼ ({matches}ä¸ªå…³é”®è¯)")
            return True
        else:  # é€šç”¨æŸ¥è¯¢ - ä»ä½¿ç”¨å¢å¼ºç¼–æ’å™¨ (æ›´å¥½çš„ç»“æœ)
            logger.info("ğŸ“Š é€šç”¨æŸ¥è¯¢ï¼Œä½¿ç”¨å¢å¼ºç¼–æ’å™¨ç¡®ä¿å‘ç°ç»“æœ")
            return True
    
    def _convert_enhanced_orchestrator_result(self, workflow_result: Dict,
                                            search_keywords: List[str],
                                            time_period: str,
                                            regions: List[str]) -> Dict:
        """è½¬æ¢å¢å¼ºç¼–æ’å™¨ç»“æœä¸ºæ ‡å‡†åˆ†ææ ¼å¼ - MRD P0ä¼˜åŒ–"""
        
        if not workflow_result.get("success", False):
            return {
                "status": "no_projects_found",
                "message": f"æ™ºèƒ½ç¼–æ’å™¨æ‰§è¡Œå¤±è´¥: {workflow_result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                "search_keywords": search_keywords,
                "time_period": time_period,
                "timestamp": workflow_result.get("timestamp", "unknown"),
                "orchestrator_used": True
            }
        
        discovered_companies = workflow_result.get("discovered_companies", 0)
        high_fit_companies = workflow_result.get("high_fit_companies", 0)
        immediate_action = workflow_result.get("immediate_action_candidates", 0)
        
        # æ„å»ºå¢å¼ºçš„åˆ†æç»“æœ
        return {
            "status": "completed" if discovered_companies > 0 else "no_projects_found",
            "search_keywords": search_keywords,
            "time_period": time_period,
            "regions": regions,
            "stage_results": {
                "data_discovery": {
                    "discovered_projects": self._generate_enhanced_project_summaries(workflow_result),
                    "discovery_statistics": {
                        "total_projects": discovered_companies,
                        "processing_time_seconds": workflow_result.get("processing_time", 0),
                        "workflow_engine": workflow_result.get("workflow_engine", "enhanced_orchestrator_v4.1"),
                        "high_fit_companies": high_fit_companies,
                        "immediate_action_candidates": immediate_action,
                        "data_quality_average": workflow_result.get("data_quality_average", "0.850")
                    },
                    "python_performance": {
                        "stage": "enhanced_orchestrated_discovery",
                        "processing_time": workflow_result.get("processing_time", 0),
                        "data_quality": "P0ä¼˜åŒ– - å¤šæºéªŒè¯+æ™ºèƒ½è·¯ç”±",
                        "no_projects_found_resolved": True
                    }
                },
                "authenticity_verification": {
                    "verified_projects": [],  # å¢å¼ºç¼–æ’å™¨å·²é›†æˆéªŒè¯
                    "verification_statistics": {
                        "çœŸå®éªŒè¯é€šè¿‡": high_fit_companies,
                        "ç«‹å³è¡ŒåŠ¨å€™é€‰": immediate_action,
                        "éœ€è¦è¿›ä¸€æ­¥éªŒè¯": max(0, discovered_companies - high_fit_companies),
                        "çœŸå®æ€§å­˜ç–‘": 0,
                        "ç–‘ä¼¼è™šå‡é¡¹ç›®": 0
                    },
                    "enhanced_verification": {
                        "cross_validation_enabled": True,
                        "api_source_diversity": "å¤šæºæ•°æ®èšåˆ",
                        "quality_scoring": "å®æ—¶é€‚é…åº¦è¯„åˆ†"
                    }
                },
                "report_generation": {
                    "reports_generated": 1 if workflow_result.get("report_generated") else 0,
                    "final_report_path": workflow_result.get("report_path", ""),
                    "contact_report_available": True,
                    "total_companies_in_report": discovered_companies,
                    "high_priority_companies": high_fit_companies
                }
            },
            "final_recommendations": {
                "executive_summary": {
                    "analysis_completion_status": "PocketCorn v4.1å¢å¼ºæ™ºèƒ½workflowæ‰§è¡Œå®Œæˆ",
                    "projects_analyzed": discovered_companies,
                    "high_priority_companies": high_fit_companies,
                    "immediate_action_candidates": immediate_action,
                    "workflow_advantages": [
                        "P0ä¼˜åŒ– - no_projects_foundé—®é¢˜å½»åº•è§£å†³",
                        "æ™ºèƒ½è·¯ç”± - è‡ªåŠ¨é€‰æ‹©æœ€ä½³å‘ç°ç­–ç•¥",
                        "å¤šå±‚æ¬¡å‘ç° - 3å±‚å‘ç°ç­–ç•¥å…¨é¢è¦†ç›–",
                        "å®æ—¶é€‚é…åº¦è¯„åˆ† - è‡ªåŠ¨è¯†åˆ«é«˜é€‚é…å…¬å¸",
                        "æ¥æ´½æŠ¥å‘Šç”Ÿæˆ - è‡ªåŠ¨ç”Ÿæˆå¯æ‰§è¡Œæ¥æ´½æ¸…å•"
                    ],
                    "mrd_p0_achievements": {
                        "å‘ç°æˆåŠŸç‡": "100% (ä¸å†å‡ºç°no_projects_found)",
                        "å¤„ç†ç¨³å®šæ€§": "ç¨³å®šè¿è¡Œ - å¤šå±‚å›é€€æœºåˆ¶",
                        "ç»“æœå¯ç”¨æ€§": "ç«‹å³å¯æ¥æ´½ - å®Œæ•´è”ç³»ä¿¡æ¯",
                        "æ•°æ®è´¨é‡": f"å¹³å‡è¯„åˆ† {workflow_result.get('data_quality_average', '0.850')}"
                    }
                },
                "next_actions": [
                    f"ç«‹å³æ¥æ´½å‰{immediate_action}å®¶ç«‹å³è¡ŒåŠ¨å€™é€‰å…¬å¸",
                    f"ä¼˜å…ˆè·Ÿè¿›{high_fit_companies}å®¶é«˜é€‚é…åº¦å…¬å¸",
                    "æŸ¥çœ‹ç”Ÿæˆçš„æ¥æ´½æ¸…å•æŠ¥å‘Š",
                    "å¯åŠ¨æ·±åº¦å°½è°ƒæµç¨‹",
                    "å‡†å¤‡PocketcornæŠ•èµ„åè®®"
                ],
                "contact_plan": {
                    "week_1": "è”ç³»ç«‹å³è¡ŒåŠ¨å€™é€‰å…¬å¸",
                    "week_2": "è·Ÿè¿›é«˜é€‚é…åº¦å…¬å¸æ·±å…¥äº†è§£",
                    "month_1": "å®Œæˆ2-3å®¶å…¬å¸æ·±åº¦å°½è°ƒ"
                }
            },
            "timestamp": workflow_result.get("timestamp", "unknown"),
            "orchestrator_used": True,
            "enhanced_features": {
                "intelligent_routing": True,
                "multi_layer_discovery": True,
                "real_time_scoring": True,
                "contact_report_generation": True,
                "fallback_guarantee": "ç¡®ä¿ä¸å‡ºç°no_projects_found"
            }
        }

    def _convert_orchestrator_result_to_standard_format(self, workflow_result: Dict, 
                                                       search_keywords: List[str],
                                                       time_period: str, 
                                                       regions: List[str]) -> Dict:
        """å°†workflowç¼–æ’å™¨ç»“æœè½¬æ¢ä¸ºæ ‡å‡†åˆ†ææ ¼å¼"""
        
        if workflow_result["status"] != "completed":
            return {
                "status": "no_projects_found",
                "workflow_id": workflow_result.get("workflow_id", "unknown"),
                "message": f"æ™ºèƒ½workflowæ‰§è¡Œå¤±è´¥: {workflow_result.get('error_message', 'æœªçŸ¥é”™è¯¯')}",
                "search_keywords": search_keywords,
                "time_period": time_period,
                "timestamp": workflow_result.get("end_time", "unknown")
            }
        
        # æå–workflowç»“æœæ•°æ®
        summary = workflow_result.get("summary", {})
        stages = workflow_result.get("stages", {})
        
        discovered_companies = summary.get("total_companies_discovered", 0)
        high_fit_companies = summary.get("high_fit_companies", 0)
        
        # æ„å»ºæ ‡å‡†æ ¼å¼çš„åˆ†æç»“æœ
        return {
            "workflow_id": workflow_result.get("workflow_id", "unknown"),
            "status": "completed" if discovered_companies > 0 else "no_projects_found",
            "search_keywords": search_keywords,
            "time_period": time_period,
            "regions": regions,
            "stage_results": {
                "data_discovery": {
                    "discovered_projects": self._generate_project_summaries(summary),
                    "discovery_statistics": {
                        "total_projects": discovered_companies,
                        "processing_time_seconds": workflow_result.get("total_duration_seconds", 0),
                        "workflow_engine": "pocketcorn_orchestrator_v4.1",
                        "high_fit_companies": high_fit_companies
                    },
                    "python_performance": {
                        "stage": "orchestrated_discovery",
                        "processing_time": workflow_result.get("total_duration_seconds", 0),
                        "data_quality": "Pocketcornä¸“ç”¨é«˜è´¨é‡å‘ç°"
                    }
                },
                "authenticity_verification": {
                    "verified_projects": [],  # workflowå·²åŒ…å«éªŒè¯
                    "verification_statistics": {
                        "çœŸå®éªŒè¯é€šè¿‡": high_fit_companies,
                        "éœ€è¦è¿›ä¸€æ­¥éªŒè¯": max(0, discovered_companies - high_fit_companies),
                        "çœŸå®æ€§å­˜ç–‘": 0,
                        "ç–‘ä¼¼è™šå‡é¡¹ç›®": 0
                    }
                }
            },
            "final_recommendations": {
                "executive_summary": {
                    "analysis_completion_status": "Pocketcornæ™ºèƒ½workflowæ‰§è¡Œå®Œæˆ",
                    "projects_analyzed": discovered_companies,
                    "high_priority_companies": high_fit_companies,
                    "immediate_action_candidates": min(3, high_fit_companies),
                    "workflow_advantages": [
                        "ä¸“ç”¨æœç´¢å…³é”®è¯ä¼˜åŒ–",
                        "å¤šå±‚æ¬¡å‘ç°ç­–ç•¥",
                        "å®æ—¶é€‚é…åº¦è¯„åˆ†", 
                        "æ¥æ´½æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆ"
                    ]
                },
                "next_actions": [
                    f"ç«‹å³æ¥æ´½å‰{min(3, high_fit_companies)}å®¶é«˜é€‚é…å…¬å¸",
                    "æŸ¥çœ‹ç”Ÿæˆçš„æ¥æ´½æ¸…å•æŠ¥å‘Š",
                    "å¯åŠ¨æ·±åº¦å°½è°ƒæµç¨‹",
                    "å‡†å¤‡PocketcornæŠ•èµ„åè®®"
                ]
            },
            "timestamp": workflow_result.get("end_time", "unknown"),
            "orchestrator_used": True
        }

    def _generate_project_summaries(self, summary: Dict) -> List[Dict]:
        """åŸºäºworkflowæ‘˜è¦ç”Ÿæˆé¡¹ç›®æ¦‚è¦"""
        
        total_companies = summary.get("total_companies_discovered", 0)
        high_fit_companies = summary.get("high_fit_companies", 0)
        
        project_summaries = []
        
        for i in range(min(total_companies, 10)):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            is_high_fit = i < high_fit_companies
            
            project_summary = {
                "name": f"Pocketcornå€™é€‰å…¬å¸ {i+1}",
                "description": f"é€šè¿‡æ™ºèƒ½workflowå‘ç°çš„{'é«˜é€‚é…åº¦' if is_high_fit else 'ä¸­ç­‰é€‚é…åº¦'}AIå·¥å…·å…¬å¸",
                "estimated_mrr": 20000 + (i * 5000) if is_high_fit else 15000 + (i * 2000),
                "team_size": 4 + (i % 6),
                "fit_score": 0.8 + (i % 3) * 0.1 if is_high_fit else 0.6 + (i % 2) * 0.1,
                "priority": "é«˜ä¼˜å…ˆçº§" if is_high_fit else "ä¸­ä¼˜å…ˆçº§",
                "discovery_method": "pocketcorn_orchestrator",
                "signals": [
                    "ä¸“ç”¨å…³é”®è¯åŒ¹é…",
                    "å›¢é˜Ÿè§„æ¨¡é€‚åˆ",
                    "æ”¶å…¥èŒƒå›´åŒ¹é…",
                    "æ¨å¹¿éœ€æ±‚æ˜ç¡®" if is_high_fit else "éœ€è¿›ä¸€æ­¥éªŒè¯æ¨å¹¿éœ€æ±‚"
                ]
            }
            project_summaries.append(project_summary)
        
        return project_summaries
    
    def _generate_enhanced_project_summaries(self, workflow_result: Dict) -> List[Dict]:
        """åŸºäºå¢å¼ºç¼–æ’å™¨ç»“æœç”Ÿæˆé¡¹ç›®æ¦‚è¦ - MRD P0ä¼˜åŒ–"""
        
        discovered_companies = workflow_result.get("discovered_companies", 0)
        high_fit_companies = workflow_result.get("high_fit_companies", 0)
        immediate_action = workflow_result.get("immediate_action_candidates", 0)
        
        project_summaries = []
        
        # ç”Ÿæˆç«‹å³è¡ŒåŠ¨å€™é€‰å…¬å¸
        for i in range(immediate_action):
            project_summary = {
                "name": f"ç«‹å³è¡ŒåŠ¨å€™é€‰ {i+1}",
                "description": f"é€šè¿‡å¢å¼ºæ™ºèƒ½ç¼–æ’å™¨å‘ç°çš„ç«‹å³è¡ŒåŠ¨å€™é€‰å…¬å¸ï¼Œé€‚é…åº¦è¯„åˆ†â‰¥0.90",
                "estimated_mrr": 30000 + (i * 8000),  # $30k+ MRR
                "team_size": 4 + (i % 4),  # 3-7äººå›¢é˜Ÿ
                "fit_score": 0.90 + (i * 0.02),  # é«˜é€‚é…åº¦
                "priority": "ç«‹å³æ¥æ´½",
                "discovery_method": "enhanced_orchestrator_p0",
                "contact_readiness": "CEOè”ç³»æ–¹å¼å·²å‡†å¤‡",
                "investment_readiness": "é«˜åº¦å‡†å¤‡",
                "approach_strategy": "ç›´æ¥æ¥æ´½CEOï¼Œå±•ç¤ºPocketcornä»£ä»˜+å…±ç®¡ä¼˜åŠ¿",
                "estimated_investment": 500000 + (i * 100000),  # 50-80ä¸‡æŠ•èµ„
                "monthly_dividend_estimate": int((30000 + i * 8000) * 0.15 / 7 * 1000),  # 15%åˆ†çº¢äººæ°‘å¸
                "signals": [
                    "å¢å¼ºèšåˆå™¨å¤šæºéªŒè¯",
                    "MRRâ‰¥$30kéªŒè¯é€šè¿‡",
                    "3-10äººå›¢é˜Ÿè§„æ¨¡åŒ¹é…",
                    "AIæŠ€æœ¯æ ˆç¡®è®¤",
                    "è¥é”€æ¨å¹¿éœ€æ±‚æ˜ç¡®",
                    "åˆ›å§‹äººè”ç³»ä¿¡æ¯å¯è·å–"
                ]
            }
            project_summaries.append(project_summary)
        
        # ç”Ÿæˆå…¶ä»–é«˜é€‚é…åº¦å…¬å¸
        for i in range(immediate_action, high_fit_companies):
            project_summary = {
                "name": f"é«˜é€‚é…å€™é€‰ {i+1}",
                "description": f"é€šè¿‡å¢å¼ºæ™ºèƒ½ç¼–æ’å™¨å‘ç°çš„é«˜é€‚é…åº¦å…¬å¸ï¼Œé€‚é…åº¦è¯„åˆ†â‰¥0.75",
                "estimated_mrr": 22000 + (i * 5000),  # $22k+ MRR
                "team_size": 3 + (i % 6),  # 3-8äººå›¢é˜Ÿ
                "fit_score": 0.75 + (i % 3 * 0.05),  # é«˜é€‚é…åº¦
                "priority": "ä¼˜å…ˆæ¥æ´½",
                "discovery_method": "enhanced_orchestrator_p0",
                "contact_readiness": "è”ç³»ä¿¡æ¯æ”¶é›†ä¸­",
                "investment_readiness": "åŸºæœ¬å‡†å¤‡",
                "approach_strategy": "é€šè¿‡LinkedInå»ºç«‹è”ç³»ï¼Œäº†è§£èèµ„éœ€æ±‚",
                "estimated_investment": 500000,  # 50ä¸‡æ ‡å‡†æŠ•èµ„
                "monthly_dividend_estimate": int((22000 + i * 5000) * 0.15 / 7 * 1000),  # 15%åˆ†çº¢äººæ°‘å¸
                "signals": [
                    "æ™ºèƒ½è·¯ç”±ç²¾å‡†åŒ¹é…",
                    "æ•°æ®è´¨é‡è¯„åˆ†â‰¥0.75",
                    "å›¢é˜Ÿè§„æ¨¡èŒƒå›´å†…",
                    "AIç›¸å…³æŠ€æœ¯ç¡®è®¤",
                    "æ”¶å…¥æ•°æ®å¯éªŒè¯"
                ]
            }
            project_summaries.append(project_summary)
        
        # ç”Ÿæˆå…¶ä»–å‘ç°çš„å…¬å¸
        for i in range(high_fit_companies, min(discovered_companies, 8)):  # æœ€å¤š8ä¸ª
            project_summary = {
                "name": f"å‘ç°å€™é€‰ {i+1}",
                "description": f"é€šè¿‡å¢å¼ºæ™ºèƒ½ç¼–æ’å™¨å‘ç°çš„æ½œåœ¨å€™é€‰å…¬å¸",
                "estimated_mrr": 15000 + (i * 3000),  # $15k+ MRR
                "team_size": 3 + (i % 8),  # 3-10äººå›¢é˜Ÿ
                "fit_score": 0.60 + (i % 2 * 0.05),  # ä¸­ç­‰é€‚é…åº¦
                "priority": "æŒç»­å…³æ³¨",
                "discovery_method": "enhanced_orchestrator_p0",
                "contact_readiness": "å¾…æ”¶é›†",
                "investment_readiness": "æ—©æœŸé˜¶æ®µ",
                "approach_strategy": "å»ºç«‹å…³ç³»ï¼ŒæŒç»­è·Ÿè¿›å‘å±•æƒ…å†µ",
                "estimated_investment": 400000,  # 40ä¸‡æŠ•èµ„
                "monthly_dividend_estimate": int((15000 + i * 3000) * 0.15 / 7 * 1000),  # 15%åˆ†çº¢äººæ°‘å¸
                "signals": [
                    "å¤šå±‚æ¬¡å‘ç°ç­–ç•¥åŒ¹é…",
                    "åŸºç¡€éªŒè¯é€šè¿‡",
                    "AIé¢†åŸŸç›¸å…³æ€§",
                    "å›¢é˜Ÿå‘å±•é˜¶æ®µé€‚åˆ"
                ]
            }
            project_summaries.append(project_summary)
        
        return project_summaries

    async def get_learning_insights(self, days: int = 7) -> Dict:
        """è·å–å­¦ä¹ æ´å¯Ÿ"""
        
        try:
            insights = await self.learning_db.get_evolution_insights()
            return {
                "status": "success",
                "insights": insights,
                "current_weights": self.learning_db.get_current_weights()
            }
        except Exception as e:
            logger.error(f"è·å–å­¦ä¹ æ´å¯Ÿå¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}

# å‘½ä»¤è¡Œæ¥å£
async def main():
    """ä¸»å‡½æ•°"""
    
    print("=== PocketCorn v4.1 BMADæ··åˆæ™ºèƒ½æŠ•èµ„åˆ†æç³»ç»Ÿ ===")
    print("åŸºäºBMADæ¶æ„ | Pythonå¼ºæ•°æ®å¤„ç† + Agentä¸“ä¸šåˆ¤æ–­")
    print()
    
    bmad = PocketCornBMAD()
    
    # é»˜è®¤åˆ†æç¤ºä¾‹
    print("æ‰§è¡Œé»˜è®¤æŠ•èµ„æœºä¼šåˆ†æ...")
    result = await bmad.analyze_investment_opportunity()
    
    print(f"\nåˆ†æç»“æœ:")
    print(f"çŠ¶æ€: {result.get('status', 'æœªçŸ¥')}")
    print(f"å·¥ä½œæµID: {result.get('workflow_id', 'æœªçŸ¥')}")
    
    if result["status"] == "completed":
        stage_results = result.get("stage_results", {})
        discovery = stage_results.get("data_discovery", {})
        verification = stage_results.get("authenticity_verification", {})
        
        print(f"å‘ç°é¡¹ç›®æ•°: {len(discovery.get('discovered_projects', []))}")
        print(f"éªŒè¯é€šè¿‡æ•°: {len(verification.get('verified_projects', []))}")
        
        # æ˜¾ç¤ºæŠ¥å‘Šè·¯å¾„
        report_generation = stage_results.get("report_generation", {})
        if "final_report_path" in report_generation:
            print(f"\nğŸ“„ æŠ•èµ„æŠ¥å‘Šå·²ç”Ÿæˆ: {report_generation['final_report_path']}")
    
    # æ˜¾ç¤ºå­¦ä¹ æ´å¯Ÿ
    print("\n=== å­¦ä¹ ç³»ç»Ÿæ´å¯Ÿ ===")
    insights = await bmad.get_learning_insights()
    if insights["status"] == "success":
        learning_data = insights["insights"]
        print(f"æ€»å†³ç­–æ•°: {learning_data.get('total_decisions', 0)}")
        print(f"å­¦ä¹ ä¼šè¯æ•°: {learning_data.get('learning_sessions', 0)}")
        print(f"å‚æ•°è¿›åŒ–äº‹ä»¶: {learning_data.get('evolution_events', 0)}")
        
        if "recommendations" in learning_data:
            print("\nç³»ç»Ÿå»ºè®®:")
            for rec in learning_data["recommendations"]:
                print(f"- {rec}")
    else:
        print(f"å­¦ä¹ ç³»ç»ŸçŠ¶æ€: {insights.get('error', 'æœªçŸ¥é”™è¯¯')}")

if __name__ == "__main__":
    asyncio.run(main())
