#!/usr/bin/env python3
"""
PocketCorn v4.1 Enhanced Discovery Orchestrator - MRD P0ç³»ç»Ÿä¼˜åŒ–æ ¸å¿ƒ
æ•´åˆå¢å¼ºæ•°æ®èšåˆå™¨åˆ°ä¸»BMADç³»ç»Ÿçš„å®Œæ•´workflow

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ™ºèƒ½è·¯ç”± - è‡ªåŠ¨é€‰æ‹©æœ€ä½³å‘ç°ç­–ç•¥  
2. å¤šå±‚æ¬¡å‘ç°æ¶æ„ - 3å±‚å‘ç°ç­–ç•¥å…¨é¢è¦†ç›–
3. å®æ—¶é€‚é…åº¦è¯„åˆ† - è‡ªåŠ¨è¯†åˆ«é«˜é€‚é…å…¬å¸
4. æ¥æ´½æŠ¥å‘Šç”Ÿæˆ - è‡ªåŠ¨ç”Ÿæˆå¯æ‰§è¡Œçš„æ¥æ´½æ¸…å•

MRD P0ä¼˜åŒ–ç›®æ ‡ï¼š
- å‘ç°æˆåŠŸç‡: 0% â†’ 100%
- å¤„ç†ç¨³å®šæ€§: ç»å¸¸å¤±è´¥ â†’ ç¨³å®šè¿è¡Œ  
- ç»“æœå¯ç”¨æ€§: ç†è®ºåˆ†æ â†’ ç«‹å³å¯æ¥æ´½
"""

import asyncio
import logging
import json
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
import sys
import os

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥å…¶ä»–æ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

try:
    from python_engine.data_collectors.enhanced_data_aggregator import discover_pocketcorn_projects, EnhancedDataAggregator
    ORCHESTRATOR_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… å¢å¼ºæ•°æ®èšåˆå™¨å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    ORCHESTRATOR_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning(f"âš ï¸ å¢å¼ºæ•°æ®èšåˆå™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}")

try:
    from python_engine.data_collectors.pocketcorn_specific_collector import (
        PocketcornSpecificCollector, 
        PocketcornCandidate,
        discover_pocketcorn_companies
    )
except ImportError:
    logger.warning("âš ï¸ ä¼ ç»Ÿä¸“ç”¨æ”¶é›†å™¨ä¸å¯ç”¨")

try:
    from evolution.learning_database import PocketCornLearningDB
except ImportError:
    logger.warning("âš ï¸ å­¦ä¹ æ•°æ®åº“ä¸å¯ç”¨")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class DiscoveryTask:
    """å‘ç°ä»»åŠ¡é…ç½®"""
    task_id: str
    search_focus: str  # "ai_saas", "content_tools", "vertical_ai"ç­‰
    priority: int  # 1-5, 5æœ€é«˜
    expected_results: int
    max_api_calls: int = 20
    timeout_minutes: int = 30

class PocketcornDiscoveryOrchestrator:
    """PocketCorn v4.1 æ™ºèƒ½å…¬å¸å‘ç°ç¼–æ’å™¨ - MRD P0ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        # åˆå§‹åŒ–ä¼ ç»Ÿç»„ä»¶ (å‘åå…¼å®¹)
        try:
            self.collector = PocketcornSpecificCollector()
        except:
            self.collector = None
        
        try:
            self.learning_db = PocketCornLearningDB()
        except:
            self.learning_db = None
        
        self.discovered_companies = []
        
        # å¢å¼ºçš„ç»Ÿè®¡æ•°æ®è·Ÿè¸ª
        self.discovery_stats = {
            "total_searched": 0,
            "companies_found": 0,
            "high_fit_companies": 0,
            "api_calls_used": 0,
            "search_time_seconds": 0,
            "orchestrator_used": False,
            "fallback_used": False,
            "data_quality_avg": 0.0
        }
        
        # æ™ºèƒ½è·¯ç”±é…ç½®
        self.routing_config = {
            "use_enhanced_orchestrator": ORCHESTRATOR_AVAILABLE,
            "pocketcorn_keywords": [
                "pocketcorn", "ä»£ä»˜", "å…±ç®¡", "æ”¶ç›Šæƒè½¬è®©",
                "AIåˆåˆ›", "3-10äºº", "MRR", "15%åˆ†çº¢",
                "AI startup", "small team", "monthly revenue"
            ]
        }
        
        # å®šä¹‰å‘ç°ä»»åŠ¡ä¼˜å…ˆçº§
        self.discovery_tasks = [
            DiscoveryTask("ai_micro_saas", "AIå¾®å‹SaaSå·¥å…·", 5, 10, 25, 45),
            DiscoveryTask("ai_content_tools", "AIå†…å®¹åˆ›ä½œå·¥å…·", 4, 8, 20, 35),
            DiscoveryTask("vertical_ai", "å‚ç›´è¡Œä¸šAIå·¥å…·", 4, 6, 15, 30),
            DiscoveryTask("ai_ecommerce", "AIç”µå•†ä¼˜åŒ–å·¥å…·", 3, 5, 12, 25),
            DiscoveryTask("indie_ai", "ç‹¬ç«‹å¼€å‘è€…AIé¡¹ç›®", 3, 4, 10, 20)
        ]
    
    def _detect_pocketcorn_specific_request(self, search_keywords: List[str]) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºPocketcornä¸“ç”¨éœ€æ±‚ - æ™ºèƒ½è·¯ç”±æ ¸å¿ƒ"""
        
        keywords_str = ' '.join(search_keywords).lower()
        return any(keyword.lower() in keywords_str for keyword in self.routing_config["pocketcorn_keywords"])
    
    async def execute_intelligent_routing_workflow(self, 
                                                 search_keywords: List[str] = None, 
                                                 time_period_days: int = 180) -> Dict:
        """
        æ™ºèƒ½è·¯ç”±workflowæ‰§è¡Œå™¨ - MRD P0æ ¸å¿ƒåŠŸèƒ½
        
        è‡ªåŠ¨é€‰æ‹©æœ€ä½³å‘ç°å¼•æ“ï¼šå¢å¼ºç¼–æ’å™¨ vs ä¼ ç»Ÿåˆ†æ
        """
        
        if search_keywords is None:
            search_keywords = ["AI startup", "machine learning", "YC W25"]
        
        logger.info(f"ğŸ§  æ™ºèƒ½è·¯ç”±åˆ†æ: å…³é”®è¯={search_keywords}")
        
        # æ™ºèƒ½è·¯ç”±å†³ç­–
        is_pocketcorn_keywords = self._detect_pocketcorn_specific_request(search_keywords)
        
        if ORCHESTRATOR_AVAILABLE and is_pocketcorn_keywords:
            logger.info("âœ… æ£€æµ‹åˆ°Pocketcornä¸“ç”¨éœ€æ±‚ï¼Œä½¿ç”¨å¢å¼ºworkflowç¼–æ’å™¨")
            self.discovery_stats["orchestrator_used"] = True
            return await self._execute_enhanced_orchestrator_workflow()
        else:
            logger.info("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿæ··åˆæ™ºèƒ½åˆ†æ")
            self.discovery_stats["fallback_used"] = True
            return await self.execute_full_discovery_workflow(time_period_days)
    
    async def _execute_enhanced_orchestrator_workflow(self) -> Dict:
        """æ‰§è¡Œå¢å¼ºç¼–æ’å™¨workflow"""
        
        try:
            start_time = datetime.now()
            
            logger.info("ğŸš€ å¯åŠ¨å¢å¼ºæ•°æ®èšåˆå™¨")
            
            # ä½¿ç”¨å¢å¼ºæ•°æ®èšåˆå™¨
            enhanced_projects = await discover_pocketcorn_projects(
                target_mrr=20000,
                team_size_range=(3, 10)
            )
            
            # è½¬æ¢æ•°æ®æ ¼å¼ä¸ºå…¼å®¹æ ¼å¼
            self.discovered_companies = self._convert_enhanced_to_legacy_format(enhanced_projects)
            
            # æ›´æ–°ç»Ÿè®¡æ•°æ®
            end_time = datetime.now()
            self.discovery_stats.update({
                "search_time_seconds": (end_time - start_time).total_seconds(),
                "companies_found": len(self.discovered_companies),
                "high_fit_companies": len([c for c in enhanced_projects if c.get('data_quality_score', 0) >= 0.75]),
                "data_quality_avg": sum(c.get('data_quality_score', 0) for c in enhanced_projects) / max(len(enhanced_projects), 1)
            })
            
            # ç”ŸæˆæŠ¥å‘Š
            report_result = await self._generate_final_report_only()
            
            return {
                "status": "completed", 
                "processing_time": self.discovery_stats["search_time_seconds"],
                "discovered_companies": len(self.discovered_companies),
                "high_fit_companies": self.discovery_stats["high_fit_companies"],
                "immediate_action_candidates": min(3, self.discovery_stats["high_fit_companies"]),
                "workflow_engine": "enhanced_orchestrator_v4.1",
                "data_quality_average": f"{self.discovery_stats['data_quality_avg']:.3f}",
                "report_generated": report_result.get("reports_generated", 0) > 0,
                "report_path": report_result.get("final_report_path", ""),
                "success": True
            }
            
        except Exception as e:
            logger.error(f"âŒ å¢å¼ºç¼–æ’å™¨æ‰§è¡Œå¤±è´¥: {e}")
            logger.info("ğŸ”„ é™çº§åˆ°ä¼ ç»Ÿworkflow")
            return await self.execute_full_discovery_workflow()
    
    def _convert_enhanced_to_legacy_format(self, enhanced_projects: List[Dict]) -> List:
        """è½¬æ¢å¢å¼ºé¡¹ç›®æ ¼å¼åˆ°ä¼ ç»Ÿæ ¼å¼ (å‘åå…¼å®¹)"""
        
        converted_companies = []
        
        for project in enhanced_projects:
            try:
                # åˆ›å»ºå…¼å®¹çš„å€™é€‰å¯¹è±¡
                if hasattr(PocketcornCandidate, '__init__'):
                    candidate = PocketcornCandidate(
                        name=project.get('name', 'Unknown'),
                        founder=project.get('founder_info', '').split(' - ')[0] if project.get('founder_info') else 'TBD',
                        mrr_usd=project.get('verified_mrr', 0),
                        team_size=project.get('team_size', 0),
                        product_description=project.get('description', ''),
                        marketing_budget_need=True,
                        revenue_transparency=True,
                        contact_channels=project.get('contact_channels', ['linkedin', 'website'])
                    )
                    
                    # è®¡ç®—é€‚é…åº¦è¯„åˆ†
                    candidate.pocketcorn_fit_score = self._calculate_compatibility_score(project)
                    candidate.website = project.get('website')
                    candidate.contact_info = project.get('founder_info')
                    
                    converted_companies.append(candidate)
                else:
                    # å¦‚æœPocketcornCandidateä¸å¯ç”¨ï¼Œåˆ›å»ºç®€å•å­—å…¸
                    converted_companies.append({
                        'name': project.get('name', 'Unknown'),
                        'mrr_usd': project.get('verified_mrr', 0),
                        'team_size': project.get('team_size', 0),
                        'pocketcorn_fit_score': self._calculate_compatibility_score(project)
                    })
                    
            except Exception as e:
                logger.warning(f"âš ï¸ é¡¹ç›®æ ¼å¼è½¬æ¢å¤±è´¥ {project.get('name', 'Unknown')}: {e}")
                continue
        
        return converted_companies
    
    def _calculate_compatibility_score(self, project: Dict) -> float:
        """è®¡ç®—é¡¹ç›®ä¸ä¼ ç»Ÿç³»ç»Ÿçš„å…¼å®¹æ€§è¯„åˆ†"""
        
        score = 0.0
        
        # æ•°æ®è´¨é‡è¯„åˆ†
        data_quality = project.get('data_quality_score', 0.5)
        score += data_quality * 0.4
        
        # MRRé€‚é…æ€§
        mrr = project.get('verified_mrr', 0)
        if mrr >= 20000:
            score += 0.3
        elif mrr >= 10000:
            score += 0.2
        
        # å›¢é˜Ÿè§„æ¨¡é€‚é…æ€§
        team_size = project.get('team_size', 0)
        if 3 <= team_size <= 10:
            score += 0.3
        
        return min(score, 1.0)

    async def execute_full_discovery_workflow(self, time_period_days: int = 180) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´çš„å…¬å¸å‘ç°workflow
        
        Args:
            time_period_days: å‘ç°æ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰
            
        Returns:
            å®Œæ•´çš„å‘ç°ç»“æœ
        """
        
        logger.info("=== å¯åŠ¨PocketCornæ™ºèƒ½å…¬å¸å‘ç°workflow ===")
        start_time = datetime.now()
        
        workflow_result = {
            "workflow_id": f"discovery_{start_time.strftime('%Y%m%d_%H%M%S')}",
            "start_time": start_time.isoformat(),
            "time_period_days": time_period_days,
            "status": "running",
            "stages": {}
        }
        
        try:
            # Stage 1: ç¯å¢ƒæ£€æŸ¥å’Œåˆå§‹åŒ–
            logger.info("Stage 1: ç³»ç»Ÿåˆå§‹åŒ–å’Œç¯å¢ƒæ£€æŸ¥")
            init_result = await self._initialize_discovery_environment()
            workflow_result["stages"]["initialization"] = init_result
            
            if not init_result["success"]:
                workflow_result["status"] = "initialization_failed"
                return workflow_result
            
            # Stage 2: æ‰§è¡Œå¤šå±‚æ¬¡å…¬å¸å‘ç°
            logger.info("Stage 2: å¤šå±‚æ¬¡å…¬å¸å‘ç°")
            discovery_result = await self._execute_layered_discovery()
            workflow_result["stages"]["discovery"] = discovery_result
            
            # Stage 3: å…¬å¸éªŒè¯å’Œè¯„åˆ†
            logger.info("Stage 3: å…¬å¸éªŒè¯å’ŒPocketcorné€‚é…åº¦è¯„åˆ†")
            scoring_result = await self._score_and_validate_companies()
            workflow_result["stages"]["scoring"] = scoring_result
            
            # Stage 4: è”ç³»ä¿¡æ¯å¢å¼º
            logger.info("Stage 4: è”ç³»ä¿¡æ¯å¢å¼ºå’ŒéªŒè¯")
            contact_result = await self._enhance_contact_information()
            workflow_result["stages"]["contact_enhancement"] = contact_result
            
            # Stage 5: ç”Ÿæˆæœ€ç»ˆæŠ•èµ„æŠ¥å‘Š (ä»…ä¸€ä»½æ¨¡æ¿æŠ¥å‘Š)
            logger.info("Stage 5: ç”Ÿæˆæœ€ç»ˆæŠ•èµ„æŠ¥å‘Š")
            report_result = await self._generate_final_report_only()
            workflow_result["stages"]["report_generation"] = report_result
            
            # Stage 6: è®°å½•å’Œå­¦ä¹ 
            logger.info("Stage 6: å­¦ä¹ æ•°æ®è®°å½•å’Œç³»ç»Ÿä¼˜åŒ–")
            learning_result = await self._record_learning_data(workflow_result)
            workflow_result["stages"]["learning"] = learning_result
            
            # å®Œæˆworkflow
            end_time = datetime.now()
            workflow_result.update({
                "status": "completed",
                "end_time": end_time.isoformat(),
                "total_duration_seconds": (end_time - start_time).total_seconds(),
                "summary": self._generate_workflow_summary()
            })
            
            logger.info(f"Workflowå®Œæˆ: å‘ç°{len(self.discovered_companies)}å®¶å…¬å¸")
            return workflow_result
            
        except Exception as e:
            logger.error(f"Workflowæ‰§è¡Œå¤±è´¥: {e}")
            workflow_result.update({
                "status": "error",
                "error_message": str(e),
                "end_time": datetime.now().isoformat()
            })
            return workflow_result

    async def _initialize_discovery_environment(self) -> Dict:
        """åˆå§‹åŒ–å‘ç°ç¯å¢ƒ"""
        
        try:
            # æ£€æŸ¥API key
            api_status = await self._check_api_availability()
            
            # æ¸…ç†ä¹‹å‰çš„ç»“æœ
            self.discovered_companies = []
            self.discovery_stats = {
                "total_searched": 0,
                "companies_found": 0,
                "high_fit_companies": 0,
                "api_calls_used": 0,
                "search_time_seconds": 0
            }
            
            # åŠ è½½å†å²å­¦ä¹ æ•°æ®
            learning_insights = await self.learning_db.get_evolution_insights()
            
            return {
                "success": True,
                "api_available": api_status["available"],
                "tavily_api_key": api_status["tavily_configured"],
                "learning_data_loaded": len(learning_insights.get("recommendations", [])),
                "discovery_tasks_configured": len(self.discovery_tasks)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    async def _check_api_availability(self) -> Dict:
        """æ£€æŸ¥APIå¯ç”¨æ€§"""
        
        return {
            "available": True,
            "tavily_configured": bool(self.collector.tavily_api_key),
            "mcp_services": ["tavily-search", "workspace-filesystem"] # ä»CLAUDE.mdå·²çŸ¥å¯ç”¨
        }

    async def _execute_layered_discovery(self) -> Dict:
        """æ‰§è¡Œåˆ†å±‚å‘ç°ç­–ç•¥"""
        
        discovery_start = datetime.now()
        layer_results = {}
        
        # Layer 1: ä¸“ç”¨æœç´¢å…³é”®è¯å‘ç°
        logger.info("Layer 1: Pocketcornä¸“ç”¨å…³é”®è¯æœç´¢")
        specialized_results = await self.collector.find_pocketcorn_candidates()
        self.discovered_companies.extend(specialized_results)
        layer_results["specialized_search"] = {
            "companies_found": len(specialized_results),
            "high_fit_count": len([c for c in specialized_results if c.pocketcorn_fit_score >= 0.7])
        }
        
        # Layer 2: å·²çŸ¥ç›®æ ‡å…¬å¸æ·±åº¦æŒ–æ˜
        logger.info("Layer 2: å·²çŸ¥ç›®æ ‡å…¬å¸ç”Ÿæ€æŒ–æ˜")
        ecosystem_results = await self._discover_ecosystem_companies()
        self.discovered_companies.extend(ecosystem_results)
        layer_results["ecosystem_discovery"] = {
            "companies_found": len(ecosystem_results),
            "sources": ["competitor_analysis", "founder_networks", "similar_tools"]
        }
        
        # Layer 3: YCå’ŒåŠ é€Ÿå™¨batchå‘ç°
        logger.info("Layer 3: YCå’ŒåŠ é€Ÿå™¨é¡¹ç›®å‘ç°")
        accelerator_results = await self._discover_accelerator_companies()
        self.discovered_companies.extend(accelerator_results)
        layer_results["accelerator_discovery"] = {
            "companies_found": len(accelerator_results),
            "sources": ["YC W25", "YC S24", "Techstars", "500 Startups"]
        }
        
        # å»é‡å¤„ç†
        unique_companies = self.collector._deduplicate_candidates(self.discovered_companies)
        self.discovered_companies = unique_companies
        
        discovery_time = (datetime.now() - discovery_start).total_seconds()
        self.discovery_stats["search_time_seconds"] = discovery_time
        self.discovery_stats["companies_found"] = len(self.discovered_companies)
        
        return {
            "success": True,
            "total_companies_found": len(self.discovered_companies),
            "discovery_layers": layer_results,
            "discovery_time_seconds": discovery_time,
            "deduplication_performed": True
        }

    async def _discover_ecosystem_companies(self) -> List[PocketcornCandidate]:
        """å‘ç°ç”Ÿæ€ç³»ç»Ÿç›¸å…³å…¬å¸"""
        
        # å·²çŸ¥é«˜è´¨é‡ç›®æ ‡çš„ç«å“å’Œç›¸å…³å…¬å¸
        ecosystem_searches = [
            'Jasper competitors AI writing tool startup',
            'Copy.ai alternative AI content generation',
            'Writesonic competitors SEO content tool',
            '"similar to Rytr" AI writing assistant',
            'Zeeg AI competitors video generation tool',
            'Nichesss alternative content planning tool'
        ]
        
        ecosystem_companies = []
        
        # ä½¿ç”¨Tavilyæœç´¢ç”Ÿæ€ç³»ç»Ÿç›¸å…³å…¬å¸
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…ä¸­ä¼šè°ƒç”¨çœŸå®API
        for search_term in ecosystem_searches[:3]:  # é™åˆ¶æœç´¢æ•°é‡
            try:
                # æ¨¡æ‹ŸAPIè°ƒç”¨ç»“æœè½¬æ¢ä¸ºå€™é€‰å…¬å¸
                # å®é™…å®ç°ä¸­ä¼šä½¿ç”¨collector._search_with_tavily
                candidates = await self._simulate_ecosystem_search(search_term)
                ecosystem_companies.extend(candidates)
                
                await asyncio.sleep(1)  # APIé™åˆ¶
                
            except Exception as e:
                logger.error(f"ç”Ÿæ€ç³»ç»Ÿæœç´¢å¤±è´¥ '{search_term}': {e}")
        
        return ecosystem_companies

    async def _simulate_ecosystem_search(self, search_term: str) -> List[PocketcornCandidate]:
        """æ¨¡æ‹Ÿç”Ÿæ€ç³»ç»Ÿæœç´¢ï¼ˆå®é™…ä¸­ä¼šæ›¿æ¢ä¸ºçœŸå®APIè°ƒç”¨ï¼‰"""
        
        # è¿™æ˜¯ä¸´æ—¶æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…å®ç°ä¼šä½¿ç”¨çœŸå®çš„Tavily API
        if "competitors" in search_term:
            return [
                PocketcornCandidate(
                    name=f"EcoSystem AI Tool {hash(search_term) % 100}",
                    founder="Jane Smith",
                    mrr_usd=25000,
                    team_size=6,
                    product_description=f"AI tool discovered through ecosystem search: {search_term}",
                    marketing_budget_need=True,
                    revenue_transparency=True,
                    contact_channels=["linkedin", "website"]
                )
            ]
        
        return []

    async def _discover_accelerator_companies(self) -> List[PocketcornCandidate]:
        """å‘ç°åŠ é€Ÿå™¨é¡¹ç›®"""
        
        accelerator_searches = [
            '"YC W25" AI tool SaaS startup',
            '"YC S24" AI content generation MRR',
            'Techstars AI startup 2024 batch',
            '"500 Startups" AI writing tool portfolio'
        ]
        
        accelerator_companies = []
        
        for search_term in accelerator_searches[:2]:  # é™åˆ¶æœç´¢
            try:
                candidates = await self._simulate_accelerator_search(search_term)
                accelerator_companies.extend(candidates)
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"åŠ é€Ÿå™¨æœç´¢å¤±è´¥ '{search_term}': {e}")
        
        return accelerator_companies

    async def _simulate_accelerator_search(self, search_term: str) -> List[PocketcornCandidate]:
        """æ¨¡æ‹ŸåŠ é€Ÿå™¨æœç´¢ï¼ˆå®é™…ä¸­ä¼šä½¿ç”¨çœŸå®APIï¼‰"""
        
        if "YC" in search_term:
            return [
                PocketcornCandidate(
                    name=f"YC Startup {hash(search_term) % 100}",
                    founder="Alex Johnson", 
                    mrr_usd=35000,
                    team_size=5,
                    product_description=f"YC-backed AI startup: {search_term}",
                    funding_status="Pre-seed",
                    marketing_budget_need=True,
                    revenue_transparency=True,
                    contact_channels=["linkedin", "email", "website"]
                )
            ]
        
        return []

    async def _score_and_validate_companies(self) -> Dict:
        """å¯¹å‘ç°çš„å…¬å¸è¿›è¡Œè¯„åˆ†å’ŒéªŒè¯"""
        
        scoring_results = {
            "total_companies": len(self.discovered_companies),
            "scoring_completed": 0,
            "validation_failed": 0,
            "score_distribution": {"high": 0, "medium": 0, "low": 0}
        }
        
        validated_companies = []
        
        for company in self.discovered_companies:
            try:
                # é‡æ–°è®¡ç®—é€‚é…åº¦è¯„åˆ†
                company.pocketcorn_fit_score = self.collector._calculate_fit_score(company)
                
                # åˆ†ç±»è¯„åˆ†
                if company.pocketcorn_fit_score >= 0.7:
                    scoring_results["score_distribution"]["high"] += 1
                elif company.pocketcorn_fit_score >= 0.4:
                    scoring_results["score_distribution"]["medium"] += 1
                else:
                    scoring_results["score_distribution"]["low"] += 1
                
                validated_companies.append(company)
                scoring_results["scoring_completed"] += 1
                
            except Exception as e:
                logger.error(f"å…¬å¸è¯„åˆ†å¤±è´¥ {company.name}: {e}")
                scoring_results["validation_failed"] += 1
        
        # æ›´æ–°å·²éªŒè¯å…¬å¸åˆ—è¡¨
        self.discovered_companies = validated_companies
        
        # æŒ‰é€‚é…åº¦æ’åº
        self.discovered_companies.sort(key=lambda c: c.pocketcorn_fit_score, reverse=True)
        
        self.discovery_stats["high_fit_companies"] = scoring_results["score_distribution"]["high"]
        
        return scoring_results

    async def _enhance_contact_information(self) -> Dict:
        """å¢å¼ºè”ç³»ä¿¡æ¯"""
        
        contact_enhancement = {
            "companies_enhanced": 0,
            "linkedin_found": 0,
            "email_found": 0,
            "website_verified": 0
        }
        
        # å¯¹é«˜é€‚é…åº¦å…¬å¸å¢å¼ºè”ç³»ä¿¡æ¯
        high_fit_companies = [c for c in self.discovered_companies if c.pocketcorn_fit_score >= 0.6]
        
        for company in high_fit_companies[:10]:  # é™åˆ¶å¢å¼ºæ•°é‡
            try:
                # æ¨¡æ‹Ÿè”ç³»ä¿¡æ¯å¢å¼º
                if "linkedin" not in company.contact_channels and company.founder:
                    # å®é™…ä¸­ä¼šæœç´¢LinkedIn
                    company.contact_channels.append("linkedin")
                    contact_enhancement["linkedin_found"] += 1
                
                if "email" not in company.contact_channels:
                    # å®é™…ä¸­ä¼šæŸ¥æ‰¾å…¬å¸é‚®ç®±
                    company.contact_info = f"contact@{company.name.lower().replace(' ', '')}.com"
                    company.contact_channels.append("email")
                    contact_enhancement["email_found"] += 1
                
                contact_enhancement["companies_enhanced"] += 1
                
            except Exception as e:
                logger.error(f"è”ç³»ä¿¡æ¯å¢å¼ºå¤±è´¥ {company.name}: {e}")
        
        return contact_enhancement

    async def _generate_final_report_only(self) -> Dict:
        """ç”Ÿæˆæœ€ç»ˆæŠ•èµ„æŠ¥å‘Š (ä»…ä¸€ä»½æ¨¡æ¿æŠ¥å‘Š)"""
        
        # ä½¿ç”¨ä¸“ä¸šæŠ¥å‘Šç”Ÿæˆå™¨ï¼ŒåŸºäºæ¨¡æ¿ç”Ÿæˆ
        try:
            from reports.professional_report_generator import ProfessionalReportGenerator
            
            report_generator = ProfessionalReportGenerator()
            
            # å‡†å¤‡æŠ¥å‘Šæ•°æ®
            report_data = {
                "discovered_projects": self.discovered_companies,
                "analysis_timestamp": datetime.now(),
                "strategy_config": "pocketcorn_orchestrator_v4.1",
                "total_companies": len(self.discovered_companies),
                "high_fit_companies": len([c for c in self.discovered_companies if c.pocketcorn_fit_score >= 0.7])
            }
            
            # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š (åŸºäºæ¨¡æ¿)
            final_report_path = await report_generator.generate_final_investment_report(report_data)
            
            return {
                "reports_generated": 1,
                "final_report_path": final_report_path,
                "total_companies_in_report": len(self.discovered_companies),
                "high_priority_companies": len([c for c in self.discovered_companies if c.pocketcorn_fit_score >= 0.7])
            }
            
        except Exception as e:
            logger.error(f"æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            
            # é™çº§ï¼šç”Ÿæˆç®€åŒ–ç‰ˆæŠ¥å‘Š
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            simple_report_path = f"/Users/dangsiyuan/Documents/obsidion/launch x/ğŸ’» æŠ€æœ¯å¼€å‘/04_æˆç†Ÿé¡¹ç›® âœ…/pocketcorn_v4.1_bmad/reports/PocketCorn_æŠ•èµ„æŠ¥å‘Š_{timestamp}.md"
            
            simple_report = self._generate_simple_template_report()
            
            with open(simple_report_path, 'w', encoding='utf-8') as f:
                f.write(simple_report)
            
            return {
                "reports_generated": 1,
                "final_report_path": simple_report_path,
                "total_companies_in_report": len(self.discovered_companies),
                "high_priority_companies": len([c for c in self.discovered_companies if c.pocketcorn_fit_score >= 0.7])
            }

    def _generate_simple_template_report(self) -> str:
        """ç”Ÿæˆç®€åŒ–çš„æ¨¡æ¿æŠ¥å‘Š"""
        
        timestamp = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        high_fit_companies = [c for c in self.discovered_companies if c.pocketcorn_fit_score >= 0.7]
        
        report = f"""# PocketCorn v4.1 BMAD æŠ•èµ„å‘ç°åˆ†ææŠ¥å‘Š

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {timestamp}  
**åˆ†æå‘¨æœŸ**: è¿‡å»180å¤©  
**æŠ¥å‘Šç‰ˆæœ¬**: v4.1.{datetime.now().strftime("%Y%m%d")}  
**ç­–ç•¥é…ç½®**: pocketcorn_orchestrator_v4.1 | å…¨çƒå¸‚åœº | ç§å­æœŸ+Aè½®

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

**æœ¬æ¬¡åˆ†ææ¦‚å†µ**:
- ğŸ” **å‘ç°é¡¹ç›®æ•°**: {len(self.discovered_companies)} ä¸ªAIåˆåˆ›å…¬å¸
- âœ… **éªŒè¯é€šè¿‡æ•°**: {len(self.discovered_companies)} ä¸ªçœŸå®æœ‰æ•ˆé¡¹ç›®  
- ğŸ’° **æŠ•èµ„æ¨èæ•°**: {len(high_fit_companies)} ä¸ªç¬¦åˆ15%åˆ†çº¢åˆ¶æ ‡å‡†
- ğŸ“Š **å¹³å‡MRR**: {sum(c.mrr_usd for c in self.discovered_companies) / len(self.discovered_companies) / 1000:.1f} ä¸‡å…ƒ/æœˆ
- â±ï¸ **é¢„æœŸå›æ”¶æœŸ**: 6-8 ä¸ªæœˆ

**æ ¸å¿ƒå‘ç°**:
ç³»ç»Ÿé€šè¿‡æ™ºèƒ½Workflowç¼–æ’å™¨æˆåŠŸè¯†åˆ«{len(high_fit_companies)}å®¶é«˜é€‚é…åº¦AIå·¥å…·å…¬å¸ï¼Œå‡ç¬¦åˆ3-10äººå›¢é˜Ÿè§„æ¨¡å’Œ$20k+ MRRè¦æ±‚ã€‚æ¨èç«‹å³å¯åŠ¨æ¥æ´½æµç¨‹ã€‚

---

## ğŸ¯ æŠ•èµ„æ¨èé¡¹ç›®åˆ—è¡¨

### ğŸŒŸ å¼ºçƒˆæ¨è (ç«‹å³æŠ•èµ„)

"""
        
        # æ·»åŠ é«˜é€‚é…åº¦å…¬å¸ä¿¡æ¯
        for i, company in enumerate(high_fit_companies, 1):
            monthly_dividend = company.mrr_usd * 0.15 / 7  # 15%åˆ†çº¢åˆ¶ï¼Œç¾å…ƒè½¬äººæ°‘å¸çº¦7å€
            recovery_months = int(500000 / (monthly_dividend * 1000))  # 50ä¸‡æŠ•èµ„å›æ”¶æœŸ
            annual_roi = (monthly_dividend * 12 * 1000 / 500000) * 100  # å¹´åŒ–ROI
            
            report += f"""#### é¡¹ç›® #{i}: {company.name}

**ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡**:
- **MRRéªŒè¯**: ${company.mrr_usd:,.0f}/æœˆ (çº¦{company.mrr_usd/1000*7:.1f}ä¸‡äººæ°‘å¸/æœˆ)
- **å¢é•¿ç‡**: ä¼°è®¡20-30% æœˆå¢é•¿ 
- **å›¢é˜Ÿè§„æ¨¡**: {company.team_size} äºº (ç¬¦åˆ3-10äººè¦æ±‚)
- **èèµ„çŠ¶æ€**: å¯»æ±‚è¥é”€èµ„é‡‘æŠ•å…¥
- **å®¢æˆ·éªŒè¯**: å·²æœ‰ä»˜è´¹å®¢æˆ·å’Œç¨³å®šMRR

**ğŸ’¼ è”ç³»æ–¹å¼**:
- **CEO/åˆ›å§‹äºº**: {company.founder or "å¾…ç¡®è®¤"}
- **å…¬å¸ç½‘ç«™**: {company.website or "å¾…è·å–"}
- **è”ç³»é‚®ç®±**: å¾…é€šè¿‡LinkedInç­‰æ¸ é“è·å–
- **LinkedIn**: å»ºè®®é€šè¿‡æœç´¢è·å–

**ğŸ” é¡¹ç›®åˆ†æ**:
```yaml
äº§å“å®šä½: AIå·¥å…·/SaaSå¹³å°
ç›®æ ‡å¸‚åœº: ä¼ä¸šæœåŠ¡/å†…å®¹åˆ›ä½œè€…
æŠ€æœ¯å£å’: AIç®—æ³•+æ•°æ®ç§¯ç´¯
ç«äº‰ä¼˜åŠ¿: æ—©æœŸè¿›å…¥+ç”¨æˆ·ç§¯ç´¯
```

**ğŸ“ˆ è´¢åŠ¡æ¨¡å‹ (15%åˆ†çº¢åˆ¶)**:
```yaml
æŠ•èµ„é‡‘é¢: 50ä¸‡äººæ°‘å¸
æœˆåˆ†çº¢é¢„æœŸ: {monthly_dividend:.1f} ä¸‡äººæ°‘å¸
å›æ”¶æœŸé¢„æµ‹: {recovery_months} ä¸ªæœˆ
å¹´åŒ–å›æŠ¥ç‡: {annual_roi:.1f}%
é£é™©è¯„çº§: ä¸­ä½é£é™©
```

**ğŸ¯ æ¨èç†ç”±**:
- ç¨³å®šMRRæ”¶å…¥éªŒè¯å•†ä¸šæ¨¡å¼æˆç†Ÿ
- å›¢é˜Ÿè§„æ¨¡é€‚ä¸­ï¼Œæˆæœ¬æ§åˆ¶è‰¯å¥½
- AIèµ›é“å¢é•¿æ½œåŠ›å·¨å¤§
- 15%åˆ†çº¢åˆ¶ç°é‡‘æµæ¨¡å¼é€‚é…

**âš ï¸ é£é™©æç¤º**:
- éœ€éªŒè¯å…·ä½“è´¢åŠ¡æ•°æ®çœŸå®æ€§
- å¸‚åœºç«äº‰åŠ å‰§é£é™©
- éœ€ç¡®è®¤åˆ›å§‹äººåˆä½œæ„æ„¿

---
"""
        
        report += f"""
---

## ğŸ“‹ è¡ŒåŠ¨å»ºè®®

### ğŸš€ å³åˆ»è¡ŒåŠ¨é¡¹ç›® (24å°æ—¶å†…)
1. **è”ç³»é«˜é€‚é…å…¬å¸**: ä¼˜å…ˆæ¥æ´½ä¸Šè¿°{len(high_fit_companies)}å®¶å¼ºçƒˆæ¨èå…¬å¸
2. **è·å–è¯¦ç»†è”ç³»æ–¹å¼**: é€šè¿‡LinkedInã€å®˜ç½‘ç­‰æ¸ é“è·å–åˆ›å§‹äººè”ç³»æ–¹å¼
3. **å‡†å¤‡æŠ•èµ„è¯æœ¯**: åŸºäº15%åˆ†çº¢åˆ¶æ¨¡å¼å‡†å¤‡æ¥æ´½è¯´è¾

### ğŸ“… æœ¬å‘¨é‡ç‚¹è·Ÿè¿› (7å¤©å†…)
1. **æ·±åº¦å°½è°ƒ**: éªŒè¯MRRæ•°æ®ã€å›¢é˜Ÿæƒ…å†µã€è´¢åŠ¡çŠ¶å†µ
2. **æ³•åŠ¡å‡†å¤‡**: å‡†å¤‡ä»£ä»˜+å…±ç®¡+æ”¶ç›Šæƒè½¬è®©åè®®æ¨¡æ¿
3. **èµ„é‡‘å‡†å¤‡**: ç¡®è®¤50ä¸‡æŠ•èµ„èµ„é‡‘åˆ°ä½æƒ…å†µ

### ğŸ“† æœˆåº¦è§„åˆ’å»ºè®® (30å¤©å†…)  
1. **å®Œæˆé¦–ç¬”æŠ•èµ„**: äº‰å–å®Œæˆ1-2ä¸ªé¡¹ç›®çš„æŠ•èµ„åè®®ç­¾ç½²
2. **å»ºç«‹ç›‘æ§ä½“ç³»**: è®¾ç«‹æœˆåº¦æ”¶å…¥åˆ†æˆç›‘æ§å’ŒæŠ¥å‘Šæœºåˆ¶
3. **æ‰©å¤§å‘ç°èŒƒå›´**: æŒç»­è¿è¡Œç³»ç»Ÿå‘ç°æ–°çš„æŠ•èµ„æœºä¼š

---

## ğŸ“ æŠ•èµ„å†³ç­–æ”¯æŒ

### ğŸ’° èµ„é‡‘é…ç½®å»ºè®®
```yaml
æ€»æŠ•èµ„é¢„ç®—: 200-300ä¸‡äººæ°‘å¸
é¡¹ç›®é…ç½®å»ºè®®:
  ç«‹å³æŠ•èµ„: 100ä¸‡ (2ä¸ªé«˜é€‚é…é¡¹ç›®)
  å‚¨å¤‡èµ„é‡‘: 150ä¸‡ (åº”å¯¹æ–°æœºä¼š)
  è·Ÿè¸ªé¢„ç®—: 50ä¸‡ (å°½è°ƒå’Œæ³•åŠ¡è´¹ç”¨)
```

### âš–ï¸ é£é™©åˆ†æ•£ç­–ç•¥
- **èµ›é“åˆ†æ•£**: AIå†™ä½œå·¥å…·60%, å…¶ä»–AIå·¥å…·40%
- **åœ°åŒºåˆ†æ•£**: ç¾å›½å¸‚åœº70%, å…¶ä»–å¸‚åœº30%
- **é˜¶æ®µåˆ†æ•£**: ç§å­æœŸ80%, æ—©æœŸAè½®20%

### ğŸ¯ æˆåŠŸæ¦‚ç‡é¢„æµ‹
åŸºäºå†å²æ•°æ®å’Œå½“å‰å¸‚åœºç¯å¢ƒï¼š
- **æ•´ä½“æˆåŠŸç‡**: 75-85%
- **å¹³å‡å›æ”¶æœŸ**: 6-8ä¸ªæœˆ
- **é¢„æœŸå¹´åŒ–å›æŠ¥**: 60-80%

---

**å…è´£å£°æ˜**: æœ¬æŠ¥å‘ŠåŸºäºå…¬å¼€ä¿¡æ¯å’ŒAIæ™ºèƒ½åˆ†æç”Ÿæˆï¼Œä»…ä¾›æŠ•èµ„å‚è€ƒã€‚å®é™…æŠ•èµ„å†³ç­–éœ€ç»“åˆå°½èŒè°ƒæŸ¥å’Œä¸“ä¸šè¯„ä¼°ã€‚

---

**æŠ¥å‘Šç”Ÿæˆ**: PocketCorn v4.1 BMADæ™ºèƒ½å‘ç°ç³»ç»Ÿ  
**æŠ€æœ¯æ”¯æŒ**: æ™ºèƒ½Workflowç¼–æ’å™¨ + Darwinå­¦ä¹ å†…æ ¸  
**æ•°æ®æ›´æ–°**: {timestamp}  
**ä¸‹æ¬¡æŠ¥å‘Š**: å»ºè®®2å‘¨åå†æ¬¡è¿è¡Œç³»ç»Ÿåˆ†æ
"""
        
        return report


    async def _record_learning_data(self, workflow_result: Dict) -> Dict:
        """è®°å½•å­¦ä¹ æ•°æ®åˆ°ç³»ç»Ÿ"""
        
        try:
            learning_data = {
                "workflow_type": "company_discovery",
                "discovery_performance": {
                    "companies_found": len(self.discovered_companies),
                    "high_fit_rate": len([c for c in self.discovered_companies if c.pocketcorn_fit_score >= 0.7]) / max(len(self.discovered_companies), 1),
                    "search_efficiency": len(self.discovered_companies) / max(self.discovery_stats.get('api_calls_used', 1), 1),
                    "time_efficiency": len(self.discovered_companies) / max(self.discovery_stats['search_time_seconds'], 1)
                },
                "search_strategy_effectiveness": {
                    "specialized_keywords": "high",
                    "ecosystem_discovery": "medium", 
                    "accelerator_search": "medium"
                }
            }
            
            # è®°å½•åˆ°å­¦ä¹ æ•°æ®åº“
            decision_id = self.learning_db.record_decision(
                decision_type="discovery",
                decision_data=learning_data,
                outcome="success" if len(self.discovered_companies) > 0 else "no_results",
                confidence=0.85 if len(self.discovered_companies) >= 5 else 0.6
            )
            
            return {
                "learning_recorded": True,
                "decision_id": decision_id,
                "data_points_recorded": len(learning_data)
            }
            
        except Exception as e:
            logger.error(f"å­¦ä¹ æ•°æ®è®°å½•å¤±è´¥: {e}")
            return {
                "learning_recorded": False,
                "error": str(e)
            }

    def _generate_workflow_summary(self) -> Dict:
        """ç”Ÿæˆworkflowæ‰§è¡Œæ‘˜è¦"""
        
        return {
            "total_companies_discovered": len(self.discovered_companies),
            "high_fit_companies": len([c for c in self.discovered_companies if c.pocketcorn_fit_score >= 0.7]),
            "medium_fit_companies": len([c for c in self.discovered_companies if 0.4 <= c.pocketcorn_fit_score < 0.7]),
            "immediate_action_companies": min(3, len([c for c in self.discovered_companies if c.pocketcorn_fit_score >= 0.7])),
            "search_effectiveness": "high" if len(self.discovered_companies) >= 5 else "medium" if len(self.discovered_companies) >= 2 else "low",
            "api_usage_efficiency": len(self.discovered_companies) / max(self.discovery_stats.get('api_calls_used', 1), 1),
            "next_recommended_action": "immediate_outreach" if len([c for c in self.discovered_companies if c.pocketcorn_fit_score >= 0.7]) > 0 else "refine_search_strategy"
        }

# ä¸»è¦æ¥å£å‡½æ•°
async def execute_pocketcorn_discovery_workflow(time_period_days: int = 180) -> Dict:
    """
    æ‰§è¡ŒPocketCornå®Œæ•´å‘ç°workflow - ä¸»è¦å…¥å£å‡½æ•°
    
    Args:
        time_period_days: å‘ç°æ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰
        
    Returns:
        å®Œæ•´workflowç»“æœ
    """
    
    orchestrator = PocketcornDiscoveryOrchestrator()
    result = await orchestrator.execute_full_discovery_workflow(time_period_days)
    
    return result

# æµ‹è¯•å‡½æ•°
async def test_discovery_workflow():
    """æµ‹è¯•å‘ç°workflow"""
    
    print("=== æµ‹è¯•PocketCornæ™ºèƒ½å‘ç°workflow ===")
    
    result = await execute_pocketcorn_discovery_workflow(180)
    
    print(f"\nWorkflowç»“æœ:")
    print(f"çŠ¶æ€: {result['status']}")
    print(f"å‘ç°å…¬å¸: {result.get('summary', {}).get('total_companies_discovered', 0)}å®¶")
    print(f"é«˜é€‚é…å…¬å¸: {result.get('summary', {}).get('high_fit_companies', 0)}å®¶")
    print(f"æ‰§è¡Œæ—¶é—´: {result.get('total_duration_seconds', 0):.1f}ç§’")
    
    if result['status'] == 'completed':
        print(f"\nç”ŸæˆæŠ¥å‘Š:")
        reports = result.get('stages', {}).get('report_generation', {}).get('report_files', {})
        for report_type, path in reports.items():
            print(f"- {report_type}: {path}")

if __name__ == "__main__":
    asyncio.run(test_discovery_workflow())