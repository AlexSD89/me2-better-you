#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®æ¡£æ¡ˆæ‰¹é‡ä¿®å¤å·¥å…·
ç”¨äºè‡ªåŠ¨åŒ–å¤„ç†é¡¹ç›®æ¡£æ¡ˆçš„é‡å¤æ–‡ä»¶ã€åˆ†ç±»æ•´ç†ã€å‘½åæ ‡å‡†åŒ–ç­‰é—®é¢˜
"""

import os
import re
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import json
from datetime import datetime

class ProjectArchiveFixer:
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.creative_content_path = self.base_path / "knowledge/å¸‚åœºé¡¹ç›®æ¡£æ¡ˆ/åˆ›æ„å†…å®¹"
        self.fix_log = []
        
    def log_fix(self, action: str, details: str):
        """è®°å½•ä¿®å¤æ“ä½œ"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.fix_log.append(f"[{timestamp}] {action}: {details}")
        print(f"âœ… {action}: {details}")
    
    def detect_duplicate_files(self) -> Dict[str, List[str]]:
        """æ£€æµ‹é‡å¤æ–‡ä»¶"""
        duplicates = {}
        all_files = {}
        
        # æ‰«ææ‰€æœ‰mdæ–‡ä»¶
        for file_path in self.creative_content_path.rglob("*.md"):
            if file_path.name.startswith("."):  # è·³è¿‡éšè—æ–‡ä»¶
                continue
                
            # æå–é¡¹ç›®åç§°ï¼ˆæ–‡ä»¶åä¸­ç¬¬ä¸€ä¸ªè¿å­—ç¬¦å‰çš„éƒ¨åˆ†ï¼‰
            project_name = file_path.stem.split("-")[0].strip()
            
            if project_name not in all_files:
                all_files[project_name] = []
            all_files[project_name].append(str(file_path))
        
        # æ‰¾å‡ºé‡å¤çš„é¡¹ç›®
        for project_name, file_paths in all_files.items():
            if len(file_paths) > 1:
                duplicates[project_name] = file_paths
                
        return duplicates
    
    def analyze_file_content(self, file_path: str) -> Dict:
        """åˆ†ææ–‡ä»¶å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            analysis = {
                'file_path': file_path,
                'size': os.path.getsize(file_path),
                'lines': len(content.split('\n')),
                'update_date': None,
                'funding_info': None,
                'user_count': None
            }
            
            # æå–æ›´æ–°æ—¥æœŸ
            date_match = re.search(r'æ›´æ–°æ—¥æœŸ:\s*(\d{4}-\d{2}-\d{2})', content)
            if date_match:
                analysis['update_date'] = date_match.group(1)
            
            # æå–èèµ„ä¿¡æ¯
            funding_match = re.search(r'æ€»èèµ„.*?(\$[\d\.]+[MBK]?)', content)
            if funding_match:
                analysis['funding_info'] = funding_match.group(1)
            
            # æå–ç”¨æˆ·æ•°ä¿¡æ¯
            user_match = re.search(r'ç”¨æˆ·.*?(\d+[ä¸‡+]?)', content)
            if user_match:
                analysis['user_count'] = user_match.group(1)
            
            return analysis
        except Exception as e:
            return {'file_path': file_path, 'error': str(e)}
    
    def select_best_version(self, file_analyses: List[Dict]) -> str:
        """é€‰æ‹©æœ€ä½³ç‰ˆæœ¬çš„æ–‡ä»¶"""
        if not file_analyses:
            return None
            
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šæ›´æ–°æ—¥æœŸ > æ–‡ä»¶å¤§å° > è¡Œæ•°
        sorted_files = sorted(file_analyses, key=lambda x: (
            x.get('update_date', '1900-01-01'),
            x.get('size', 0),
            x.get('lines', 0)
        ), reverse=True)
        
        return sorted_files[0]['file_path']
    
    def categorize_files(self) -> Dict[str, List[str]]:
        """å°†æ–‡ä»¶æŒ‰å†…å®¹ç±»å‹åˆ†ç±»"""
        categories = {
            'å›¾åƒåˆ›ä½œ': [],
            'è§†é¢‘åˆ›ä½œ': [],
            'éŸ³é¢‘åˆ›ä½œ': [],
            '3Då†…å®¹ç”Ÿæˆ': [],
            'å…¶ä»–': []
        }
        
        # å…³é”®è¯æ˜ å°„
        keywords = {
            'å›¾åƒåˆ›ä½œ': ['å›¾åƒ', 'å›¾ç‰‡', 'è§†è§‰', 'æ‘„å½±', 'ç”»è´¨', 'åƒç´ ', 'çŸ¢é‡', 'å›¾æ ‡', 'Logo'],
            'è§†é¢‘åˆ›ä½œ': ['è§†é¢‘', 'Video', 'å‰ªè¾‘', 'åŠ¨ç”»', 'ç›´æ’­', 'çŸ­è§†é¢‘'],
            'éŸ³é¢‘åˆ›ä½œ': ['éŸ³é¢‘', 'Audio', 'éŸ³ä¹', 'è¯­éŸ³', 'æ’­å®¢', 'å£°éŸ³'],
            '3Då†…å®¹ç”Ÿæˆ': ['3D', 'ä¸‰ç»´', 'æ¨¡å‹', 'æ¸²æŸ“', 'è™šæ‹Ÿ', 'AR', 'VR']
        }
        
        for file_path in self.creative_content_path.glob("*.md"):
            if file_path.name.startswith("."):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ£€æŸ¥å†…å®¹ä¸­çš„å…³é”®è¯
                categorized = False
                for category, category_keywords in keywords.items():
                    if any(keyword in content for keyword in category_keywords):
                        categories[category].append(str(file_path))
                        categorized = True
                        break
                
                if not categorized:
                    categories['å…¶ä»–'].append(str(file_path))
                    
            except Exception as e:
                self.log_fix("é”™è¯¯", f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
                categories['å…¶ä»–'].append(str(file_path))
        
        return categories
    
    def standardize_naming(self, file_path: str) -> str:
        """æ ‡å‡†åŒ–æ–‡ä»¶å‘½å"""
        filename = Path(file_path).name
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼ˆé¡¹ç›®å-ä¸­æ–‡æè¿°.mdï¼‰
        if re.match(r'^[A-Za-z0-9\._-]+-.*\.md$', filename):
            return filename
        
        # æå–é¡¹ç›®åå’Œæè¿°
        project_name = filename.split('.')[0]
        
        # æ ¹æ®é¡¹ç›®åç”Ÿæˆæ ‡å‡†æè¿°
        descriptions = {
            'Recraft': 'AIå›¾åƒåˆ›ä½œå¹³å°',
            'Midjourney': 'AIè‰ºæœ¯ç”Ÿæˆä¸åˆ›æ„å·¥å…·',
            'GlassImaging': 'AIå›¾åƒå¤„ç†å¹³å°',
            'LumiAI': 'AIè§†è§‰è¯†åˆ«ä¸å¢å¼ºç°å®',
            'Fal.ai': 'AIç”Ÿæˆåª’ä½“å¹³å°',
            'Markable_AI': 'AIé©±åŠ¨åˆ›ä½œè€…å˜ç°å¹³å°',
            'Marbl': 'AIå“ç‰Œå†…å®¹å¹³å°',
            'Stability_AI': 'å¼€æºAIæ¨¡å‹ä¸ç”Ÿæˆå¹³å°',
            'Adobe': 'AIæ–‡æ¡£æ€»ç»“å·¥å…·'
        }
        
        description = descriptions.get(project_name, 'AIå¹³å°')
        new_filename = f"{project_name}-{description}.md"
        
        return new_filename
    
    def fix_duplicates(self):
        """ä¿®å¤é‡å¤æ–‡ä»¶"""
        duplicates = self.detect_duplicate_files()
        
        for project_name, file_paths in duplicates.items():
            self.log_fix("æ£€æµ‹åˆ°é‡å¤", f"é¡¹ç›® {project_name} æœ‰ {len(file_paths)} ä¸ªæ–‡ä»¶")
            
            # åˆ†ææ‰€æœ‰æ–‡ä»¶
            analyses = [self.analyze_file_content(fp) for fp in file_paths]
            
            # é€‰æ‹©æœ€ä½³ç‰ˆæœ¬
            best_file = self.select_best_version(analyses)
            if not best_file:
                continue
                
            # åˆ é™¤å…¶ä»–ç‰ˆæœ¬
            for file_path in file_paths:
                if file_path != best_file:
                    try:
                        os.remove(file_path)
                        self.log_fix("åˆ é™¤é‡å¤æ–‡ä»¶", f"åˆ é™¤ {file_path}")
                    except Exception as e:
                        self.log_fix("é”™è¯¯", f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def organize_files(self):
        """æ•´ç†æ–‡ä»¶åˆ°æ­£ç¡®çš„ç›®å½•"""
        categories = self.categorize_files()
        
        for category, file_paths in categories.items():
            if category == 'å…¶ä»–':
                continue
                
            category_dir = self.creative_content_path / category
            if not category_dir.exists():
                category_dir.mkdir()
            
            for file_path in file_paths:
                file_path_obj = Path(file_path)
                if file_path_obj.parent == self.creative_content_path:
                    # æ–‡ä»¶åœ¨ä¸»ç›®å½•ï¼Œéœ€è¦ç§»åŠ¨åˆ°å­ç›®å½•
                    new_path = category_dir / file_path_obj.name
                    try:
                        shutil.move(str(file_path), str(new_path))
                        self.log_fix("ç§»åŠ¨æ–‡ä»¶", f"{file_path_obj.name} -> {category}/")
                    except Exception as e:
                        self.log_fix("é”™è¯¯", f"ç§»åŠ¨æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def standardize_names(self):
        """æ ‡å‡†åŒ–æ–‡ä»¶å‘½å"""
        for file_path in self.creative_content_path.rglob("*.md"):
            if file_path.name.startswith("."):
                continue
                
            new_name = self.standardize_naming(str(file_path))
            if new_name != file_path.name:
                new_path = file_path.parent / new_name
                try:
                    file_path.rename(new_path)
                    self.log_fix("é‡å‘½å", f"{file_path.name} -> {new_name}")
                except Exception as e:
                    self.log_fix("é”™è¯¯", f"é‡å‘½åå¤±è´¥ {file_path}: {e}")
    
    def generate_report(self) -> str:
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        report = f"""
# é¡¹ç›®æ¡£æ¡ˆæ‰¹é‡ä¿®å¤æŠ¥å‘Š

## ä¿®å¤æ—¶é—´
{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ä¿®å¤æ“ä½œè®°å½•
"""
        
        for log_entry in self.fix_log:
            report += f"- {log_entry}\n"
        
        report += f"""
## å½“å‰æ–‡ä»¶ç»“æ„
"""
        
        # ç»Ÿè®¡å„ç›®å½•æ–‡ä»¶æ•°é‡
        for item in self.creative_content_path.iterdir():
            if item.is_dir():
                file_count = len(list(item.glob("*.md")))
                report += f"- {item.name}/: {file_count} ä¸ªæ–‡ä»¶\n"
            elif item.suffix == '.md':
                report += f"- {item.name}\n"
        
        return report
    
    def run_full_fix(self):
        """æ‰§è¡Œå®Œæ•´çš„ä¿®å¤æµç¨‹"""
        print("ğŸ”§ å¼€å§‹é¡¹ç›®æ¡£æ¡ˆæ‰¹é‡ä¿®å¤...")
        
        # 1. ä¿®å¤é‡å¤æ–‡ä»¶
        print("\nğŸ“‹ æ­¥éª¤1: æ£€æµ‹å’Œä¿®å¤é‡å¤æ–‡ä»¶")
        self.fix_duplicates()
        
        # 2. æ•´ç†æ–‡ä»¶åˆ†ç±»
        print("\nğŸ“ æ­¥éª¤2: æ•´ç†æ–‡ä»¶åˆ†ç±»")
        self.organize_files()
        
        # 3. æ ‡å‡†åŒ–å‘½å
        print("\nğŸ“ æ­¥éª¤3: æ ‡å‡†åŒ–æ–‡ä»¶å‘½å")
        self.standardize_names()
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“Š æ­¥éª¤4: ç”Ÿæˆä¿®å¤æŠ¥å‘Š")
        report = self.generate_report()
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self.creative_content_path / "ä¿®å¤æŠ¥å‘Š.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nâœ… ä¿®å¤å®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        return report

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®åŸºç¡€è·¯å¾„
    base_path = "/Users/dangsiyuan/Documents/obsidion/launch x"
    
    # åˆ›å»ºä¿®å¤å™¨å®ä¾‹
    fixer = ProjectArchiveFixer(base_path)
    
    # æ‰§è¡Œä¿®å¤
    report = fixer.run_full_fix()
    
    print("\n" + "="*50)
    print("ä¿®å¤æŠ¥å‘Šæ‘˜è¦:")
    print("="*50)
    print(report)

if __name__ == "__main__":
    main() 