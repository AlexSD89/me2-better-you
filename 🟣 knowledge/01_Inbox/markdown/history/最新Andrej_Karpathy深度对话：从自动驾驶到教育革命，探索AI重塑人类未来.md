天空之城城主 *2024年09月06日 08:04* *北京*

**未经许可不得转载，务必保留原文出处链接和公众号按钮**

（关注本城公众号并设为星🌟标，

第一时间获取最新顶级商业科技认知）

![图片](https://mmbiz.qpic.cn/mmbiz_png/V08icaMk7MVaVZaBItNiateE0x0lKBvFYUbJBA0NtOzhPhfb3SKKqNZAVu90Xls81mK8HgHWbk7KtdibhZOaS9NqQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

https://www.youtube.com/watch?v=hM\_h0UA7upI

文： 天空之城 ·城主  

在这场最新的面对面访谈中，AI领域的大神级人物Andrej Karpathy与NoPriors投资播客展开了一场关于人工智能现状和未来发展，及其对教育和认知影响的深度探讨。Karpathy凭借其在OpenAI、特斯拉等顶尖科技公司的丰富经验，输出了独特而深刻的见解。

访谈涵盖了广泛的主题，从自动驾驶技术的现状和未来，到AI研究的最新进展；从大语言模型的发展潜力，到AI在教育领域的革命性应用；从人机融合的可能性，到AI对人类认知和学习方式的深远影响。

Karpathy强调了AI不应该是取代人类，而是应该成为赋能人类的工具。他深入探讨了AI研究的技术细节，包括Transformer架构的重要性、合成数据的潜力与挑战、小型高效模型的发展前景等。在教育方面，Karpathy正在开发一个创新的AI驱动的教育平台，旨在为全球每个人提供高质量、个性化的教育体验。他对AI在改变学习动机、打破传统教育壁垒方面的潜力表示乐观。

自从OpenAI离职全心搞AI教育后，这是Andrej第一次出来专访，对于关心Andrej的同学们来说，这个访谈已经等太久了。

B站传送：【精校】AI大神Andrej Karpathy最新九月面对面访谈@NoPriors 【中英字幕】】

https://b23.tv/KZe39ww

  

本次访谈的重点内容：

**自动驾驶技术的现状与未来：**

Karpathy认为特斯拉在解决软件问题方面处于领先地位，而Waymo则面临硬件挑战。他预测特斯拉将在长期内占据优势，因为软件问题相对更容易解决。自动驾驶技术从演示到实际产品化经历了漫长的十年，但仍未实现真正的全球化。Karpathy认为自动驾驶领域的进展可以类比于AGI（通用人工智能）的发展。

**AI研究的现状与趋势：**

Transformer架构被视为重大突破，它解决了之前神经网络架构的许多限制。当前研究重点已转向数据集和损失函数的创新，而不是架构本身。合成数据在AI训练中被视为未来趋势，但需要小心处理以避免模型退化。Karpathy预测，未来的AI模型可能会更小、更高效，甚至可能只需10亿参数就能实现强大的认知功能。

**合成数据与AI训练：**

合成数据被视为解决AI训练数据不足问题的重要方法。然而Karpathy警告说，使用合成数据时需要谨慎，以避免模型的隐性退化。他提出了在合成数据中注入熵的重要性，以保持数据的多样性和丰富性。

**小型高效模型的未来：**

Karpathy预测，未来可能会出现参数量大大减少但功能强大的AI模型。他认为，当前的大型模型可能浪费了大量容量来记忆不重要的信息。未来的AI系统可能更像是一个由多个专门化小模型组成的"生态系统"，而不是单一的大模型。

**AI在教育领域的革命性应用，教育动机和未来方向：**

Karpathy正在开发一个以AI为基础的全球化教育平台，旨在为每个人提供高质量的个性化教育。他认为AI可以实现教育的真正个性化，适应不同学习者的背景和需求。AI教育助手可以扮演类似于个人导师的角色，大幅提高学习效率。Karpathy认为教育不应该仅仅是娱乐，而应该是一种挑战性的、塑造思维的过程。

谈话探讨了AI如何改变学习动机，以及在后AGI时代，教育可能更多地成为一种娱乐和自我提升的方式。Karpathy强调了文化环境对学习动机和职业选择的重要影响。他希望AI教育能够打破传统的精英主义和血统观念，使高质量教育更加民主化。

Karpathy强调，数学、物理和计算机科学仍将是塑造思维能力的核心学科，对于未来世界至关重要。他建议年轻人应该专注于培养解决问题的能力和逻辑思维，而不是仅仅积累知识。Karpathy预见未来的教育将更加灵活，人们会更频繁地回到"学校"学习新技能。

  

\-=Web3天空之城书面全文版（1.6万字）=-

NoPriors：

今天我们和 Andrej Karpathy 一起聊天，他不需要再多介绍。Andrej 是著名的研究员，备受喜爱的人工智能教育家，是 OpenAI 的早期团队成员，曾担任特斯拉 Autopilot 的负责人，现在致力于教育领域的人工智能。我们将与他讨论研究现状，他的新公司，以及我们对人工智能的期望。

非常感谢你今天加入我们，很高兴你能来。

Andrej：

谢谢，我很高兴来到这里。

  

NoPriors：

你曾领导特斯拉的 Autopilot，现在我们确实有了完全自动驾驶的汽车，道路上的乘用车。你如何看待当前的能力集，我们应该多快看到能力的提升或普及的乘用车？

Andrej：

是的，我在自动驾驶领域可能花了大约五年的时间。我认为这是一个迷人的领域。目前在这个领域发生的事情是，我确实认为我会从自动驾驶中找到很多类比，我会说，类似于 AGI，而这可能是因为我熟悉这个领域。但我有点觉得我们在自动驾驶方面已经有一点达到了 AGI，因为现在有一些系统，你可以基本上带着它们四处转转，并作为付费客户使用。在旧金山，Waymo 当然非常常见。你可能也坐过 Waymo。我坐过很多次，非常惊人，它可以带你四处转转，而你是以产品的形式付费的。

有趣的是，我第一次坐 Waymo 实际上是十年前，几乎正好是2014年左右。是一位在那儿工作的朋友给我做了一个演示。十年前它带我绕着街区开了一圈，基本上是一次完美的驾驶。花了十年从我看到的演示变成一个我可以付费使用的产品，而且是在城市规模内扩展，等等。

  

NoPriors：

你认为其中有多少是由于监管因素，而多大程度是技术因素？你认为技术什么时候准备好？是最近吗？

Andrej：

我认为是技术。你不可能在30分钟的一次演示驾驶中看到全部情况。你不会遇到他们十年来必须应对的所有问题。所以演示和产品之间存在巨大的差距。我认为其中很多与法规等方面有关。但我确实认为，我们在这种意义上在自动驾驶领域达到了 AGI 的一点点成就。尽管如此，我认为真正令人着迷的是全球化根本没有发生。所以你有一个演示，你可以在南方使用它，但世界还没有改变。这需要很长时间。所以从演示到实际全球化，我认为那里还有个巨大差距。我会说，这与 AGI 相关，因为我怀疑当我们得到 AGI 时，它看起来会很相似。在自动驾驶领域，人们普遍认为Waymo领先于Tesla。但我个人认为，Tesla实际上领先于Waymo。尽管这看起来并非如此，但我对特斯拉及其自动驾驶计划非常看好。

我认为特斯拉面临的是软件问题，而Waymo面临的是硬件问题。在我看来，软件问题要容易解决得多。特斯拉已经在全球部署了大量汽车，规模宏大，而我认为Waymo需要达到这一点。因此，一旦特斯拉能够真正部署并且正常工作，我认为这将是非常令人难以置信的。

我昨天刚试驾了最新版本的特斯拉自动驾驶系统，现在它已经可以把我带到任何地方了。我不得不说，他们最近有了非常好的改进。是的，我最近一直在使用它，它实际上运行得相当好。昨天它为我完成了一次神奇的驾驶，所以我对团队的工作印象深刻。

所以我仍然认为特斯拉主要面临的是软件问题，而Waymo主要面临的是硬件问题。虽然目前看起来Waymo有些领先，但我认为当我们在10年后回顾时，谁真正实现了规模化，谁的收入来源最多，从这个角度来看，我仍然认为特斯拉领先。

  

NoPriors：

你认为我们离解决软件问题的转折点有多远，何时才能达到某种程度的相等性？

显然，如果你看Waymo的车，它有很多非常昂贵的LiDAR和其他传感器，这些传感器支持了其软件系统。而特斯拉的方法是只用摄像头，这样可以有效地去除大量的成本和复杂性，并且可以应用于多种不同类型的车。你认为这种转变什么时候会发生？

Andrej：

希望在未来几年左右。

但实际上，真正有趣的是，我不确定人们是否意识到特斯拉其实也使用了很多昂贵的传感器。他们只是在训练时使用这些传感器。所以有一堆装有LiDAR的车子在行驶。他们做了许多无法扩展的事情，还有额外的传感器等等。他们进行地图绘制和所有这些工作。在训练阶段完成这些工作，然后将其浓缩成一个部署到车上的仅基于视觉的测试包。这就像是在传感器和成本上的套利。

我认为这实际上是一种很聪明的策略，但还没有被充分理解。我认为这会有很好的效果，因为像素已经包含了信息。我认为网络会有能力做到这一点。在训练阶段，这些传感器确实有用，但在测试阶段它们并不那么有用。

  

NoPriors：

似乎另一个正在发生的转变是从许多边界情况设计启发式方法向端到端深度学习的转变。这就是最近发生的另一个转变。你要谈谈这个问题，并且介绍一下这个吗？

Andrej：

是的，我认为这一直是特斯拉从一开始就计划好的。我在谈论神经网络如何能够逐步取代整个栈。因为当我加入时，有大量的C++代码。而现在，在车上运行的测试包中，C++代码已经少了很多。我们没有谈论后端的那些大量内容，神经网络有点像穿过系统。

首先，它只是在图像层面做检测。然后它处理多张图像，给你一个预测。随着时间的推移，多个图像给你一个预测。你正在丢弃C++代码，最终只是发出转向命令。所以我认为特斯拉是在逐步取代整个栈。

我的理解是现在的Waymo实际上不是这样，他们尝试过，但最终没有实现，这是我目前的理解。但我不确定，因为他们没有谈论这个问题。但我从根本上相信这种方法。如果你这样考虑的话，我认为这是最后一块拼图。

我确实怀疑，像特斯拉这样的端到端系统在大约10年内，就是一个神经网络。意思是，视频流进入一个神经网络，然后输出指令。你必须逐步建立起来，一步步来。即使所有的中间预测和我们所做的所有事情，我认为它们实际上并没有误导开发。我认为它们是其中的一部分，因为这有很多微妙的原因。

实际上，像端到端驾驶，当你只是模仿人类等行为时，你用很少的监督信息来训练一个庞大的神经网络。训练这么多亿个参数信号太少了。所以这些中间表示等有助于你开发所有特征和检测器，然后让端到端的部分问题变得容易得多。

所以我怀疑，虽然我不确定，因为我不是团队的一员，但有大量的预训练正在进行，以便你可以进行端到端的微调。所以基本上，我觉得有必要逐步地推进。这就是特斯拉所做的。我认为这是正确的方法。看起来它正在发挥作用。所以我真的很期待。

  

NoPriors：

如果你从头到尾开始做，你无论如何都不会有数据。这说得通。

你离开之前在特斯拉的人形机器人项目上做过工作。我有很多问题，其中一个是从这里开始。有什么可以转移的？

Andrej：

基本上，所有东西都可以转移。而且我认为人们并没有意识到这一点。

NoPriors：

好的。这是一个很大的声明。这看起来是一个完全不同的问题。

Andrej：

我认为汽车在实际观察时基本上就是机器人。汽车是机器人。

我认为特斯拉不是一家汽车公司，这种看法是误导性的。特斯拉是一家规模化的机器人公司。规模化也是一个完全独立的变量。他们不是在制造单一的产品，而是在制造制造产品的机器，这是一个完全不同的事情。所以我认为特斯拉是一家规模化的机器人公司。

从汽车到人形机器人之间的转变实际上并不费劲。早期版本的Optimus机器人，它以为自己是辆车，因为它有完全相同的电脑和摄像头。这真的很有趣，因为我们在机器人上运行汽车网络，而它在办公室走来走去。它试图识别可驾驶空间，但现在我想都是可行走的空间了。实际上，它有点泛化了，需要进行一些微调。它认为自己是在驾驶，但实际上是在穿越一个环境。

  

NoPriors：

一种合理的方式来看待这件事，实际上，它是一个机器人，很多东西可以转移，但比如说你缺少执行和行动数据。

Andrej：

是的，你肯定会缺少一些组件。但我还想说的是，很多东西是可以转移的，比如说Optimus的启动速度，对我来说非常令人印象深刻。因为Elon一说我们要做这个，大家就带着所有合适的工具出现了。所有东西很快就出现了，所有这些CAD模型和供应链的东西。我感觉，哇，Tesla内部有这么多构建机器人方面的专业知识。而且用的工具都是一样的。就好像在重新配置，从一辆汽车变成《Transformer》电影里的那种。它们只是被重新配置和重新洗牌，但就像是同样的东西。你需要所有相同的组件，你需要考虑所有相同种类的东西，无论是在硬件方面、规模方面，还是在智能方面。

关于智能，有很多的转移，不仅是特定网络的转移，还有整个方法、标签团队以及所有协调和人们采用的方法。我只是觉得有很多的转移。

  

NoPriors：

但你认为人形机器人或人形设备的第一个应用领域会是什么？

Andrej：

我认为很多人有这样的愿景，比如说做洗衣服等等。我认为那会来得很晚。我不认为B2C是一个正确的起点，因为我不认为我们可以让机器人像是撞伤奶奶，这就是我的看法，有点像是这样的。我觉得这会涉及太多的法律责任。我认为这不是正确的方法。但比如说一个非常诡异的拥抱。它只会倒下之类的事情，你知道的，这些东西还不完美，需要一些工作才能改进。我认为最好的客户首先是你自己。特斯拉可能会采取这种方式。如果人们能看得出来，我对特斯拉非常看好。

第一个客户是你自己，你在工厂里孵化它，可能进行大量的物料处理等工作。这样，你不必与第三方合作签订合同，避免了涉及律师等繁琐的事情。你孵化它，然后第二步是B2B。你去那些有巨大仓库的公司，我们可以进行物料处理，起草合同，安装围栏，完成所有这些事情。

当你在多家公司孵化后，我认为那时候你才开始进入B2C应用。我确实认为我们还会看到B2C机器人，比如Unitree等公司开始推出我非常想要的机器人。有一个G1机器人，我可能会买一个，而且可能会有一个人在那些平台上建立起来的生态系统。

在规模上的优势可能会使这种方法获胜。但一开始，这涉及很多的物料处理，然后逐渐向越来越多的具体应用发展。我真正感兴趣的是Friedman关于树叶吹机的挑战。我会很喜欢看到一个乐观主义者走在街上，小心翼翼地捡起每一片树叶，这样我们就不需要树叶吹机了。我认为这是可行的，并且是一个惊人的任务。所以我希望这是其中一个最早的应用。或者就算是耙叶也可以，那也应该行得通，只是非常安静地耙叶。

  

NoPriors：

他们确实有一个正在工作的机器，只是不是类人机器人。我们可以谈一谈类人机器人这个论点吗？最简单的解释是这个世界是为人类而建的，你只需要建造一套硬件，正确的做法是建立一个可以在这套硬件上完成越来越多任务的模型。

还有另一种观点认为人类在任何特定任务上都不是最优的。你可以让他们更强大、更大、更小，或者其他任何方式，那为什么我们不做超级人类的事情呢？

Andrej：

对此，我认为人们可能低估了进入任何单一平台的固定成本的复杂性。你为任何单一平台支付了大量的固定成本，因此，集中化并拥有一个可以完成所有任务的平台是非常有意义的。类人外形也非常吸引人，因为人们可以非常容易地进行远程操作。因此，这是一种非常有用的数据收集方式，因为人们显然能够很容易地进行远程操作。我认为这一点通常被忽视。当然，还有你提到的为人类设计的世界等方面，所以我觉得这也很重要。

我认为我们将在类人平台上有一些变种，但任何平台都有很大的固定成本。最后一个方面是，你可以从不同任务之间的迁移学习中受益良多。在人工智能中，你希望有一个单一的神经网络，它是多任务的，能够处理很多事情。这就是你获得所有智能和能力的地方。这也是为什么语言模型如此有趣的原因，因为你有一个单一的体系，比如文本领域，在执行所有这些不同的问题时，它们之间共享知识，而且这一切都耦合在一个神经网络中。我认为你需要那样的平台。你希望为捡叶子收集的所有数据能为所有其他任务带来收益。如果你为某个单一用途构建一个特殊的东西，你不会从所有其他任务的转换中受益。

  

NoPriors：

是的，我认为有一种说法是，G1大约是30Grand，但似乎很难在某个特定的物料清单（BOM）下构建一个非常有能力的类人机器人。如果你想在轮子上装一个能做事情的手臂，也许在开始时有更便宜的通用平台方法。这对你有意义吗？

Andrej：

更便宜的通用平台方法？从硬件的角度来看，是的，我认为这有意义。你可以给它装一个轮子而不是脚，等等。

我确实感觉……我想知道这是否会有点陷入局部最小值。我只是觉得，选择一个平台并使其完美，是长期来看相当不错的赌注。另外一件事是，我觉得这会让人们感到熟悉，我认为人们会理解你可能想与它交流。我觉得这其中的心理层面因素可能会更倾向于人类平台，除非人们害怕它并且更喜欢一个更加抽象的平台。不过我不知道这是否会只是一个类似八轮怪物在做事情，我不知道这会不会让人觉得更吸引或者更少吸引。

  

NoPriors：

有趣的是，我认为Unitree的另一种形式是狗，而且这几乎是一个更友好或更熟悉的形象。

Andrej：

是的，但随后人们看《黑镜》，突然这只狗变得像一个可怕的东西。所以，很难想透。我只是认为从心理学上讲，人们会很容易理解正在发生的事情。

  

NoPriors：

你认为相对于证明这个未来，技术里缺少了什么里程碑？

Andrej：特指机器人吗？

NoPriors：是的，特指机器人。或者是人形机器人或其他任何人类形态的东西？

Andrej：

我不确定我是否对这个问题有十分清晰的看法。我确实认为在人形机器人这种形态中，对于下半身的控制，我不确定是否适合通过示范进行模仿学习。因为下半身涉及很多倒立摆控制等复杂问题。而对于上半身，则需要大量的远程操作、数据收集和端到端的处理。因此，在这个意义上，一切都变得非常混合化。

我不清楚这些系统是如何互动的。

  

NoPriors：

当我与这个领域的专家交谈时，他们很多关注的是执行机构、操作以及某种数字操作等。

Andrej：

我预计在一开始，大部分项目是通过远程操作来启动，模仿它，直到能达到95%的成功率。然后谈到人对机器人的比例，逐渐让人们成为机器人的监督者，而不是直接执行任务。这些变化都会随着时间的推移逐步发生。

我不知道是否有任何我特别熟悉的具体障碍。我只是觉得这需要很多繁重的工作。很多工具已经可以使用。Transformers 是一个美丽的组织块，你可以用它做任意的任务。你只需要数据，把它以正确的形式输入，训练它，进行实验，部署它，不断迭代。这确实是很多繁重的工作。我不知道是否存在某个单独的技术性问题会阻碍我们的进步。

  

NoPriors：

我们现在的大块研究处于什么状态？

Andrej：

我们处于非常好的状态。我认为，也许还没有完全被认可，但 Transformer 确实非常了不起。它不仅仅是另一个神经网络，而是一个非常通用的神经网络。例如，当人们谈论神经网络中的缩放损失时，缩放损失在很大程度上实际上是Transformer的特性。在Transformer之前，人们在玩LSTM和堆叠它们等。你实际上得不到清晰的缩放损失，这个东西实际上无法训练，也不起作用。是Transformer首次实现了真正的缩放，你得到了缩放损失，一切都变得合理了。

所以它就像是一个通用的训练计算机。我把它看作是一种计算机，但它就像一个可微的计算机。你可以给它输入和输出，以及上亿的数据，然后你可以用反向传播来训练它，它实际上会自我安排去完成任务。我认为这实际上是我们在算法领域偶然发现的一个神奇的东西。

其中有一些个别的创新。例如，残差连接已经存在了。你有需要插入的层标准化。你有注意力模块。你没有那些像tanh之类的饱和非线性，因为它们会消除梯度信号，所以在Transformer中没有这些。所以有几项创新，大约四或五个，都被整合到这个Transformer中。这就是谷歌在他们的论文中所做的。这种方法实际上已经被训练出来了。突然间，你获得了缩放损失，并且有了一个可以在很大程度上训练的结构。这是一个重大的突破。

  

NoPriors：

你觉得我们还没有达到这种突破的极限，因为当然会有关于数据壁垒以及规模进一步发展的成本问题的讨论。你怎么看这个问题？

Andrej：

我们开始进入的领域是，我不认为神经网络架构再从根本上限制我们了。它已经不是瓶颈了。以前Transformer是一种瓶颈，但现在它已经不再是瓶颈了。现在我们更多地在讨论什么是损失函数，数据集在哪里。这些问题几乎成为了瓶颈。

这不再是一个基于你想要它变成什么而重新配置的通用组织。这就是为什么许多活动已经转移到了这个领域。很多公司和其他应用这种技术的企业不再怎么考虑Transformer了。他们不再怎么考虑架构。

Llama的发布中，Transformer并没有太大的变化。我们增加了RoPE相对位置编码，这是主要的变化。其他一切都无关紧要，像是一些小东西的3%的提升而已。但实际上，RoPE是唯一插入的东西。这就是Transformer在过去五年左右的变化。所以在这方面没有太多的创新。大家都认为这是理所当然的，让我们训练它，等等。然后大家主要在数据集和损失函数的细节上进行创新。所以所有的活动都集中在那里了。

  

NoPriors：

在那个领域，以前我们用的是互联网数据，现在互联网数据已经用完了。所以问题主要围绕合成数据或者更昂贵的数据收集。

Andrej：

我觉得这是个好观点。现在很多活动都在大型语言模型（LLM）方面。互联网数据不是你想要的用于训练你的Transformer的数据。它像是一个最近邻，实际上让你走得更远，令人惊讶。但互联网数据是一堆互联网网页，你真正想要的是你大脑里的内心独白，你大脑中的轨迹。在你解决问题时，大脑中的路径，如果我们有十亿个这样的路径，比如AGI就在这里，大致来说，这在很大程度上是准确的。而我们根本没有这种情况。

所以现在很多活动所在的领域，我认为，是通过互联网数据来实现接近这一点，因为互联网碰巧有足够的推理痕迹和大量的知识，加上变换器使其工作的还不错。我认为现在很多活动集中在将数据集重构为内心独白格式。大量合成数据的生成对此很有帮助。有趣的是，当前的模型在多大程度上帮助我们创建下一代模型，就像是一种改进的阶梯。

  

NoPriors：

你认为合成数据有多大用处，或者说能带我们走多远？因为正如你所说，每个数据、每个模型都有助于更好地训练后续模型，至少在创建工具、数据标注等方面，也许部分是合成数据。你认为合成数据的部分有多重要？

Andrej：

当我和人们谈话时，他们说，是的，我认为这是我们能够取得进展的唯一途径，我们必须让它发挥作用。但在使用合成数据时，你必须小心，因为这些模型会悄无声息地退化。这是一个主要问题之一。

如果你去ChatGPT并让它告诉你一个笑话，你会发现它只知道大约三个笑话。这就像是唯一的情况，它大多数时候只给你一个笑话，有时候会给你大约三个笑话。这是因为模型退化了，而且退化得悄无声息。

当你看任何单一的输出时，你只看到了一个单一的例子。但当你实际查看分布时，你会注意到这不是一个非常多样化的分布，悄无声息地退化了。当你进行合成数据生成时，这是一个问题，因为你实际上非常需要那种熵。你需要数据集中有丰富的多样性和丰富性，否则，你得到的数据集会变得收缩。当你查看任何单个示例时，你看不到它，但分布已经失去了大量的熵和丰富性，所以它在无声中变得更糟。

这就是为什么你必须非常小心，必须确保在数据集中保持熵。为此有很多技术。例如，有人发布了Persona数据集作为示例。Persona数据集是一个包含十亿个个性特征的数据集，像人的背景：“我是老师”或者“我是艺术家”，“我住在这里，我做这件事”等等。它就像是虚构的人类背景的小段落。

当你进行合成数据生成时，不只是说，完成这个任务并用这种方式做，而是想象你在向这个人描述，并加入这些信息，现在你迫使它探索更多空间，并获得一些熵。所以你必须非常小心地注入熵，保持分布。我认为这是困难的部分，也许人们一般不会充分意识到这一点。

所以我基本上认为合成数据绝对是未来，我的印象是我们不会缺乏数据。我只是觉得你必须小心。

  

NoPriors：

你觉得我们现在从这项研究中学到了什么关于人类认知的东西？

我不知道我们是否在学习……有人可以争辩说，弄清我们想要的推理轨迹的形状，例如，有助于实际理解大脑的运作方式。

Andrej：

我会小心对待类比，但总的来说，我确实认为这是完全不同的事物。不过，有些类比还是可以做的。

举个例子，我认为Transformer在很多方面实际上比人脑更好。它们实际上是一个更高效的系统。它们不如人脑工作的原因主要是数据问题，大体上说，这是我认为的一阶近似。

事实上，Transformer记忆序列的能力远远超过人类。比如，如果你给它一个序列，并在该序列中进行一次前向和反向传播传递，那么如果你给它序列的前几个元素，它会完成序列的其余部分。它记住了那个序列，而且它对这个非常擅长。如果你给人类一次演示一个序列，人类是绝对记不住的。

因此，我确实认为，基于梯度的优化，我们在训练神经网络时一直进行的前向-反向更新，在某些方面实际上比人脑更高效。这些模型更好，但它们还没有准备好大放异彩。在许多认知方面，我认为它们可能会突出。只要有了正确的输入，它们会变得更好。

  

NoPriors：

这是计算机在各种应用中都具有的算术能力，不是吗？

Andrej：

我认为人类的大脑有很多限制。工作记忆非常小，而Transformers有更大得多的工作记忆，这将继续保持下去。它们是更高效的学习者。人脑在各种限制下运作，不明显的是人脑是否使用反向传播，也不明显那将如何工作。它是一个非常随机的动态系统，在各种限制条件下工作，包括环境条件等等。

所以，我确实认为我们实际拥有的东西潜力上比大脑更好，只不过还没达到那一步。

  

NoPriors：

您如何看待随着时间的推移，人类与不同的AI系统的增强？您认为这是一个可能的发展方向吗？用AI模型增强人类？

Andrej：

我认为总体来说，绝对是这样。

NoPriors：

因为，有一种抽象的版本，你将其用作工具，那是外部版本。还有，合并的场景，很多人最终谈到这个。

Andrej：

我们已经在某种程度上融合了。问题是，有输入输出的瓶颈。但大多数情况下，如果你有这些模型中的任何一个，你已经在使用它们了。

NoPriors：

是的，但那有点不一样，因为我想人们已经争论了40到50年，认为科技工具只是人类能力的延伸。计算机是人类思维的自行车，等等。

Andrej：对，正是这样。

  

NoPriors：

但是，有一部分AI社区认为，我们可以通过某种形式解决与未来AI或其他事物的潜在冲突。例如，像Neuralink的提议，等等。

Andrej：

没错，就是这样。我还不知道这种合并会是什么样子，但我肯定能看出你想要减少工具使用的输入输出。我认为这有点像一个外皮层。我们是在我们的新皮层上构建，不是吗？这只是下一层。它恰好在云中，等等。但它是大脑的下一层。

  

NoPriors：

早在2000年代初的《Accelerando》一书中就有一个版本，基本上所有东西都体现在一副计算眼镜中，这副眼镜与您的大脑连接，并且您佩戴它们。如果你失去了它们，你就会觉得失去了一部分个性或记忆。

Andrej：

我认为这很有可能。今天，手机几乎已经是这样了。我认为情况会变得更糟。当你把你的科技产品放在一边时，你就像大自然中的裸体人类，或者你失去了部分智慧。这非常令人焦虑。

  

NoPriors：

一个非常简单的例子就是地图。我注意到现在很多人其实不再能很好地导航他们的城市，因为他们总是使用转弯提示方向。

Andrej：

如果我们有这样一个东西，比如说通用翻译器，我认为离这不远了。如果你把你的东西放在一边，你就会失去与不讲英语的人交流的能力。

NoPriors：

我很乐意重新利用我大脑的那部分来做进一步的研究。

Andrej：

我不知道你是否看过那个视频，就像有个孩子，他拿着一本杂志，却在杂志上滑动。令我着迷的是，这个孩子不理解什么是自然存在的，什么是技术附加在自然之上的，因为它变得如此透明。我认为这看起来可能类似，人们将开始假设这些工具的存在。然后，当你把它们拿走时，你会意识到，人们好像不知道什么是技术，什么不是。

如果你戴着这个东西，它总是在为你翻译所有人或者为你做类似的事情，那么可能人们就会失去基本的认知能力。我认为存在这种可能性。

我们将会专精化。你不能理解说西班牙语的人吗？这是什么情况？或者，当你去到物体面前，就像在迪士尼，所有的物体都是有生命的。我认为我们可能会走向那样一个世界，为什么不能和物体说话呢？就像今天，你可以和Alexa说话，向她询问一些事情等等。

NoPriors：

我见过一些玩具公司，它们试图在玩具中嵌入一个大语言模型（LLM），以便能够与孩子互动。

Andrej：

是不是很奇怪，当你走到一扇门前，不能直接说“开门”？另一个我喜欢的例子是《超能敢死队》或《机械公敌》，有人取笑说你不能随便和东西对话，真是见鬼了。

  

NoPriors：

如果我们在谈论外部大脑，这是一件非常重要的事情，需要将其民主化。你怎么看当前的市场结构以及在大规模语言模型研究中发生的事情？实际上，只有少数几家大型实验室有机会在下一代训练中取得进展。这对于未来人们能够访问的技术来说意味着什么？

Andrej：

你可能在暗示的是生态系统的状态。我们有几个封闭平台形成的寡头垄断，同时也有相对落后的开源平台，比如Meta Llama等。这反映了开源生态系统的状况。

当我们开始把这些东西看作是一个外部大脑时，有一句加密货币的说法叫“没有你的密钥，就没有你的Token”。如果说，这就像“不是你的权重，就不是你的大脑”？

NoPriors：

这很有趣，因为一个公司实际上在控制你的外皮质，因此很大一部分你的……

Andrej：

这开始感觉有点侵入性了。如果这是我的外皮质，我认为人们会更加在意所有权，是的。 你意识到你是在租用你的大脑。 似乎租用你的大脑有点奇怪。

NoPriors：

这个思想实验就像是，你愿意放弃所有权和控制权来租用一个更好的大脑吗？因为我愿意，是的。所以我认为这是一个权衡，我们会看看这如何运作。

Andrej：

也许有可能默认使用封闭版本，因为它们很出色，但你可以在各种情况下有一个后备方案。我认为这有点像今天事情的发展。就像当一些封闭源提供商的API宕机时，人们开始实现对开放生态系统的后备方案，他们完全控制并感到由此而来的赋权。所以，这也许就是对大脑未来样子的扩展，如果发生了什么事情，你就依靠开源资源。但是大多数时候，你其实……

  

NoPriors：所以开源资源持续进步非常重要。

Andrej：

我认为是这样，百分之百。这不是一个显而易见的观点，或者现在人们可能不一定同意的事情，但我百分之百认为是这样。

  

NoPriors：

我一直在想的是，最小的、高效的模型是什么，你可以在某种意义上达到，无论是参数大小还是你想怎么考虑？还有就是你的观点，因为你对蒸馏、小模型有很多思考，我有些好奇。

Andrej：

我认为它可以出奇地小。而且我确实认为当前的模型浪费了大量容量来记住不重要的东西。比如，它们记住了 SHA 哈希码，记住了一些古老的东西……因为数据集没有得到最好的整理。

我认为这种情况会有所改变。我们只需要到达认知核心。我认为认知核心可以非常小，它只是一个会思考的东西。如果它需要查找信息，它知道如何使用不同的工具。

  

NoPriors：那是像30亿参数吗？是20亿吗？

Andrej：

我认为甚至10亿。10亿就足够了。我们可能会达到那一点。模型可以非常非常小。我认为它们可以非常小的原因根本上，就像蒸馏一样。蒸馏出乎意料地有效。蒸馏是你得到一个非常大的模型或者大量的计算资源之类的东西，监督一个非常小的模型。你实际上可以把很多功能塞进一个非常小的模型里。

  

NoPriors：

这是某种数学表示或信息理论公式吗？因为几乎感觉你现在应该能够计算这个。

Andrej：

可能吧。也许可以这样考虑这个问题：我们回到互联网数据集，这是我们正在处理的东西。互联网大约是0.001%的认知，99.99%的信息垃圾。我认为大部分信息对思考部分没有用。

  

NoPriors：

也许换个方式来问这个问题就是，有没有一种数学表示形式可以体现认知能力相对于模型大小的关系？或者你如何在你想要达成的目标中捕捉认知，知道这是最小值或最大值？也许没有一个好的方式来表示这一点。

所以我认为也许十亿参数可以获得一个不错的认知核心。

Andrej：

我认为即使是十亿参数也太多了。我不知道。我们拭目以待。

NoPriors：

考虑到设备边缘与云端的区别，以及使用模型的原始成本，一切都很令人兴奋。但是在不到十亿个参数的情况下，我也在本地设备上有我的外脑。

Andrej：

可能不是一个单一的模型，对我来说，思考这实际上会如何发展是很有趣的，因为我认为你想要从并行处理中受益。你不想有一个顺序过程，你想要有一个并行过程。我认为公司在某种程度上也有点像工作的并行化。但公司中有一个层级结构，因为这是组织内进行信息处理和简化所需要的一种方法。所以我认为我们最终可能会拥有一个大语言模型公司的结构。我认为你拥有各种不同能力、专注于独特领域的模型并不是什么不太可能的事情。这将实际上在很大程度上开始类似于公司。程序员和项目经理等角色在并行工作，并为你协同运算。因此，也许这样思考是不正确的。它更像是一个蜂群。你的外皮层就像是一个大型语言模型的蜂群。这更像是一个生态系统，就像一个生物生态系统，你在其中有专门的角色和生态位。我认为它将开始趋同那样。你有自动地将问题上升到蜂群的其它部分，具体取决于问题的难度。所以也许CEO就像一个非常聪明的云模型，但工人可以便宜得多，甚至可能是开源模型或其他什么的。而我的成本函数与你的成本函数不同。所以这可能会很有趣。

  

NoPriors：

你离开了OpenAI，从事教育工作。你一直是一名教育者。那么，为什么要这样做？

Andrej：

我的起点是，我一直是一名教育者，我热爱学习，也热爱教学。这是一个我长期以来一直非常热衷的领域。另一件事是，我认为有一个宏观的图景在推动我，我认为在AI领域有很多活动。而且我认为大多数是想要取代或替代人类。这主题就像是把人滑到一旁。但我总是对能赋能人的任何事物更感兴趣。从一个更高的层面看，我是站在人类一边。我对AI能做什么来赋能人类感兴趣。我不希望未来人们只是处于自动化的一边。我希望人们处于一种非常有权能的状态。我希望他们变得非常出色，比今天出色得多。

另一个非常有趣的方面是，如果一个人有全科的完美导师，他们能走多远？我认为如果人们有完美的课程安排，他们可以走得非常远。我们看到了这一点，假如有些富人可能有导师，他们确实走得很远。所以我认为我们可以通过AI甚至LexarPassive接近这一点。

  

NoPriors：

实际上，从80年代开始就有非常明确的文献支持这一点，一对一的辅导可以帮助人们提高一个标准差。是布鲁姆的东西。有很多非常有趣的先例。

你如何通过AI的视角来看待这一点？或者说，什么样的第一类产品能真正帮助实现这一点？因为有像《钻石时代》这样的书，他们讨论了《年轻女士的插图入门》之类的东西。

Andrej：

所以我会说，我肯定受到它某些方面的启发。在实际操作中，我正在尝试建立一个单一的课程，希望它能成为人们学习AI时的首选课程。我认为基本问题在于如何扩大这些课程的规模。例如，我曾在斯坦福教授过231N，这是第一门深度学习课程，并且相当成功。但问题是，如何真正扩大这些课程的规模？如何让地球上的80亿人都能受益？他们讲不同的语言，能力水平各不相同，单个教师无法覆盖如此广泛的受众。

因此，问题在于如何使用AI来扩大一个优秀教师的影响力。我这样思考这个问题：老师负责大量的课程创建和设计，因为以目前的AI能力，我不认为这些模型能够创建一个好的课程。但我认为它们适合成为学生的前端，向他们解释课程内容。基本上，老师不再直接面对学生，而是在后台设计课程材料，AI则作为前端，能够说各种不同的语言，引导学生完成整个课程。

  

NoPriors：这种情况可以理解为类似助教（TA）的体验吗？

Andrej：

AI助教作为学生的前端，与学生互动并引导他们完成课程。我认为这是可以解决的，尽管现在还不存在，但它可以变得非常好。随着时间的推移和能力的提高，课程设置可能会以各种方式重构。

我喜欢找到一些东西，今天的人工智能能力和对它有一个良好的模型。我认为很多公司可能并不直观地理解今天的能力在哪里，最终会构建一些超前于现有能力的东西，或者可能不够雄心勃勃。因此，我确实认为这是一个可能性与真正有趣和激动人心的结合点。

  

NoPriors：

回到你刚才提到的某件事，我觉得非常鼓舞人心，特别是考虑到你的背景以及你对我们目前研究状况的理解。基本上，我们不知道从学习的角度来看人类表现的极限是什么。考虑到更好的工具，这里有一个很简单的类比。我们一个月前刚刚举办了奥运会，一个跑者以及最好的英里时间或者任何体育运动，今天的水平比以前好多了。抛开像10年前的兴奋剂不谈，仅仅因为你开始训练得更早，拥有一个非常不同的计划，我们有更好的科学理解，我们有技术，我们有装备。

你相信如果我们从工具和课程开始，人类可以取得更大进步，这一点令人惊叹。

Andrej：

是的，我认为我们甚至还没有触及到可能实现的任何一部分。所以我认为基本上有两个维度。第一个是全球化的维度，我希望每个人都能接受到真正优质的教育，另一个是一个人可以走多远。我认为这两个问题都非常有趣且令人兴奋。

  

NoPriors：

通常，当人们谈论一对一学习时，他们关注的是其自适应性，即在挑战与其水平相当的人。你认为今天可以用人工智能实现这一点吗？还是说这是未来的事情，今天更多的是扩大影响力、多语言和全球化？

Andrej：

显而易见的是，诸如不同语言之类的事情非常容易实现。我认为当前的模型在翻译方面实际上非常好，基本上可以实时定位和翻译材料。所以很多事情都是显而易见且容易实现的。

根据一个人的背景进行适应，我觉得这不像是容易摘到的果实，但也不至于难到遥不可及。不过这确实是你需要的东西，因为并不是每个人都有相同的背景。而且，如果你过去熟悉其他学科，利用你知道的东西来做类比也是非常有帮助的。这在教育中非常强大，所以这是一个你想要利用的维度。但我认为这开始变得不那么显而易见，需要一些工作。

一个简单的版本不会太难，你可以想象只是提示模型，比如“哦，我懂物理”或者“我懂这个”。你可能会得到一些东西。但我指的是一些真正有用的东西，不是那种你可以演示，有时能工作的东西。我指的是它真的起作用，并且以一种人的方式起作用。

  

NoPriors：

这就是为什么我问到适应性的问题，因为人们学习的速度不同，或者有些事物他们觉得有挑战性，而其他人则不然，反之亦然。在这种情况下，你怎么去调整呢？我猜你可以随着时间推移，将某人在某方面的优劣重新引入到模型中。

Andrej：

这就是人工智能的特点。我觉得很多这些功能就像提示一样。所以你总是会看到演示，但你真的会得到一个产品吗？你知道我的意思吗？在这个意义上，我会说演示很近，但产品还很远。

  

NoPriors：

我们之前讨论过的一件有趣的事情是，研究界发生的某种血统关系。你来自某些实验室，每个人都在谈论彼此来自哪个实验室。我认为有相当高比例的诺贝尔奖得主实际上曾经在前诺贝尔奖得主的实验室工作过。所以这大概是某种文化、知识或品牌的传播，不知道是哪一种。在一个以AI教育为中心的世界里，你如何保持谱系，或者这并不重要？或者你如何看待这些关于网络和知识传播方面的问题？

Andrej：

我其实不想生活在一个非常看重谱系的世界里，所以我希望AI可以帮助你稍微打破这种结构。这感觉有点像某种稀缺资源的把关机制，好像是说，有有限数量的人拥有这个谱系等等。我认为这有点像是某种方面的表现。

我希望它能够打破这种结构。

  

NoPriors：

这确实是一个方面，比如实际学习的一部分谱系。

这也像是聚集效应。为什么所有或者大部分的AI社区都在湾区？为什么大部分的金融科技社区都在纽约？

我认为很多时候是因为你把一些有共同兴趣和信念的聪明人聚集在一起，他们从这个共同核心中延伸出来，然后以一种有趣的方式分享知识。

你必须在某种程度上让这种行为转移到线上，尤其是对年轻人而言。

Andrej：

其中一个方面有点像教育方面。比如今天如果你是某个社区的一员，你会获得大量的教育和学徒机会等，这非常有帮助，会让你在那个领域达到一种有权能的状态。

另一个方面是文化方面的，也就是你受什么激励以及你想要从事什么工作。文化重视什么、推崇什么、奉什么为神圣？

在学术界，举例来说，就是H指数。每个人都关心H指数，你发表的论文数量等等。我曾是那个社区的一员，我见证了这一点。

我感觉现在我到了不同的地方，各个社区都有不同的偶像。我认为这对人们的动机、他们的社会地位以及他们真正关心的事物产生了巨大的影响。

我还觉得我曾是不同社区的一部分，比如在斯洛伐克长大，那是一个非常不同的环境，在加拿大也是一个非常不同的环境。

在那里重要的是什么？冰球。

举个例子，我会说在加拿大，我在多伦多大学和多伦多。我不认为它是一个非常具有企业家精神的环境。根本不会想到你应该创业。人们不这么做。你不会有朋友在做这个。你也不知道你应该仰望它。人们不会读所有这些创始人们的书籍然后讨论他们。这根本不是你向往或在意的事情。

每个人都在谈论的是，你在哪里找到了实习？你以后打算去哪儿工作？而且大家似乎都接受有一套固定的公司列表，你应该从中选择并与其中一家对齐。这就是你仰望或者追求的目标。

所以这些文化方面的因素非常强大，可能实际上是主要的变量。因为我几乎觉得，如今教育方面的问题已经相对容易了，比如说有大量的资源已经可用，等等。

所以我认为主要是你所身处的文化环境。

  

NoPriors：

在这一点上，我们几周前聊的一个话题是，我记得你也在网上发过，学习和娱乐是有区别的。学习确实应该是困难的。我认为这涉及到地位的问题，地位是一个伟大的激励因素，比如说谁是偶像。

你认为，通过这样的系统，在动机方面你能够改变多少，如果这是一个阻碍因素？你是否专注于给予人们资源，使他们能够在自己的能力范围内尽可能地在过程中走得更远，比历史上的任何时候都更进一步，已经是鼓舞人心？或者你实际上是想改变有多少人愿意学习，或者至少激励他们走上学习的道路？

Andrej：

"愿意"是一个有负担的词。我会说，我想让学习变得容易得多。然后可能会有人不愿意学习。今天，比如人们为了实际原因愿意学习，比如他们想找到工作等等，这是完全有道理的。所以在一个前AGI社会中，教育是有用的。我认为人们会因此而有动机，因为他们在经济上不断攀升等等。

  

NoPriors：

但在后AGI社会，我认为教育在很大程度上将是一种娱乐。包括像成功的结果教育，不仅仅是让内容从你身上流过。

Andrej：

是的，我认为是这样的。结果就像理解、学习、能够贡献新知识，或者你如何定义它。

NoPriors：

我认为这不是偶然的，如果你回到200年前、300年前，那些做科学的人是贵族或有钱人。我们都会成为与安德烈一起学习的贵族。

Andrej：

是的。我确实认为我看到它非常类似于你之前的引用。我觉得学习某些东西有点像去健身房，但这是对大脑的锻炼，就像去健身房的感觉。去健身房是很有趣的。人们喜欢举重等。有些人不去健身房。不，不。有些人去，但需要努力。是的。是的，需要努力，但它是努力的，同时也有点有趣。你也有一个回报，比如你在各方面对自己感觉良好，而且我认为教育基本上等同于那样的感觉。

所以这就是我说教育不应该是有趣的时候的意思，等等。这有点有趣，但我认为这是一种特定的乐趣，我确实认为，也许在一个后AGI的世界里，我希望发生的是人们实际上，他们确实经常去健身房，不仅是身体上的，还包括精神上的。这是我们仰望的东西，有很高的教育程度。

  

Priors：

我可以问你关于Eureka的最后一个问题吗，只是因为我觉得这会让人们感兴趣。比如第一个课程的受众是谁？

Andrej：

第一个课程的受众，我主要认为这是一个本科水平的课程。所以如果你在技术领域读本科，我认为这将是一个理想的受众。我确实认为我们现在看到的是一种陈旧的教育概念：你上学，然后毕业去工作。显然，这样的模式在一个变化如此迅速的社会里会完全崩溃。随着科技的快速发展，人们会更加频繁地回到学校学习。

这种学习有点像本科的水平，但我认为任何年龄段的人都在范围之内。年龄上会非常多样化，但主要是那些技术性的人，他们大多数是真正想要了解不少内容的人。

  

NoPriors：他们什么时候可以上这门课？

Andrej：

我希望是在今年年底。我确实有很多干扰正在积累，但我认为明年初可能是个时间节点。我在努力把它做好，这确实需要时间才能完成。

  

NoPriors：

我还有最后一个相关的问题。如果你今天有小孩子，你认为他们应该学习什么以确保一个有用的未来？

Andrej:

在我看来，有一个正确的答案。 **正确答案大概是数学、物理、计算机科学这些学科。** 我这么说的原因是因为我认为它对思维能力有帮助，这是最佳的思维技能核心。

当然，我有特定的背景，所以我会这么想，这只是我的看法。我觉得我上过的物理课和其他课都塑造了我的思维方式，这对解决问题非常有用，总的来说等等。如果我们处在一个AGI前的世界，这会有用。在AGI之后，你仍然希望有能力的人类可以在任何任意能力中发挥作用。所以我认为这是对人们的正确答案，他们应该做和学的事情，要么有用，要么好。

我认为很多其他的东西你可以稍后再添加，但在人们有大量时间和注意力的关键时期，应该主要用来做这些简单操作密集型的任务和工作负载，而不是记忆密集型的任务和工作负载。我学的是数学学位，觉得在学习的过程中，感觉自己的大脑正在开辟一条新沟槽，而且这种沟槽在以后会更难开辟。

当然，我还会把很多其他东西也加入进来，比如，我并不排斥所有其他学科。我认为拥有多样性的事物其实是很美的，但我确实认为其中的80%应该像这样。

  

NoPriors：

首先，与我们的工具相比，我们不是有效的记忆者。

谢谢你做这件事，真是太有趣了。

Andrej：很高兴来到这里。

  

  

素材来源官方媒体/网络新闻素材来源官方媒体/网络新闻 继续滑动看下一个

向上滑动看下一个 [知道了](https://mp.weixin.qq.com/s/) ： ， ， ， ， ， ， ， ， ， ， ， ， 。 视频 小程序 赞 ，轻点两下取消赞 在看 ，轻点两下取消在看 分享 留言 收藏 听过