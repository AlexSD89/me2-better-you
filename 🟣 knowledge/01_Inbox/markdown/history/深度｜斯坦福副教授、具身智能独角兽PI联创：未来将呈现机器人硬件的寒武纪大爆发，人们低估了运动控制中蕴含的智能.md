---
source: "https://mp.weixin.qq.com/s/d2XKV_BtTluxQwwIjJdu0A"
created: 2025-05-04
---
No Priors *2025年05月04日 13:11*

![图片](https://mmbiz.qpic.cn/mmbiz_png/ib38wYqSEotBzrEIlTbOB0F21M8ugYLwThaxnJelFounf5y2ccKxia2bkDunbwNQlv3cicsGlXnYchLQrxcUFhfzA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

图片来源： No Priors

**Z Highlights**

- 传统的机器人研究往往专注于某一个具体应用场景，但这种方法很难推广到更广泛的任务。研究人员往往会在单一应用上深挖，但一旦想要扩展到其他任务，就会陷入瓶颈。我们认为，最大限度地利用所有可用数据才是关键。跨不同平台的数据可以传递丰富的信息，让模型的泛化能力更强。 **我们希望打造的通用机器人，本质上是一个 “ 基础模型 ” ，能够驱动下一代现实世界的机器人技术。**
- 目前机器人研究最重点的部分是获取更加多样化的机器人数据，如果我们希望机器人能够在现实世界中有效运作，它们就必须具备适应不同环境的能力。我们需要让机器人进入各种不同的环境中采集数据。我认为，优化数据采集能力非常重要。 **如果我们能达到数据充裕的程度，那么问题就归结为研究、计算能力和评估。**
- 现在，人工智能社区对语言模型、视觉 \- 语言模型等方向关注很多，大家都在想着 “ 让我们创造出最聪明的 AI” 。 **但我觉得，人们低估了运动控制中蕴含的智能** 。人类从婴儿时期起就不断训练自己的低阶运动能力，而机器人则需要从自身的物理体验中学习。
- 我无法确定未来会是什么样，但我倾向于认为， **未来的机器人世界将呈现出极其丰富的多样性** ，就像 “ 机器人硬件的寒武纪大爆发 ” 。一旦技术成熟，我们可能会看到各式各样的机器人形态。

*Chelsea Finn 是 Physical Intelligence （ PI ）的联合创始人，她现任斯坦福大学计算机科学与电子工程系副教授，曾就职于 Google Brain 。她在斯坦福大学期间开发的遥操作系统（ teleoperation structure ）在 Mobile ALOHA 机器人上的应用被认为是通用智能技术的里程碑之一。本文为 Chelsea Finn 和自媒体创作者 Elad Gil 在 No Priors 播客节目上的对话实录。*

**Chelsea 的机器人研究之路**

**Elad Gil ：** Chelsea ，非常感谢你今天做客《 No Priors 》。

**Chelsea Finn ：** 谢谢你们的邀请。

**Elad Gil ：** 你在机器人领域的研究可谓声名卓著，无论是在 Google ，还是在斯坦福，都做出了重要贡献。我很想先了解一下你的研究历程 —— 你是如何踏入这个领域的？最初吸引你的是什么？你曾参与过哪些重要的项目？

**Chelsea Finn ：** 是啊，回首这一路，确实走了很久。起初我是被机器人可能带来的影响所吸引了，但与此同时，我也对如何在机器中建立感知和智能这一问题充满好奇。机器人恰恰是这一切的最佳载体。此外，这个领域里也有许多有趣的数学问题，能让大脑保持活跃，时刻思考。这些都让我觉得从事这项研究非常有趣。

我真正开始认真研究机器人是在十多年前，也就是在加州大学伯克利分校攻读博士学位的时候。那时，我们在研究神经网络控制，试图训练神经网络，让它能够直接从图像像素映射到机器人手臂的电机力矩。当时，这种做法并不流行，但今天来看，这已经成为机器人领域的主流研究方向之一，也吸引了众多关注。

在那个起点上，我就意识到 —— 我们可以训练机器人完成令人惊叹的任务， **但要让机器人能在各种场景、不同物体之间通用地执行这些任务，才是真正的巨大挑战。** 十年前，我们训练机器人拧瓶盖、用铲子将物体放入碗中、精准地插入某些物体，甚至让它挂衣架。看上去这些任务已经很 “ 酷 ” 了，但当你尝试让机器人在不同的环境、面对不同物体都能完成这些任务时，才会意识到挑战有多大。

因此，我开始思考如何扩大数据集，训练机器人适应更广泛的任务场景，并尝试不同的学习方法 —— 强化学习、视频预测、模仿学习等等。

在博士毕业后，我曾在 Google Brain 工作了一年，然后回到斯坦福成为教授，创立了自己的实验室，继续围绕这些方向展开研究。最近，我又创立了 Physical Intelligence ，至今已接近一年，因此目前暂离斯坦福，专注于这家公司。不过，我仍在指导斯坦福的学生，与学术界保持联系。

**Physical Intelligence ：让机器人通用化**

**Elad Gil ：** 太有趣了！你们创立 Physical Intelligence 时，和四位联合创始人以及一支极为出色的团队一起，提出了一个相当独特的思路。能否和我们分享一下 PI 正在研究的核心方向？你们的方法有什么特别之处？

**Chelsea Finn ：** 我们的目标是打造一个庞大的神经网络模型，最终能够控制任何机器人，在任何环境下完成任何任务。

传统的机器人研究往往专注于某一个具体应用场景，但这种方法很难推广到更广泛的任务。研究人员往往会在单一应用上深挖，但一旦想要扩展到其他任务，就会陷入瓶颈，难以突破。而 Physical Intelligence 旨在从根本上解决这个更广泛的问题 —— 让机器人真正具备通用智能。

与其他机器人公司不同，我们认为，最大限度地利用所有可用数据才是关键。而这不仅仅意味着利用单一机器人的数据，还包括整合来自不同机器人平台的数据。不论是六轴关节、七轴关节、双臂、单臂，我们都发现，跨不同平台的数据可以传递丰富的信息，让模型的泛化能力更强。

此外，在机器人平台迭代时，我们不希望旧数据被浪费。过去，我们常常遭遇这样的困境：当机器人的新版本发布时，以前训练好的模型就会无法兼容，导致整个学习过程推倒重来。这种代价太大了。 **因此，我们希望打造的通用机器人，本质上是一个 “ 基础模型 ” ，能够驱动下一代现实世界的机器人技术。**

**通向机器人 “ 大模型 ” 的道路**

**Elad Gil ：** 听起来，你们的思路和语言模型的发展路径有相似之处，比如大规模数据训练、 Transformer 架构、迁移学习等。能否详细谈谈你们的技术架构？你们如何设计这个 “ 基础模型 ” ？

**Chelsea Finn ：** 在最初阶段，我们的核心任务是扩大数据收集规模。不同于语言模型，我们并没有一个机器人动作的 Wikipedia ，也没有遍布网络的海量机器人运动数据。因此，我们非常关注如何在现实世界中扩大数据收集，因为真实数据一直是推动机器学习突破的关键。

去年 10 月，我们发布了一些初步成果，展示了如何扩展机器人数据，以及如何让机器人学习执行复杂任务，例如叠衣服、擦桌子、组装纸箱等。

当前，我们的研究正进一步聚焦于语言交互和环境泛化能力。去年 10 月的实验中，机器人只是在单一环境下训练，并在同一环境中测试。虽然它可以学习叠从未见过的衬衫，但泛化能力仍然有限，无法真正 “ 理解 ” 指令，而只能执行训练数据中出现过的任务。因此，扩展指令理解能力和泛化能力，成为了我们的重要研究方向。

在架构上，我们使用 Transformer 和预训练视觉 \- 语言模型，这让我们能够充分利用互联网上的丰富信息。几年前，我们的研究表明 —— **如果你使用视觉 \- 语言模型，那么即便机器人从未在训练数据中见过某个概念，它仍然可以理解并执行相应任务。**

举个有趣的例子 —— 如果你让机器人把猫罐头递给 Taylor Swift ，尽管它从未见过 Taylor 本人，但因为互联网充满了 Taylor Swift 的图片，机器人可以利用预训练模型的权重，推理出猫罐头应该递给 Taylor ，而不需要从零开始学习。这让我们在构建通用机器人智能的道路上，迈出了重要一步。

**Elad Gil ：** 实现通用性的核心基础究竟是什么？是进一步扩展数据规模，还是增加计算资源，亦或是某种后训练的方式？我只是有些好奇，毕竟当前大家关注的方向大致如此。但在语言模型领域，人们已经投入了大量精力研究推理模块等方面。您认为目前机器人领域缺失的关键要素是什么呢？

**Chelsea Finn ：** 我认为最重要的一点 —— 尽管听上去有些无聊 —— 就是获取更加多样化的机器人数据。去年 10 月底的那次发布，我们的数据采集仅涵盖了三座建筑。当然，互联网作为语言模型的驱动力，提供了极其庞大的数据来源。而视觉模型的数据来源则远远更加丰富，因为互联网上的图片和文本均由世界各地的人们贡献而成。因此， **我们需要在更多不同的场所采集数据，涉及更多种类的物体、任务，不仅要扩大数据的数量，更要提升数据的多样性，这一点至关重要。** 我们目前的重点正是让机器人进入各种不同的环境中，采集数据。

除此之外，我们在这个过程中还意外收获了一点，那就是学习如何让机器人在不同场所运行并发挥作用。这实际上是一个令人愉快的副产品，因为如果我们希望机器人能够在现实世界中有效运作，它们就必须具备适应不同环境的能力。因此，数据的多样性是首要任务。当然，我们也在探索其他方法，比如利用人类的视频数据、网络数据、预训练模型，并在一定程度上考虑推理能力，尽管目前更多是基础层面的推理。

例如，让机器人把一件脏衬衫放进洗衣篮。如果它能识别出衬衫和洗衣篮的位置，并理解如何完成这一任务，那就是一种推理能力。同样，假设机器人要制作一份三明治，而用户有特定的要求，比如对酸黄瓜过敏，那么机器人就应该推理出不能在三明治里放酸黄瓜。这类基本推理能力是我们正在研究的方向，但归根结底，最关键的还是获得更加多样化的机器人数据。

**开源 vs. 封闭**

**Elad Gil ：** 到目前为止，你们采取的主要策略似乎是开源模式，为机器人领域提供模型和软件包。您认为这是一条长期可行的路径吗？还是更倾向于 “ 开源核心 ” 模式，或者最终会转向专有模型？毕竟，现在有几家机器人公司正在采取不同的策略 —— 有的公司专注于软硬件结合，有的专注于特定的硬件平台，还有的则只提供软件，并且选择开源或封闭的模式。我想了解，在这条光谱上，你们的公司处于什么位置？

**Chelsea Finn ：** 我们一直非常开放。不仅开源了部分模型权重，并在技术论文中详细介绍了相关内容，我们还与硬件公司合作，向它们提供机器人设计方案。

有些人听到后会非常震惊，问： “ 知识产权怎么办？机密性怎么办？ ” 但这其实是我们经过深思熟虑后做出的决定。主要有几个原因。

首先，我们认为这个领域仍处于起步阶段，而未来三年内，这些模型和机器人都将大幅提升。 **我们希望推动研究进展，支持整个社区，促进机器人的发展。这样，当我们真正开发出通用型模型时，世界已经为它们做好了准备** —— 有更加完善的机器人来运用这些模型，也有更多专业人才掌握如何利用这些模型。

其次，我们拥有一支出色的研究团队和工程师，而优秀的工程师更愿意在开放的环境中工作，尤其是研究人员，他们希望自己的成果被认可，并能够自由分享和讨论自己的想法。因此，我们认为，吸引最优秀的研究人员和工程师是解决这一问题的关键。

最后，我要强调的是，我们最大的风险不是竞争对手，而是这个问题无法得到解决。这才是我们真正担忧的。

**Elad Gil ：** 有意思，为什么您会担心这个问题？

**Chelsea Finn ：** 因为机器人是一门极具挑战性的学科，历史上失败的案例数不胜数。与识别图像中的物体不同，机器人对错误的容忍度极低 —— 如果它抓取物体时稍有偏差，哪怕只是微小的接触误差，都可能导致整个操作失败。这只是一个例子。此外，数据采集方面也存在挑战，而涉及硬件的任何事情都远比纯软件复杂得多。

**Elad Gil ：** 不过，现在已有不少机器人在现实世界中发挥作用，比如飞机自动驾驶、物流中心的分拣机器人、制造业的机械臂等。这些都是在受控环境中运行的机器人，应用场景较为明确。而从您的观点来看，机器人在短期内最可能在哪些领域实现突破？毕竟，有些任务对错误的容忍度极低，而另一些任务则可以通过约束问题的范围，使其在模型能力范围内顺利完成。那么，您认为 PI 或机器人领域的新方法，最有可能首先在哪些场景中取得实质性进展？

**Chelsea Finn ：** 作为一家公司，我们真正关注的是长期问题，而不是某个特定的应用，因为当你专注于单一应用时，可能会出现失败模式。我认为一个实际的挑战是，在机器学习中，许多成功的应用，比如推荐系统、语言模型、图像检测等，往往是由人类来消费这些模型的输出 —— 人类擅长这类事情。而机器人在很多自然的应用场景下，通常是自主执行任务，并不依赖于人类来消费它的指令，比如机械臂的移动指令，并不会像语言模型那样被人类直接消费、检查和验证。

我认为我们需要思考新的方式，不同场景中的容错率，亦或是人类与机器人可以协同工作的方式。我觉得这将是一个重大挑战，也正是我们在语言交互方面研究的动机之一 —— **我们希望人类能够通过输入指令，决定他们希望机器人如何行动、执行哪些任务，以及如何在特定场景下提供帮助** ，这是至关重要的。

**通用人形机器人与具身智能**

**Elad Gil ：** 另一种通用化的形式 —— 至少在我们当前的世界中 —— 就是人形机器人，对吧？因此，有些人专门关注人形机器人，比如特斯拉和其他公司，认为 “ 世界是为人类设计的 ” ，因此，人形机器人是与人类共存的最佳形态。但也有人采取了截然不同的方式，比如认为需要某种更专门针对家庭、工厂或制造业等特定环境的机器人。你对人形机器人和其他形态的机器人怎么看？

**Chelsea Finn ：** 我认为人形机器人确实很酷，我在斯坦福的实验室里就有一个。但另方面，我觉得它们有些被高估了。实际一点来说，目前我们在数据方面相当受限。有些人认为，人形机器人因为形态与人类相似，所以可能更容易收集数据，更容易模仿人类。我确实听过这样的观点。但如果你真的尝试过远程操作人形机器人，就会发现它实际上比静态机械臂或轮式移动机器人要难得多。

**我认为，优化数据采集能力非常重要。如果我们能达到数据充裕的程度，那么问题就归结为研究、计算能力和评估。** 因此，我们正在优化这一点 —— 我们选择使用成本较低的机器人，以及那些可以轻松开发远程操作界面的机器人，使得远程操作变得更快捷，并能够收集多样化的数据。

**Elad Gil ：** 这让我想起了之前爆火的那个金 · 卡戴珊的假视频，视频里她去购物，身后跟着一个机器人，帮她提着所有的购物袋。当我看到那个视频时，我就特别想要一个人形机器人一直跟着我，感觉会很好玩。所以，我希望有一天，我能用你们的软件让机器人跟着我，到处做各种事情。那么，在这些研究中，你怎么看待具身智能（ embodied intelligence ）模型的发展？这似乎是另一种技术路线，有些人在这个问题上做出了不同的选择。

**Chelsea Finn ：** 现在，人工智能社区对语言模型、视觉 \- 语言模型等方向关注很多，这个领域确实有很大热度，大家都在想着 “ 让我们创造出最聪明的 AI” 。 **但我觉得，人们低估了运动控制中蕴含的智能。**

我们能像现在这样使用双手，是经过数百万年的进化才达成的，而即便是经历了漫长进化的动物中，仍有许多无法做到这一点。因此，我认为，在执行一些看似简单的任务 —— 比如倒一碗麦片、倒一杯水 —— 时，其实涉及了极大的复杂性和智能。从某种角度来看，我觉得具身智能或物理智能（ physical intelligence ）是智能的核心，甚至可能比某些非具身模型更被低估了。

**Elad Gil ：** 在过去几年里，我最喜欢的机器人论文之一是你的 Aloha 论文，我觉得那是一个非常巧妙的方法。在过去两三年间，有哪些研究促成了这一领域的快速发展？我感觉现在有很多人在这个领域创业，大家都觉得这是一个值得投入的时机。你认为有哪些关键的研究推动了这一变化，使得人们认为这是一个值得投入的方向？

**机器人研究的关键节点**

**Chelsea Finn ：** 至少对我来说，有几个关键的转折点，标志着这个领域的发展速度远超以往：

一个是 SayCan 研究，它表明我们可以使用语言模型进行高层规划，然后将其与底层模型结合，使机器人能够执行长时任务。另一个是 Archi Tool 研究，它证明了我们可以利用大量的网络数据进行更好的泛化，例如之前提到 Taylor Swift 的案例。第三个是我们的 RT-X 研究，我们成功地在不同机器人形态上训练模型，并整合了多个研究实验室的数据。这是一个巨大的工程，我们把所有实验室的机器人数据整合到一个通用格式里进行训练。当我们训练完成后，可以将一个模型的检查点发送到千里之外的实验室，而那里的研究生在机器人上运行这个模型时，往往能得到比他们自己迭代出的模型更好的效果。

这表明，这项技术确实开始奏效了，跨机器人数据共享能带来实际收益。你还提到了 Aloha 研究，后来的移动 Aloha 研究表明，我们可以通过远程操作，让模型学习相当复杂的灵巧操作任务。此外，我们还进行了一项后续研究，探索如何让机器人系鞋带 —— 这个项目很有趣，因为当时有教授说，如果机器人能系鞋带，他就退休。

**Elad Gil ：** 他后来退休了吗？

**Chelsea Finn ：** （笑）他并没有退休。

**Elad Gil ：** 不行，我们得想办法让他退休！我们应该跟进这个事。（笑）

**Chelsea Finn ：** 是啊，不过这只是一些例子。我觉得这个领域已经取得了巨大的进展。在我们创立 PI 之后，很多人也将此视为一个信号 —— 当专家们愿意为这个领域下注时，或许真的会发生一些重大变革。

**Elad Gil ：** 那么，今天 PI 你们发布的一项新技术是 “ 分层交互机器人 ” （ Hierarchical Interactive Robot, HI Robot ），能和我们详细聊聊这个吗？

**层级交互机器人与决策制定**

**Chelsea Finn ：** 这个项目真的很有趣，我们关注了两个方面。首先，当任务的时间跨度较长，比如需要几分钟才能完成，那么仅仅依靠单一的策略来根据图像输出动作可能效果并不理想。比如，如果你想让机器人制作一个三明治，而它只是逐步输出下一个动作指令，那可能会不够高效。而如果机器人能按照一套完整的步骤来思考和执行任务，效果可能会更好。这就是我们引入层级架构的原因。

其次，在训练机器人策略时，通常我们会对数据进行标注，比如 “ 拿起海绵 ”“ 把碗放进垃圾桶 ”“ 折叠衣服 ” ，然后训练出一个可以执行这些指令的策略。但最终，我们并不希望机器人只能执行固定指令，而是希望它能与我们互动。例如，当我们说 “ 我是素食主义者，你可以给我做一个三明治吗？ ” 或者 “ 我对酸黄瓜过敏，所以别放进去 ” ，机器人能够理解并调整行动。甚至在过程中，我们可能会临时更改指令，比如： “ 等等，不要加番茄了。 ”

**从 “ 执行简单指令 ” 到 “ 处理个性化需求和实时调整 ” ，这之间存在着巨大的差距。因此，我们设计了一套系统，包含两个模型。第一个模型根据用户的指令进行推理，决定下一步动作，例如 “ 拿起番茄 ” 。第二个模型则负责执行具体的运动指令，比如如何操控机械臂来抓取番茄。**

这个项目的过程让人兴奋。首先，看到机器人可以按照不同的需求制作素食三明治、火腿奶酪三明治，甚至还能进行杂货购物和餐桌清洁，真的很酷。其次，我们认为这确实是一个合理的解决方案，能够有效提升机器人的任务执行能力。

**数据输入的选择**

**Elad Gil ：** 在技术能力方面，我很好奇目前机器人使用的传感器够不够全面？以自动驾驶为例，一些公司不仅依赖视觉，还会使用雷达等传感器来增强系统能力。那么在机器人领域，我们是否还缺少某些关键的传感器？未来是否应该引入新的输入或反馈机制？

**Chelsea Finn ：** 目前，我们主要依靠视觉，尤其是 RGB 摄像头。通常，机器人会配备外部摄像头来观察环境，同时在机械臂的腕部也会安装摄像头。这种配置已经能够支持许多复杂任务。我个人希望能给机器人配备 “ 皮肤 ” ，但现有的触觉传感器要么不够耐用，要么过于昂贵，要么分辨率太低，因此在硬件层面还有很多挑战。不过，我们发现，在腕部安装 RGB 摄像头，实际上可以提供许多与触觉传感器相似的信息，因此目前这已是一个有效的替代方案。

**Elad Gil ：** 确实，人类拥有很多感知系统，比如触觉、温度感知等等。这些在机器人上是否都需要实现？如果我们以人类或动物为参照，有哪些感知能力是机器人必须具备的？

**Chelsea Finn ：** 这是个有趣的问题，比如在制作三明治时，我们可能希望机器人能 “ 尝 ” 一下，判断三明治是否合格。

**Elad Gil ：** 或者至少应该能 “ 闻 ” 一下味道，对吧？

**Chelsea Finn ：** 是的，我曾向我们的另一位创始人， Sergey （ ZP 注： Sergey Levine 目前任教于加州大学伯克利分校电气工程与计算机科学系，以在强化学习和机器人方面的广泛研究而闻名），提出过加入嗅觉功能的想法，毕竟嗅觉在很多情况下非常有用。尽管我们目前还没有尝试，但在未来这可能是一种不错的补充。冗余感知有时也很重要，比如听觉可以帮助我们发现异常情况，比如当某个物体掉落时，即使视觉没有捕捉到，听觉也能提供警示信息。

**不过，目前我们认为机器人智能的研究瓶颈不在于传感器，而是数据和架构设计。更重要的是，我们的策略模型目前没有 “ 记忆 ”** ，它们只能根据当前图像进行决策，甚至无法记住半秒钟前的情况。因此，我认为在添加更多传感器之前，更值得优先解决的问题是如何让模型拥有更强的记忆能力。事实上，即使不增加额外的传感器，我们仍然可以在许多领域开发出实用的机器人。

**自动驾驶 vs. 机器人市场**

**Elad Gil ：** 你认为机器人行业的发展模式是否会像自动驾驶行业一样？十几年前，自动驾驶领域曾涌现出许多初创公司，但如今市场基本被 Waymo 和特斯拉主导，其他大多数公司要么消失，要么被整合。机器人行业是否也会经历类似的整合趋势？现有的主要玩家是否已经占据了主导地位？

**Chelsea Finn ：** 如果你在一年前问我，我的回答可能会完全不同。最近，我们看到许多新的公司进入这个领域。我认为， 10 年前自动驾驶的技术还不成熟，而深度学习在这段时间取得了巨大进步，这种情况在机器人行业同样适用。如果你在 5 到 10 年前问我，我会说时机还太早，技术还不到位。其实，现在我们可能仍然处于 “ 太早 ” 的阶段，毕竟机器人要在物理世界中实现智能是极其困难的。自动驾驶的艰难发展过程已经证明了这一点。

至于行业格局，大公司确实拥有大量资金，因此能够长期投入，但它们的步伐通常会较慢。相比之下，初创公司虽然资源有限，但能更快速地推进项目，减少官僚程序的干扰。比如，在 Google 工作时，我们几乎不可能把机器人带出公司，因为涉及代码安全问题。然而，对于数据收集来说，在不同环境下测试机器人是非常重要的。因此，在这一领域，小公司或许更具灵活性和优势。

**给机器人创业者的建议**

**Chelsea Finn ：** 我认为，如果有人想要创办一家机器人公司，我的主要建议是尽可能快速地学习，并迅速部署产品，在实践中学习并不断迭代。这可能是最重要的建议。尽快让机器人进入实际环境，从中汲取经验。

当然，我也不确定自己是否是给创业者提供建议的最佳人选 —— 毕竟我自己才当了 11 个月的企业家。但这大概是我能给出的建议。

**Elad Gil ：** 这很棒啊！你在运营一家极具前景的初创公司，所以我认为你完全有资格为这个领域的创业者提供建议。最近我听说有一些团队在训练机器人模型时，会利用人类的观察数据作为训练集的一部分，比如从 YouTube 视频中提取信息，或者专门录制数据用于训练。你如何看待这种方法？

**数据观察与数据生成**

**Chelsea Finn ：** 我认为这些数据确实有很大的价值，但如果单纯依赖它们，可能难以走得太远。其实，这里可以做一些很有趣的类比。例如，如果你观看奥运会游泳比赛，即便你拥有和运动员相同的体能，仅仅通过观察他们的动作，你依然无法学会如何游泳。因为游泳不仅仅是力量的问题，而是需要练习如何控制自己的肌肉，才能完成那些动作。类似地，如果你想学会打网球，仅仅观看职业选手比赛并不能让你掌握技巧。

或许这些例子看起来有些夸张，因为它们涉及的是顶级运动员。但我之所以用这些比喻，是因为人类在运动控制方面已经是专家了，我们从婴儿时期起就不断训练自己的低阶运动能力，而机器人却完全不同。 **机器人需要从自身的物理体验中学习，而不仅仅是观察数据。** 因此，尽管观察数据可以帮助机器人扩展已有的经验，但它自身的实践数据才是不可或缺的。

**Elad Gil ：** 在这些案例中，数据的生成方式是怎样的？是机器人自己探索生成，还是人类引导它们完成某些动作？因为你刚才提到的 “ 可迁移性 ” 很有意思，哪些数据是具备可迁移性的，哪些不是呢？

**Chelsea Finn ：** 我们收集数据的方式有点像 “ 操控木偶 ” 。就像在 Aloha 研究中，我们记录了机器人执行任务时的所有数据，包括电机指令、传感器数据和摄像机图像，这些都是机器人的 “ 体验 ” 。

此外，自动化体验也会发挥重要作用。就像语言模型在初始训练后可以使用强化学习来自我优化一样，机器人模型也可以通过自主训练来增强自身能力。

至于哪些数据是可迁移的，哪些不是，这主要取决于数据的分布范围。但衡量这种 “ 广度 ” 其实并不容易。我们很难精确定义两个任务之间的差异，或者两座厨房环境的不同程度。但我们可以通过某些指标来粗略估计，比如数据涉及的建筑数量、场景的多样性等。

**Elad Gil ：** 我们刚才聊了很多关于人形机器人和其他形式的机器人。如果展望未来，你觉得最终会形成一个统一的机器人形态，还是会出现一个多元的生态系统，就像生物界那样？

**未来机器人的形态**

**Chelsea Finn ：我无法确定未来会是什么样，但我倾向于认为，未来的机器人世界将呈现出极其丰富的多样性。我的联合创始人 Sergey 曾形象地将其比作 “ 机器人硬件的寒武纪大爆发 ”—— 一旦技术成熟，我们可能会看到各式各样的机器人形态。**

我认为，这种情况就像我们日常生活中的厨房用具 —— 我们不会只使用一台万能设备来完成所有烹饪任务，而是拥有各种专门的工具，比如搅拌机、咖啡机、烤面包机等。机器人也可能会朝着类似的方向发展。例如，在厨房里，可能会有一款专门设计用于烹饪的机械臂，配备针对该场景优化的硬件，同时成本也可以做到足够低廉。而在其他地方，比如折叠衣物、洗碗等任务，也可能会有专门的机器人设计。

当然，这只是我的个人推测，但我认为未来的机器人世界可能会与许多人当前的设想截然不同。

**Elad Gil ：** 在《钻石时代》这本书里，作者描绘了一种未来场景：每家每户都连接着 “ 物质管道 ” ，可以通过 3D 打印技术制造一切所需物品。某种程度上，这是一种进化导向的硬件生产方式 —— 不断优化和选择功能最优的形态。你认为这样的未来是否可能实现 ？还是说，最终只需要少数几个强大的基础机器人形态，就能满足所有需求？

**Chelsea Finn ：** 我认为这样的未来是有可能的。而且，如果我们针对特定用途进行优化，我们确实可以制造出成本更低、效率更高的硬件。至于最终会是一个高度泛化的机器人形态，还是一个更加精细化、分工明确的机器人生态，这一点目前很难预测。

**Elad Gil ：** 的确，这个问题的答案非常难以确定。毕竟，从供应链的角度来看，硬件的种类越少，规模化生产的成本就会越低。因此，除非存在明显的成本优势，否则市场最终可能会倾向于较少的标准化硬件形态，因为它们更容易大规模制造、复制，并降低生产成本。

**Chelsea Finn ：** 确实如此。但也许，我们未来会有机器人来管理整个供应链，让它能够按需制造任何定制化设备。

**Elad Gil ：** 哈哈，那就是机器人 “ 无处不在 ” 的未来了。

*原视频： No Priors Ep. 107 | With Physical Intelligence Co-Founder Chelsea Finn*

*https://www.youtube.com/watch?v=AzqsJk1f12k&list=PLMKa0PxGwad7jf8hwwX8w5FHitXZ1L\_h1&index=2*

*编译： Yvette Chen*

*请注意，本文编译自文未载明的原始链接，不代表 Z Potentials 立场。如果您对本文有任何想法或见解，欢迎在评论区留言互动探讨。*

*Z Potentials 将继续提供更多关于人工智能、机器人、全球化等领域的优质内容。我们诚邀对未来充满憧憬的您加入我们的社群，与我们共同分享、学习、成长。*

**\-----------END-----------**

![图片](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

****🚀** 我们正在招募新一期的实习生**

[![图片](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)](https://mp.weixin.qq.com/s?__biz=MzI4NTgxMDk1NA==&mid=2247503698&idx=4&sn=ade3fdbb8a82ca59be3212c4843bb1a0&scene=21#wechat_redirect)

******🚀** 我们正在寻找有创造力的00后创业****

[![图片](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)](https://mp.weixin.qq.com/s?__biz=MzI4NTgxMDk1NA==&mid=2247494663&idx=1&sn=8fab67231b9ebc593ac65864fd8f7e00&scene=21#wechat_redirect)

![图片](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

***关于Z Potentials***  

![图片](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

继续滑动看下一个

Z Potentials

向上滑动看下一个